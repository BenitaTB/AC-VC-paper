{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83b985b-2f42-4fe5-ae42-fbec7456a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from scipy import stats\n",
    "import statsmodels.stats.multitest\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import os\n",
    "import pims\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import imageio\n",
    "import scipy\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "\n",
    "%run analysis_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eacfa03a-3422-4ea9-8a95-234391fc3f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAzimuthDistribution(df, peak,fig,ax):\n",
    "    # fig = plt.figure(figsize=(ops['mm']*25, ops['mm']*28),constrained_layout =True)\n",
    "    # # ax = fig.add_axes([0.07, 0.77, 0.1, 0.2]) #left, bottom, width, height\n",
    "    # ax = fig.add_subplot(1,1,1) #left, bottom, width, height\n",
    "    if np.max(peak) > 7:\n",
    "        azimuths = ['-108','-90','-72','-54','-36','-18','0','18','36','54','72','90','108']\n",
    "    else:\n",
    "        azimuths = ['-108','-72','-36','0','36','72','108']\n",
    "\n",
    "    bins_peak = np.arange(0,len(azimuths), 1)\n",
    "\n",
    "    hist_all, bins = np.histogram(peak,bins_peak)\n",
    "    hist_all_norm = hist_all/np.sum(hist_all)\n",
    "    plt.hist(bins[:-1],bins,weights = hist_all_norm, color = '#C8C6C6',  histtype ='stepfilled',alpha = 0.4)\n",
    "    plt.hist(bins[:-1],bins,weights = hist_all_norm, color = 'k', histtype ='step', linewidth = 0.5)\n",
    "    plt.xlim([min(bins_peak),max(bins_peak)])\n",
    "    # plt.xticks([0,2,4,6,8,10,12],['-108','-72','-36','0','36', '72', '108'])           \n",
    "    plt.xticks([0,6,12],['-108','0','108'])           \n",
    "\n",
    "    plt.ylim([0,0.15])\n",
    "    plt.yticks([0,0.05, 0.1, 0.15], ['0','5','10','15'])\n",
    "    plt.xlim([-0.1, 12.1])\n",
    "    plt.text(0,0.14, 'n: ' + str(len(peak)), fontsize=15)     \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Percentage of boutons (%)', 'Sound azimuth (\\u00b0)', '', mySize=15)\n",
    "    ax.spines['bottom'].set_bounds(0,12)\n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71e66f1-779a-4189-9376-d8047b2a9f08",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAzimuthDistribution_byArea(fig, gs, df, gaussFit,peak, ops):\n",
    "    #%%\n",
    "    from matplotlib import gridspec\n",
    "    # fig = plt.figure(figsize=(130*mm, 260*mm), constrained_layout=False)\n",
    "    # fig = plt.figure(figsize=(80*mm, 130*mm), constrained_layout=False)\n",
    "\n",
    "    # gs = gridspec.GridSpec(5, 2, figure=fig, hspace=0.4, wspace=0.5,left=0.2, right=0.9, bottom=0.1, top=0.92)\n",
    "   \n",
    "    ops['areas'] = ['V1', 'P','POR', 'LI', 'LM', 'AL', 'RL', 'A', 'AM', 'PM' ]\n",
    "\n",
    "    peaks_byArea, peaks_collapsed_byArea = [], []\n",
    "    cnt = 0\n",
    "    bins_peak = np.arange(0,len(ops['azimuths']), 1.2)\n",
    "\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        idx_thisArea = np.nonzero(np.array(df['area']) == ops['areas'][ar])[0]\n",
    "        \n",
    "        gaussIdx_thisArea = np.intersect1d(gaussFit, idx_thisArea)\n",
    "        # gaussIdx_thisArea = np.intersect1d(gaussIdx_thisArea,a1_idx)\n",
    "        \n",
    "        peaks_this = peak[gaussIdx_thisArea]\n",
    "        peaks_all =  peak[gaussFit]  \n",
    "       #  peaks_all =  param_gauss[np.intersect1d(gaussFit, a1_idx),1]  \n",
    "       \n",
    "        t, p_ks = stats.kstest(peaks_this, peaks_all)\n",
    "    \n",
    "        peaks_this_collapsed = abs(peaks_this - np.round(max(peaks_all))/2)\n",
    "        peaks_byArea.append(peaks_this)\n",
    "        peaks_collapsed_byArea.append(peaks_this_collapsed)\n",
    "\n",
    "        \n",
    "        hist_thisArea, bins = np.histogram(peaks_this,bins_peak)\n",
    "        hist_thisArea_norm = hist_thisArea/np.sum(hist_thisArea)\n",
    "        median_thisArea = np.nanmedian(peaks_this)\n",
    "                    \n",
    "        hist_all, bins = np.histogram(peaks_all,bins_peak)\n",
    "        hist_all_norm = hist_all/np.sum(hist_all)\n",
    "        \n",
    "        if np.mod(cnt,2) ==0:\n",
    "            k = 0\n",
    "        else:\n",
    "            k=1\n",
    "        ax = fig.add_subplot(gs[int(np.floor(cnt/2)), k])\n",
    "        #option 1\n",
    "        # plt.hist(bins[:-1],bins,weights = hist_thisArea_norm, color = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],histtype='stepfilled', alpha = 0.4,label = 'n: ' + str(len(gaussIdx_thisArea)))           \n",
    "        # plt.hist(bins[:-1],bins,weights = hist_thisArea_norm, color = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],histtype='step',linewidth = 0.75, alpha = 1,label = 'n: ' + str(len(gaussIdx_thisArea)))           \n",
    "        # plt.hist(bins[:-1],bins,weights = hist_all_norm, color = 'k', histtype ='step', linewidth = 0.35)\n",
    "\n",
    "        #option 2\n",
    "        plt.hist(bins[:-1],bins,weights = hist_thisArea_norm, color = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],histtype='step',linewidth = 2, alpha = 1,label = 'n: ' + str(len(gaussIdx_thisArea)))           \n",
    "        plt.hist(bins[:-1],bins,weights = hist_all_norm, color = '#C8C6C6', histtype='stepfilled', alpha=1)\n",
    "\n",
    "\n",
    "        plt.xlim([min(bins_peak),max(bins_peak)])\n",
    "        # plt.vlines(median_thisArea, 0, max(hist_thisArea_norm + 0.02), color= 'r' , linewidth = 2)\n",
    "        \n",
    "        if len(ops['azimuths']) ==13:\n",
    "            plt.xticks([0,6,12],['-108', '0', '108'])           \n",
    "            plt.ylim([0,0.3])\n",
    "            plt.yticks([0, 0.3], ['0', '30'])\n",
    "            plt.xlim([-0.2, 12.2])\n",
    "            \n",
    "            # if stats.multitest.multipletest()\n",
    "            # plt.text(10,0.27, 'p= ' + str(np.round(p_ks,10)))\n",
    "            # if len((gaussIdx_thisArea)) > 1000:\n",
    "            #     plt.text(0,0.29, 'n: ' + str(len(gaussIdx_thisArea)), fontsize=5)   \n",
    "            # else:\n",
    "            #     plt.text(0,0.29, 'n: ' + str(len(gaussIdx_thisArea)), fontsize=5)  \n",
    "            if ops['areas'][ar] == 'POR':\n",
    "                plt.text(0.5, 0.75, 'POR', ha='center', fontsize=15,  weight='normal', transform=plt.gca().transAxes, color=ops['myColorsDict']['HVA_colors'][ops['areas'][ar]])\n",
    "                # plt.text(5.4, 0.26, ops['areas'][ar], horizontalalignment ='center', weight='bold')\n",
    "            else:\n",
    "                plt.text(5.8, 0.23, ops['areas'][ar], horizontalalignment ='center', weight='normal',color=ops['myColorsDict']['HVA_colors'][ops['areas'][ar]])\n",
    "            if cnt ==8:\n",
    "                myPlotSettings_splitAxis(fig, ax, 'Percentage of boutons (%)', 'Sound azimuth (\\u00b0)', '', mySize=15)\n",
    "            elif cnt == 9:\n",
    "                myPlotSettings_splitAxis(fig, ax, '', '','', mySize=15)\n",
    "            else:\n",
    "                ax.spines[\"bottom\"].set_visible(False)\n",
    "                plt.xticks([],[])\n",
    "                myPlotSettings_splitAxis(fig, ax, '', '', '', mySize=15)\n",
    "            if k==1:\n",
    "                plt.yticks([0, 0.3], ['', ''])\n",
    "                \n",
    "            ax.tick_params(axis='both', length=2)  # Change tick length for both axes\n",
    "            ax.tick_params(axis='y', pad=1)   \n",
    "            ax.tick_params(axis='x', pad=1)   \n",
    "\n",
    "        cnt +=1  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adefa06e-1356-43fb-90d4-3a33f94dda62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHierarchicalBootstrap(fig, ax, df, peak, gaussFit, ops, nBoot= 1000):\n",
    "    \n",
    "    ks_distance_mat, ks_sigLevels_mat, mannU, mannU_med = doHierarchicalBoostrap(df.iloc[gaussFit], peak[gaussFit], ops['areas'],nBoot =nBoot, nAnimals = 5, nRois = 100)     \n",
    "\n",
    "    colors = sns.color_palette('binary', n_colors =100)\n",
    "\n",
    "    myColors = [colors[10], colors[40], colors[60], colors[80]]\n",
    "\n",
    "    xLabels = ops['areas'].copy()\n",
    "    # xLabels.append('Shuffle')\n",
    " \n",
    "    plt.imshow(ks_distance_mat, cmap = 'Blues', vmin =0.1, vmax =0.5)\n",
    "    plt.colorbar(ticks = [0.1, 0.3, 0.5],fraction = 0.05, pad = 0.05)\n",
    "    \n",
    "    plt.imshow(ks_sigLevels_mat, cmap = LinearSegmentedColormap.from_list('myMap', myColors, N=4), vmax = 3) \n",
    "    cbar = plt.colorbar(ticks = [0.4, 1.15, 1.9, 2.62], fraction = 0.05, pad = 0.07)\n",
    "    cbar.ax.set_yticklabels(['N.S.', 'p < 0.05', 'p < 0.01', 'p < 0.001'])\n",
    " \n",
    "    # plt.title('nAnimals: ' + str(j) + ', nRois: ' + str(i) + ', nBoot:' + str(iBoot))\n",
    "    plt.xticks(np.arange(0,len(ops['areas'])), xLabels, rotation =90)\n",
    "    plt.yticks(np.arange(0,len(ops['areas'])), ops['areas'])\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(1)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce44093b-1dfa-4364-881e-1b0afaee3c74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotProportionCentre_onMap(fig, ref,ref2, df, ops, b=300):\n",
    "    \n",
    "    df = df[~df['x'].isnull()]\n",
    "    df = df[~df['y'].isnull()]\n",
    "    df = df[df['x'] != 0]\n",
    "    df = df[df['y'] != 0]\n",
    "    df = df[df['area'] != 'OUT']\n",
    "\n",
    "    mapsPath =  'Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\retinotopyMaps\\\\'\n",
    "    map_V1 = imageio.imread(os.path.join(mapsPath,'Reference_map_allen_V1Marked.png'))\n",
    "    \n",
    "    # for b in binSize:\n",
    "    leftBorder = 4.4 # 6 = 0 degrees. -30 deg  is 4.4, because 1 space is 18 deg\n",
    "    rightBorder = 7.6\n",
    "       \n",
    "    # b =300\n",
    "    left_tuned = np.nonzero(np.array(df['peak']) < leftBorder)[0]\n",
    "    right_tuned = np.nonzero(np.array(df['peak']) > rightBorder)[0]\n",
    "    centre_tuned0 = np.setdiff1d(np.arange(0,len(np.array(df['peak']))), left_tuned)\n",
    "    centre_tuned1 = np.setdiff1d(np.arange(0,len(np.array(df['peak']))), right_tuned)\n",
    "    centre_tuned = np.intersect1d(centre_tuned0, centre_tuned1)\n",
    "    \n",
    "    lateral_tuned = np.setdiff1d(np.arange(0,len(df)), centre_tuned)\n",
    "    \n",
    "    binned_map = makeSpatialBinnedMap(ref,spatialBin =b) \n",
    "\n",
    "    binned_prop_map_centre = makeProportions_bySpatialBin_v3(df,binned_map, centre_tuned, thresh = 5, mask='none', V1_mask=[])\n",
    "    \n",
    "    binned_values_map_smooth = smooth_spatialBins(binned_prop_map_centre, spatialBin =b, nSmoothBins=1)\n",
    "\n",
    "    def get_midPoint(x, a, b, c, d):\n",
    "        return c + (x - a) * (d - c) / (b - a)\n",
    "    \n",
    "    # ref2 = imageio.imread(os.path.join(refPath,'ReferenceMap_allen_black_nice_uncropped.png'))\n",
    "\n",
    "    \n",
    "    # fig = plt.figure(figsize=(self.mm*100, self.mm*70), constrained_layout=True)       \n",
    "      \n",
    "    # chance = len(centre_tuned)/len(df)\n",
    "    chance = 0.18118882788254953\n",
    "\n",
    "    vmax = 0.32 #np.nanmax(binned_prop_map_left)\n",
    "    vmin = 0\n",
    "    # midPoint =0.5\n",
    "    cmap = 'OrRd'\n",
    "    # midPoint = get_midPoint(chance, vmin,vmax, 0, 1)\n",
    "    # colors = sns.color_palette(cmap, n_colors =100, as_cmap = True)\n",
    "    # cmap_shift = shiftedColorMap(colors, start=0, midpoint=midPoint, stop=1, name='shiftedcmap')\n",
    "   # \n",
    "    #%%\n",
    "    # cmap_shift = 'Purples'\n",
    "\n",
    "    # fig = plt.figure(figsize=(ops['mm']*70, ops['mm']*70), constrained_layout=True)       \n",
    "        \n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.imshow(ref2)\n",
    "    # plt.imshow(ref)\n",
    "    pad = np.empty((13,513));pad[:] = np.nan\n",
    "    binned_map_adj = np.concatenate((pad,binned_values_map_smooth),0)\n",
    "    binned_map_adj = binned_map_adj[:,:-40]\n",
    "    pad = np.empty((398,37));pad[:] = np.nan\n",
    "    binned_map_adj = np.concatenate((pad,binned_map_adj),1)\n",
    "\n",
    "    # plt.imshow(binned_values_map,cmap=colors, vmin =4, vmax=8)\n",
    "    plt.imshow(binned_map_adj,cmap=cmap, vmin =vmin, vmax=vmax,alpha = 0.95)\n",
    "    # plt.colorbar(fraction=0.038, pad=0.04)\n",
    "    # ax.spines[\"top\"].set_color('k')            \n",
    "    # ax.spines[\"top\"].set_linewidth(1)\n",
    "    # ax.spines[\"left\"].set_color('k')            \n",
    "    # ax.spines[\"left\"].set_linewidth(1)\n",
    "    # ax.spines[\"bottom\"].set_color('k')            \n",
    "    # ax.spines[\"bottom\"].set_linewidth(1)\n",
    "    # ax.spines[\"right\"].set_color('k')            \n",
    "    # ax.spines[\"right\"].set_linewidth(1)\n",
    "    plt.yticks([],[])\n",
    "    plt.xticks([],[])\n",
    "    plt.axis('off')\n",
    "    plt.title('Percentage centre-tuned boutons (%)')\n",
    "    cbar = plt.colorbar(ticks = [0,0.16, 0.32],fraction=0.038, pad=0.04)\n",
    "    cbar.ax.set_yticklabels(['0', '16', '32'], fontsize=15)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e8a5eba-af29-4f58-b52f-2689dfd7a525",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotProportionCentre_bySession(df,gaussFit,peak, eng, ops, injectionSubset = []):\n",
    "    leftBorder = 4.4 #\n",
    "    rightBorder = 7.6\n",
    "    \n",
    "    outOnes = np.nonzero(np.array(df['area']) == 'OUT')[0]\n",
    "    inOnes = np.setdiff1d(np.arange(0, len(df)), outOnes)\n",
    "    \n",
    "    idx = np.intersect1d(inOnes,gaussFit)\n",
    "    \n",
    "    ventral_idx =np.nonzero(np.array([df['animal'].iloc[i] in ops['ventralAnimals'] for i in range(len(df))]))[0]\n",
    "    dorsal_idx =np.nonzero(np.array([df['animal'].iloc[i] in ops['dorsalAnimals'] for i in range(len(df))]))[0]\n",
    "    anterior_idx =np.nonzero(np.array([df['animal'].iloc[i] in ops['anteriorAnimals'] for i in range(len(df))]))[0]\n",
    "    posterior_idx =np.nonzero(np.array([df['animal'].iloc[i] in ops['posteriorAnimals'] for i in range(len(df))]))[0]\n",
    "    \n",
    "    if len(injectionSubset) > 0:\n",
    "        if injectionSubset == 'ventral':\n",
    "            idx = np.intersect1d(ventral_idx, idx)\n",
    "        elif injectionSubset == 'dorsal':\n",
    "            idx = np.intersect1d(dorsal_idx, idx)\n",
    "        elif injectionSubset == 'anterior':\n",
    "            idx = np.intersect1d(anterior_idx, idx)\n",
    "        elif injectionSubset == 'posterior':\n",
    "            idx = np.intersect1d(posterior_idx, idx)\n",
    "            \n",
    "    # idx = np.intersect1d(ventral_idx,idx)\n",
    "    # idx =inOnes\n",
    "    peak_gauss = peak[idx]\n",
    "    df_gaussFit = df.iloc[idx]\n",
    "  \n",
    "    left_tuned = np.nonzero(peak_gauss < leftBorder)[0]\n",
    "    right_tuned = np.nonzero(peak_gauss > rightBorder)[0]\n",
    "    centre_tuned0 = np.setdiff1d(np.arange(0,len(peak_gauss)), left_tuned)\n",
    "    centre_tuned1 = np.setdiff1d(np.arange(0,len(peak_gauss)), right_tuned)\n",
    "    centre_tuned = np.intersect1d(centre_tuned0, centre_tuned1)\n",
    "    \n",
    "    #shuffle\n",
    "    nShuffles = 1000\n",
    "  \n",
    "    peak_gauss_sh = peak_gauss.copy(); np.random.shuffle(peak_gauss_sh)\n",
    "    seshIdx_unique = np.unique(df_gaussFit['sessionIdx'])\n",
    "    prop_left = np.empty(len(seshIdx_unique));prop_left[:] = np.nan\n",
    "    prop_right = np.empty(len(seshIdx_unique));prop_right[:] = np.nan\n",
    "    prop_centre = np.empty(len(seshIdx_unique));prop_centre[:] = np.nan\n",
    "\n",
    "    for s in range(len(seshIdx_unique)):\n",
    "        idx_thisSession = np.nonzero(np.array(df_gaussFit['sessionIdx']) == seshIdx_unique[s])[0]\n",
    "        \n",
    "        if len(idx_thisSession) <10:\n",
    "            continue\n",
    "        left_thisSesh = np.intersect1d(idx_thisSession, left_tuned)\n",
    "        right_thisSesh = np.intersect1d(idx_thisSession, right_tuned)\n",
    "        centre_thisSesh = np.intersect1d(idx_thisSession, centre_tuned)\n",
    "        \n",
    "        \n",
    "        prop_left[s] = len(left_thisSesh)/len(idx_thisSession)\n",
    "        prop_right[s] = len(right_thisSesh)/len(idx_thisSession)\n",
    "        prop_centre[s] = len(centre_thisSesh)/len(idx_thisSession)\n",
    "\n",
    "    sessionRef = makeSessionReference(df_gaussFit)   \n",
    "    \n",
    "    inj_DV, inj_AP= [],[]\n",
    "    for j in range(len(sessionRef['seshAnimal'])):\n",
    "        if sessionRef['seshAnimal'][j] in ops['ventralAnimals']:\n",
    "            inj_DV.append('Ventral')\n",
    "        elif sessionRef['seshAnimal'][j] in ops['dorsalAnimals']:\n",
    "            inj_DV.append('Dorsal')\n",
    "            \n",
    "        if sessionRef['seshAnimal'][j] in ops['anteriorAnimals']:\n",
    "            inj_AP.append('Anterior')\n",
    "        elif sessionRef['seshAnimal'][j] in ops['posteriorAnimals']:\n",
    "            inj_AP.append('Posterior')\n",
    "\n",
    "    prop_left_byArea, prop_right_byArea, prop_centre_byArea = [],[],[]\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        idx_thisArea = np.nonzero(np.array(sessionRef['seshAreas']) == ops['areas'][ar])[0]\n",
    "        \n",
    "        prop_this = np.array(prop_left[idx_thisArea])\n",
    "        idx =np.nonzero(np.isnan(prop_this) < 0.05)[0]\n",
    "        prop_this = prop_this[idx]\n",
    "        prop_left_byArea.append(prop_this)\n",
    "        \n",
    "        prop_this = np.array(prop_right[idx_thisArea])\n",
    "        idx =np.nonzero(np.isnan(prop_this) < 0.05)[0]\n",
    "        prop_this = prop_this[idx]\n",
    "        prop_right_byArea.append(prop_this)\n",
    "        \n",
    "        prop_this = np.array(prop_centre[idx_thisArea])\n",
    "        idx =np.nonzero(np.isnan(prop_this) < 0.05)[0]\n",
    "        prop_this = prop_this[idx]\n",
    "        prop_centre_byArea.append(prop_this)\n",
    "        \n",
    "    notNanIdx = np.nonzero(np.isnan(np.array(prop_centre)) < 0.5)[0]  \n",
    "        \n",
    "    df_props_forTest = pd.DataFrame({'proportion_centre': np.array(prop_centre[notNanIdx]),\n",
    "                                     'proportion_left': np.array(prop_left[notNanIdx]),\n",
    "                                     'proportion_right': np.array(prop_right[notNanIdx]),\n",
    "                            'area': np.array(sessionRef['seshAreas'])[notNanIdx],\n",
    "                            'stream': np.array(sessionRef['seshStream'])[notNanIdx],\n",
    "                            'animal':  np.array(sessionRef['seshAnimal'])[notNanIdx],\n",
    "                            'Inj_DV': np.array(sessionRef['pos_DV'])[notNanIdx],\n",
    "                            'Inj_AP': np.array(sessionRef['pos_AP'])[notNanIdx],\n",
    "                            'prop_ventral': np.array(sessionRef['prop_ventral'])[notNanIdx]})\n",
    "    \n",
    "    df_path = os.path.join(ops['outputPath'], 'df_prop_forTest.csv')\n",
    "\n",
    "    df_props_forTest.to_csv(df_path)\n",
    "\n",
    "    prop_left_areaShuffle = np.zeros((len(ops['areas']), nShuffles))\n",
    "    prop_centre_areaShuffle = np.zeros((len(ops['areas']), nShuffles))\n",
    "    prop_right_areaShuffle = np.zeros((len(ops['areas']), nShuffles))\n",
    "\n",
    "    for n in range(nShuffles):\n",
    "        areas_bySession = np.array(sessionRef['seshAreas'])\n",
    "        np.random.shuffle(areas_bySession)\n",
    "        for ar in range(len(ops['areas'])):  \n",
    "            idx = np.nonzero(areas_bySession  == ops['areas'][ar])[0]\n",
    "            prop_left_areaShuffle[ar,n] = np.nanmedian(prop_left[idx])\n",
    "            prop_centre_areaShuffle[ar,n] = np.nanmedian(prop_centre[idx])\n",
    "            prop_right_areaShuffle[ar,n] = np.nanmedian(prop_right[idx])\n",
    "\n",
    "    N = 200\n",
    "    left_sh, centre_sh, right_sh = [], [],[]\n",
    "    for n in range(nShuffles):\n",
    "        rand = np.random.choice(np.arange(0,len(df_gaussFit)), N, replace =True)\n",
    "        \n",
    "        left_sh.append(len(np.intersect1d(left_tuned, rand))/N)\n",
    "        centre_sh.append(len(np.intersect1d(centre_tuned, rand))/N)\n",
    "        right_sh.append(len(np.intersect1d(right_tuned, rand))/N)\n",
    "            \n",
    "    left_sh = np.mean(left_sh)\n",
    "    centre_sh = np.mean(centre_sh)\n",
    "    right_sh = np.mean(right_sh)\n",
    "   \n",
    "    from scipy.stats import friedmanchisquare, wilcoxon                \n",
    "    \n",
    "    #centre tuned\n",
    "    #%%\n",
    "    fig = plt.figure(figsize = (ops['mm']*100,ops['mm']*100), constrained_layout=True)\n",
    "\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    # t,p_kruskal = stats.kruskal(prop_left_byArea[0],prop_left_byArea[1],prop_left_byArea[2],prop_left_byArea[3],prop_left_byArea[4],prop_left_byArea[5],\n",
    "    #                             prop_left_byArea[6],prop_left_byArea[7],prop_left_byArea[8],prop_left_byArea[9])\n",
    "    formula = 'proportion_centre ~ area + Inj_DV + Inj_AP + (1|animal)'                 \n",
    "    p_LMM, all_pVals = eng.linearMixedModel_fromPython_anova_multiVar(df_path, formula, nargout=2)\n",
    "\n",
    "           \n",
    "    # upper = [np.percentile(prop_centre_areaShuffle[j,:], 97.5) for j in range(len(areas))]\n",
    "    # lower = [np.percentile(prop_centre_areaShuffle[j,:], 2.5) for j in range(len(areas))]\n",
    "    # plt.hlines(centre_sh, -0.5,9.5,linestyle='dashed', color ='k', linewidth =0.75)\n",
    "    propCentre_median_byArea = []\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.05,size = len(prop_centre_byArea[ar])) \n",
    "        plt.plot([ar-0.25,ar+0.25], [np.nanmedian(prop_centre_byArea[ar]),np.nanmedian(prop_centre_byArea[ar])], linewidth = 2, c = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],alpha=1,zorder = 2)\n",
    "        # plt.scatter(xVals_scatter, np.array(prop_centre_byArea[ar]), s = 10, facecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]] , edgecolor = 'none',zorder = 1, alpha =0.3)\n",
    "        plt.scatter(xVals_scatter, np.array(prop_centre_byArea[ar]), s = 10, facecolors ='white' , edgecolor = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],zorder = 1,linewidth=0.5, alpha =0.3)\n",
    "\n",
    "        propCentre_median_byArea.append(np.nanmedian(prop_centre_byArea[ar]))\n",
    "        # plt.fill_between([ar-0.2,ar+0.2],[lower[ar], lower[ar]], [upper[ar],upper[ar]], color= 'gray', alpha = 0.2)\n",
    "        # plt.hlines(pVals_ks[ar], ar - 0.3,ar + 0.3, color = 'r', label='real')            \n",
    "        # plt.hlines(lower[ar],ar-0.2,ar+0.2, linewidth = 0.5, color = self.myColorsDict['color_gray_dashedline'],zorder =0)      \n",
    "        # plt.hlines(upper[ar],ar-0.2,ar+0.2, linewidth = 0.5, color = self.myColorsDict['color_gray_dashedline'],zorder =0) \n",
    "        \n",
    "        if p_LMM < 0.05:\n",
    "            p_mannWhitney, compIdx = doMannWhitneyU_forBoxplots(prop_centre_byArea, multiComp = 'fdr')\n",
    "            # p_mannWhitney\n",
    "            cnt = 0\n",
    "            for c in range(len(compIdx)):\n",
    "                if p_mannWhitney[c] < 0.05:\n",
    "                    pos = compIdx[c].split('_')\n",
    "                    plt.hlines(0.52+cnt, int(pos[0]), int(pos[1]), color = 'k', linewidth =0.35)\n",
    "                    cnt += 0.02\n",
    "        # t, p_signRank = stats.wilcoxon(prop_centre_byArea[ar]-centre_sh)\n",
    "        # print(str(p_signRank))\n",
    "        # if p_signRank <  0.00511: ##adjusted for multicomp\n",
    "        #     plt.text(ar,0.9, '*', fontsize=10)\n",
    "        \n",
    "        \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Percentage of boutons (%)', '', 'Centre, p: ' + str(p_LMM), mySize=15)  \n",
    "    # myPlotSettings_splitAxis(fig, ax, '', '', '', mySize=5)  \n",
    "    plt.xticks(np.arange(0,len(ops['areas'])), ops['areas'], rotation = 90)\n",
    "    plt.ylim([-0.02, 0.8])\n",
    "    plt.yticks([0,0.2,0.4,0.6,0.8], ['0','20', '40','60', '80'])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "\n",
    "    fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\percentageCentre_byArea.svg'))\n",
    "\n",
    "\n",
    "    #%% Also plot the other proportions for the supplementals\n",
    "    fig = plt.figure(figsize = (ops['mm']*200,ops['mm']*100), constrained_layout=True)\n",
    "\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    # t,p_kruskal = stats.kruskal(prop_left_byArea[0],prop_left_byArea[1],prop_left_byArea[2],prop_left_byArea[3],prop_left_byArea[4],prop_left_byArea[5],\n",
    "    #                             prop_left_byArea[6],prop_left_byArea[7],prop_left_byArea[8],prop_left_byArea[9])\n",
    "    formula = 'proportion_left ~ area + (1|animal)'                 \n",
    "    p_LMM = eng.linearMixedModel_fromPython_anova(df_path, formula, nargout=1)\n",
    "           \n",
    "    # upper = [np.percentile(prop_centre_areaShuffle[j,:], 97.5) for j in range(len(areas))]\n",
    "    # lower = [np.percentile(prop_centre_areaShuffle[j,:], 2.5) for j in range(len(areas))]\n",
    "    # plt.hlines(centre_sh, -0.5,9.5,linestyle='dashed', color ='k', linewidth =0.75)\n",
    "\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.05,size = len(prop_left_byArea[ar])) \n",
    "        plt.plot([ar-0.25,ar+0.25], [np.nanmedian(prop_left_byArea[ar]),np.nanmedian(prop_left_byArea[ar])], linewidth = 2, c = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],alpha=1,zorder = 2)\n",
    "        # plt.scatter(xVals_scatter, np.array(prop_left_byArea[ar]), s = 10, facecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]] , edgecolor = 'none',zorder = 1, alpha =0.3)\n",
    "        plt.scatter(xVals_scatter, np.array(prop_left_byArea[ar]), s = 10, facecolors ='white' , edgecolor = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],zorder = 1,linewidth=0.5, alpha =0.3)\n",
    "\n",
    "        # plt.fill_between([ar-0.2,ar+0.2],[lower[ar], lower[ar]], [upper[ar],upper[ar]], color= 'gray', alpha = 0.2)\n",
    "        # plt.hlines(pVals_ks[ar], ar - 0.3,ar + 0.3, color = 'r', label='real')            \n",
    "        # plt.hlines(lower[ar],ar-0.2,ar+0.2, linewidth = 0.5, color = self.myColorsDict['color_gray_dashedline'],zorder =0)      \n",
    "        # plt.hlines(upper[ar],ar-0.2,ar+0.2, linewidth = 0.5, color = self.myColorsDict['color_gray_dashedline'],zorder =0) \n",
    "        \n",
    "        if p_LMM < 0.05:\n",
    "            p_mannWhitney, compIdx = doMannWhitneyU_forBoxplots(prop_left_byArea, multiComp = 'fdr')\n",
    "            # p_mannWhitney\n",
    "            cnt = 0\n",
    "            for c in range(len(compIdx)):\n",
    "                if p_mannWhitney[c] < 0.05:\n",
    "                    pos = compIdx[c].split('_')\n",
    "                    plt.hlines(0.52+cnt, int(pos[0]), int(pos[1]), color = 'k', linewidth =0.35)\n",
    "                    cnt += 0.02\n",
    "        # t, p_signRank = stats.wilcoxon(prop_centre_byArea[ar]-centre_sh)\n",
    "        # print(str(p_signRank))\n",
    "        # if p_signRank <  0.00511: ##adjusted for multicomp\n",
    "        #     plt.text(ar,0.9, '*', fontsize=10)\n",
    "        \n",
    "        \n",
    "    # myPlotSettings_splitAxis(fig, ax, '', '', 'p: ' + str(np.round(p_LMM,3)), mySize=6)  \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Percentage of boutons (%)', '',  'Ipsi, p: ' + str(p_LMM), mySize=15)  \n",
    "    plt.xticks(np.arange(0,len(ops['areas'])), ops['areas'], rotation = 90)\n",
    "    plt.ylim([-0.02, 1])\n",
    "    plt.yticks([0,0.2,0.4,0.6,0.8,1], ['0','20', '40','60','80','100'])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "\n",
    "    \n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    # t,p_kruskal = stats.kruskal(prop_left_byArea[0],prop_left_byArea[1],prop_left_byArea[2],prop_left_byArea[3],prop_left_byArea[4],prop_left_byArea[5],\n",
    "    #                             prop_left_byArea[6],prop_left_byArea[7],prop_left_byArea[8],prop_left_byArea[9])\n",
    "    formula = 'proportion_right ~ area + (1|animal)'                 \n",
    "    p_LMM = eng.linearMixedModel_fromPython_anova(df_path, formula, nargout=1)\n",
    "           \n",
    "    # upper = [np.percentile(prop_centre_areaShuffle[j,:], 97.5) for j in range(len(areas))]\n",
    "    # lower = [np.percentile(prop_centre_areaShuffle[j,:], 2.5) for j in range(len(areas))]\n",
    "    # plt.hlines(centre_sh, -0.5,9.5,linestyle='dashed', color ='k', linewidth =0.75)\n",
    "\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.05,size = len(prop_right_byArea[ar])) \n",
    "        plt.plot([ar-0.25,ar+0.25], [np.nanmedian(prop_right_byArea[ar]),np.nanmedian(prop_right_byArea[ar])], linewidth = 2, c = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],alpha=1,zorder = 2)\n",
    "        # plt.scatter(xVals_scatter, np.array(prop_right_byArea[ar]), s = 10, facecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]] , edgecolor = 'none',zorder = 1, alpha =0.3)\n",
    "        plt.scatter(xVals_scatter, np.array(prop_right_byArea[ar]), s = 10, facecolors ='white' , edgecolor = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],zorder = 1,linewidth=0.5, alpha =0.3)\n",
    "\n",
    "        # plt.fill_between([ar-0.2,ar+0.2],[lower[ar], lower[ar]], [upper[ar],upper[ar]], color= 'gray', alpha = 0.2)\n",
    "        # plt.hlines(pVals_ks[ar], ar - 0.3,ar + 0.3, color = 'r', label='real')            \n",
    "        # plt.hlines(lower[ar],ar-0.2,ar+0.2, linewidth = 0.5, color = self.myColorsDict['color_gray_dashedline'],zorder =0)      \n",
    "        # plt.hlines(upper[ar],ar-0.2,ar+0.2, linewidth = 0.5, color = self.myColorsDict['color_gray_dashedline'],zorder =0) \n",
    "        \n",
    "        if p_LMM < 0.05:\n",
    "            p_mannWhitney, compIdx = doMannWhitneyU_forBoxplots(prop_right_byArea, multiComp = 'fdr')\n",
    "            # p_mannWhitney\n",
    "            cnt = 0\n",
    "            for c in range(len(compIdx)):\n",
    "                if p_mannWhitney[c] < 0.05:\n",
    "                    pos = compIdx[c].split('_')\n",
    "                    plt.hlines(0.52+cnt, int(pos[0]), int(pos[1]), color = 'k', linewidth =0.35)\n",
    "                    cnt += 0.02\n",
    "        # t, p_signRank = stats.wilcoxon(prop_centre_byArea[ar]-centre_sh)\n",
    "        # print(str(p_signRank))\n",
    "        # if p_signRank <  0.00511: ##adjusted for multicomp\n",
    "        #     plt.text(ar,0.9, '*', fontsize=10)\n",
    "        \n",
    "    # myPlotSettings_splitAxis(fig, ax, '', '', 'p: ' + str(np.round(p_LMM,3)), mySize=6)  \n",
    "    myPlotSettings_splitAxis(fig, ax, '', '',  'Contra, p: ' + str(p_LMM), mySize=15)  \n",
    "    plt.xticks(np.arange(0,len(ops['areas'])), ops['areas'], rotation = 90)\n",
    "    plt.ylim([-0.02, 1])\n",
    "    plt.yticks([0,0.2,0.4,0.6,0.8,1], ['0','20', '40','60','80','100'])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "    \n",
    "    # fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\percentageLeftRight_byArea.svg'))\n",
    "   \n",
    "    return propCentre_median_byArea\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e400da-e7b0-4835-84b0-51040c231f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotProportionCentre_byStream(fig, df,peak,gaussFit,eng, ops):\n",
    "    leftBorder = 4.4\n",
    "    rightBorder = 7.6\n",
    "    \n",
    "    outOnes = np.nonzero(np.array(df['area']) == 'OUT')[0]\n",
    "    inOnes = np.setdiff1d(np.arange(0, len(df)), outOnes)\n",
    "    \n",
    "    idx = np.intersect1d(inOnes,gaussFit)\n",
    "    # idx =inOnes\n",
    "\n",
    "    peak_gauss = peak[idx]\n",
    "    df_gaussFit = df.iloc[idx]\n",
    "  \n",
    "    left_tuned = np.nonzero(peak_gauss < leftBorder)[0]\n",
    "    right_tuned = np.nonzero(peak_gauss > rightBorder)[0]\n",
    "    centre_tuned0 = np.setdiff1d(np.arange(0,len(peak_gauss)), left_tuned)\n",
    "    centre_tuned1 = np.setdiff1d(np.arange(0,len(peak_gauss)), right_tuned)\n",
    "    centre_tuned = np.intersect1d(centre_tuned0, centre_tuned1)\n",
    "    \n",
    "    #shuffle\n",
    "    nShuffles = 1000\n",
    "    peak_gauss_sh = peak_gauss.copy(); np.random.shuffle(peak_gauss_sh)\n",
    "    seshIdx_unique = np.unique(df_gaussFit['sessionIdx'])\n",
    "    prop_left = np.empty(len(seshIdx_unique));prop_left[:] = np.nan\n",
    "    prop_right = np.empty(len(seshIdx_unique));prop_right[:] = np.nan\n",
    "    prop_centre = np.empty(len(seshIdx_unique));prop_centre[:] = np.nan\n",
    "\n",
    "    for s in range(len(seshIdx_unique)):\n",
    "        idx_thisSession = np.nonzero(np.array(df_gaussFit['sessionIdx']) == seshIdx_unique[s])[0]\n",
    "        \n",
    "        if len(idx_thisSession) <10:\n",
    "            continue\n",
    "        left_thisSesh = np.intersect1d(idx_thisSession, left_tuned)\n",
    "        right_thisSesh = np.intersect1d(idx_thisSession, right_tuned)\n",
    "        centre_thisSesh = np.intersect1d(idx_thisSession, centre_tuned)\n",
    "        \n",
    "        \n",
    "        prop_left[s] = len(left_thisSesh)/len(idx_thisSession)\n",
    "        prop_right[s] = len(right_thisSesh)/len(idx_thisSession)\n",
    "        prop_centre[s] = len(centre_thisSesh)/len(idx_thisSession)\n",
    "\n",
    "    sessionRef = makeSessionReference(df_gaussFit)\n",
    "            \n",
    "    prop_left_byGroup, prop_right_byGroup, prop_centre_byGroup = [],[],[]\n",
    "    for ar in range(len(ops['groups'])):\n",
    "        idx_thisArea = np.nonzero(np.array(sessionRef['seshStream']) == ops['groups'][ar])[0]\n",
    "        \n",
    "        prop_this = np.array(prop_left[idx_thisArea])\n",
    "        idx =np.nonzero(np.isnan(prop_this) < 0.05)[0]\n",
    "        prop_this = prop_this[idx]\n",
    "        prop_left_byGroup.append(prop_this)\n",
    "        \n",
    "        prop_this = np.array(prop_right[idx_thisArea])\n",
    "        idx =np.nonzero(np.isnan(prop_this) < 0.05)[0]\n",
    "        prop_this = prop_this[idx]\n",
    "        prop_right_byGroup.append(prop_this)\n",
    "        \n",
    "        prop_this = np.array(prop_centre[idx_thisArea])\n",
    "        idx =np.nonzero(np.isnan(prop_this) < 0.05)[0]\n",
    "        prop_this = prop_this[idx]\n",
    "        prop_centre_byGroup.append(prop_this)\n",
    "                  \n",
    "       \n",
    "    notNanIdx = np.nonzero(np.isnan(np.array(prop_centre)) < 0.5)[0]  \n",
    "    notV1 = np.nonzero(np.array(sessionRef['seshStream']) != 'V1')[0]\n",
    "    thisIdx = np.intersect1d(notV1,notNanIdx)\n",
    "\n",
    "    df_props_forTest = pd.DataFrame({'proportion_centre': np.array(prop_centre[thisIdx]),\n",
    "                                     'proportion_left': np.array(prop_left[thisIdx]),\n",
    "                                     'proportion_right': np.array(prop_right[thisIdx]),\n",
    "                                     'area': np.array(sessionRef['seshAreas'])[thisIdx],\n",
    "                                     'stream': np.array(sessionRef['seshStream'])[thisIdx],\n",
    "                                     'animal':  np.array(sessionRef['seshAnimal'])[thisIdx],\n",
    "                                     'Inj_DV': np.array(sessionRef['pos_DV'])[thisIdx],\n",
    "                                     'Inj_AP': np.array(sessionRef['pos_AP'])[thisIdx],\n",
    "                                     'prop_ventral': np.array(sessionRef['prop_ventral'])[thisIdx]})    \n",
    "        \n",
    "    #plot it\n",
    "    df_path = os.path.join(ops['outputPath'], 'df_prop_forTest.csv')\n",
    "    df_props_forTest.to_csv(df_path)\n",
    "    \n",
    "    \n",
    "        \n",
    "    #% Centre tuned\n",
    "    fig = plt.figure(figsize=(ops['mm']*60, ops['mm']*100), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "   \n",
    "    formula = 'proportion_centre ~ stream + Inj_DV + Inj_AP + (1|animal)'                 \n",
    "    p_LMM, all_pVals = eng.linearMixedModel_fromPython_anova_multiVar(df_path, formula, nargout=2)\n",
    "                \n",
    "    # upper = [np.percentile(prop_left_areaShuffle[j,:], 97.5) for j in range(len(areas))]\n",
    "    # lower = [np.percentile(prop_left_areaShuffle[j,:], 2.5) for j in range(len(areas))]\n",
    "    # plt.hlines(centre_sh, -0.5,2.5,linestyle='dashed', color ='k', linewidth =0.75)\n",
    "\n",
    "    for ar in range(1,len(ops['groups'])):\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.06,size = len(prop_centre_byGroup[ar])) \n",
    "        plt.plot([ar-0.2,ar+0.2], [np.nanmedian(prop_centre_byGroup[ar]),np.nanmedian(prop_centre_byGroup[ar])], linewidth = 2, c = ops['colors_groups'][ar],zorder = 2)\n",
    "        plt.scatter(xVals_scatter, np.array(prop_centre_byGroup[ar]), s = 10, facecolors = 'white' , edgecolors = ops['colors_groups'][ar], linewidths =0.5,zorder = 1, alpha =0.3)\n",
    "           \n",
    "       \n",
    "        # t, p_signRank = stats.wilcoxon(prop_centre_byGroup[ar]-centre_sh)\n",
    "        # print(str(p_signRank))\n",
    "        # if p_signRank <  0.00511: ##adjusted for multicomp\n",
    "        #     plt.text(ar,0.8, '*', fontsize=10)\n",
    "        \n",
    "    # if p_LMM < 0.05:\n",
    "    # p_mannWhitney, compIdx = doMannWhitneyU_forBoxplots(prop_centre_byGroup, multiComp = 'fdr')\n",
    "    # cnt = 0\n",
    "    # for c in range(len(compIdx)):\n",
    "    #     if p_mannWhitney[c] < 0.05:\n",
    "    #         pos = compIdx[c].split('_')\n",
    "    #         plt.hlines(0.53+cnt, int(pos[0]), int(pos[1]), color = 'k', linewidth =0.5)\n",
    "    #         cnt += 0.03    \n",
    "        \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Percentage centre-tuned boutons (%)', '', 'p: ' + str(np.round(p_LMM,3)), mySize=15)  \n",
    "    # plt.xticks(np.arange(1,len(ops['groups'])), ['Ventral','Dorsal' ], rotation = 45, horizontalalignment='right')\n",
    "    plt.xticks(np.arange(1,len(ops['groups'])), ['Ventral','Dorsal' ])\n",
    "    plt.ylim([-0.02, 0.8])\n",
    "    plt.yticks([0,0.2,0.4, 0.6, 0.8], ['0', '20', '40', '60', '80'])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "\n",
    "  \n",
    "    #left tuned\n",
    "    fig = plt.figure(figsize = (ops['mm']*100,ops['mm']*100), constrained_layout=True)\n",
    "    # fig = plt.figure(figsize = (ops['mm']*70,ops['mm']*38), constrained_layout=True)\n",
    "\n",
    "    ax = fig.add_subplot(1,2,1)\n",
    "    formula = 'proportion_left ~ stream + Inj_DV + Inj_AP + (1|animal)'                 \n",
    "    p_LMM, all_pVals = eng.linearMixedModel_fromPython_anova_multiVar(df_path, formula, nargout=2)\n",
    "           \n",
    "    # upper = [np.percentile(prop_left_areaShuffle[j,:], 97.5) for j in range(len(areas))]\n",
    "    # lower = [np.percentile(prop_left_areaShuffle[j,:], 2.5) for j in range(len(areas))]\n",
    "    # plt.hlines(left_sh, -0.5,2.5,linestyle='dashed', color ='k', linewidth =0.75)\n",
    "\n",
    "    for ar in range(1,len(ops['groups'])):\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.05,size = len(prop_left_byGroup[ar])) \n",
    "        plt.plot([ar-0.25,ar+0.25], [np.nanmedian(prop_left_byGroup[ar]),np.nanmedian(prop_left_byGroup[ar])], linewidth = 2, c = ops['colors_groups'][ar],zorder = 2)\n",
    "        plt.scatter(xVals_scatter, np.array(prop_left_byGroup[ar]), s = 10, facecolors = 'white' , edgecolors =  ops['colors_groups'][ar], linewidths =0.5,zorder = 1,alpha=0.3)\n",
    "           \n",
    "       \n",
    "        # t, p_signRank = stats.wilcoxon(prop_left_byGroup[ar]-left_sh)\n",
    "        # print(str(p_signRank))\n",
    "        # if p_signRank <  0.00511: ##adjusted for multicomp\n",
    "        #     plt.text(ar,0.8, '*', fontsize=10)\n",
    "    # if p_LMM < 0.05:\n",
    "    p_mannWhitney, compIdx = doMannWhitneyU_forBoxplots(prop_left_byGroup, multiComp = 'fdr')\n",
    "    cnt = 0\n",
    "    for c in range(len(compIdx)):\n",
    "        if p_mannWhitney[c] < 0.05:\n",
    "            pos = compIdx[c].split('_')\n",
    "            plt.hlines(0.9+cnt, int(pos[0]), int(pos[1]), color = 'k', linewidth =0.5)\n",
    "            cnt += 0.02    \n",
    "        \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Percentage of boutons (%)', '', 'Ipsi, p: ' + str(np.round(p_LMM,3)), mySize=15)  \n",
    "    plt.xticks(np.arange(1,len(ops['groups'])), ['Ventral','Dorsal' ], rotation = 0, horizontalalignment='center')\n",
    "    plt.ylim([-0.05, 1])\n",
    "    plt.yticks([0,0.5,1], ['0', '50', '100'])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "    \n",
    "    ax = fig.add_subplot(1,2,2)\n",
    "    formula = 'proportion_right ~ stream + Inj_DV + Inj_AP + (1|animal)'                 \n",
    "    p_LMM, all_pVals = eng.linearMixedModel_fromPython_anova_multiVar(df_path, formula, nargout=2)\n",
    "           \n",
    "           \n",
    "    # upper = [np.percentile(prop_left_areaShuffle[j,:], 97.5) for j in range(len(areas))]\n",
    "    # lower = [np.percentile(prop_left_areaShuffle[j,:], 2.5) for j in range(len(areas))]\n",
    "    # plt.hlines(centre_sh, -0.5,2.5,linestyle='dashed', color ='k', linewidth =0.75)\n",
    "\n",
    "    for ar in range(1,len(ops['groups'])):\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.05,size = len(prop_right_byGroup[ar])) \n",
    "        plt.plot([ar-0.25,ar+0.25], [np.nanmedian(prop_right_byGroup[ar]),np.nanmedian(prop_right_byGroup[ar])], linewidth = 2, c = ops['colors_groups'][ar],zorder = 2)\n",
    "        plt.scatter(xVals_scatter, np.array(prop_right_byGroup[ar]), s = 10, facecolors = 'white' , edgecolors = ops['colors_groups'][ar], linewidths =0.5,zorder = 1, alpha=0.3)\n",
    "           \n",
    "        # if p_LMM < 0.05:\n",
    "           \n",
    "        # t, p_signRank = stats.wilcoxon(prop_right_byGroup[ar]-right_sh)\n",
    "        # print(str(p_signRank))\n",
    "        # if p_signRank <  0.00511: ##adjusted for multicomp\n",
    "        #     plt.text(ar,0.8, '*', fontsize=10)\n",
    "    p_mannWhitney, compIdx = doMannWhitneyU_forBoxplots(prop_right_byGroup, multiComp = 'fdr')\n",
    "    cnt = 0\n",
    "    for c in range(len(compIdx)):\n",
    "        if p_mannWhitney[c] < 0.05:\n",
    "            pos = compIdx[c].split('_')\n",
    "            plt.hlines(0.9+cnt, int(pos[0]), int(pos[1]), color = 'k', linewidth =0.5)\n",
    "            cnt += 0.02    \n",
    "        \n",
    "    myPlotSettings_splitAxis(fig, ax, '', '', 'Contra, p: ' + str(np.round(p_LMM,3)), mySize=15)  \n",
    "    plt.xticks(np.arange(1,len(ops['groups'])), ['Ventral','Dorsal' ], rotation = 0, horizontalalignment='center')\n",
    "    plt.ylim([-0.05, 1])\n",
    "    plt.yticks([0,0.5,1], ['0', '50', '100'])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "\n",
    "    #---------------------------------------------------------------------------------------------------------\n",
    "    t = []\n",
    "    for i in range(len(df_gaussFit)):\n",
    "        if df_gaussFit['area'].iloc[i] in ops['dorsal']:\n",
    "            t.append('Dorsal')\n",
    "        elif df_gaussFit['area'].iloc[i] in ops['ventral']:\n",
    "            t.append('Ventral')\n",
    "        elif df_gaussFit['area'].iloc[i] == 'V1':\n",
    "            t.append('V1')\n",
    "        else:\n",
    "            t.append('')\n",
    "\n",
    "    df_gaussFit['streamIdx'] = t\n",
    "    \n",
    "#     ks_distance_mat, ks_sigLevels_mat, mannU, mannU_med = doHierarchicalBoostrap_byStream(df_gaussFit, peak_gauss, ops['groups'], nBoot = 1000, nAnimals = 5, nRois =150, dataType = 'locations')\n",
    "        \n",
    "#     colors = sns.color_palette('binary', n_colors =100)\n",
    "#     myColors = [colors[10], colors[40], colors[60], colors[80]]\n",
    "#     xLabels = ops['groups'].copy()\n",
    "#     # xLabels.append('Shuffle')\n",
    " \n",
    "#     fig = plt.figure(figsize=(ops['mm']*100,100*ops['mm']),constrained_layout = True)\n",
    "#     ax = fig.add_subplot(1,1,1)\n",
    "#     plt.imshow(ks_distance_mat, cmap = 'Blues', vmin =0.15, vmax =0.2)\n",
    "#     cbar = plt.colorbar(ticks = [0.15, 0.175, 0.2],fraction = 0.05, pad = 0.05)\n",
    "#     cbar.ax.set_yticklabels(['0.15', '0.175', '0.2'])\n",
    "\n",
    "#     plt.imshow(ks_sigLevels_mat, cmap = LinearSegmentedColormap.from_list('myMap', myColors, N=4),vmin =0, vmax = 3) \n",
    "#     cbar = plt.colorbar(ticks = [0.4, 1.15, 1.9, 2.62], fraction = 0.05, pad = 0.07)\n",
    "#     cbar.ax.set_yticklabels(['N.S.', 'p < 0.05', 'p < 0.01', 'p < 0.001'])\n",
    " \n",
    "            \n",
    "#     # plt.title('nAnimals: ' + str(j) + ', nRois: ' + str(i) + ', nBoot:' + str(iBoot))\n",
    "#     plt.xticks(np.arange(0,len(ops['groups'])), xLabels, rotation =90)\n",
    "#     plt.yticks(np.arange(0,len(ops['groups'])), xLabels)\n",
    "#     for axis in ['top','bottom','left','right']:\n",
    "#         ax.spines[axis].set_linewidth(1)\n",
    "        \n",
    "    #%%\n",
    "    #% ------------------------------------------------------------------------------------------------\n",
    "\n",
    "    fig = plt.figure(figsize=(100*ops['mm'], 100*ops['mm']), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    bins_peak = np.arange(0,len(ops['azimuths']), 1)\n",
    "\n",
    "    for ar in range(1,len(ops['groups'])):\n",
    "        idx_thisArea = np.nonzero(np.array(df_gaussFit['streamIdx']) == ops['groups'][ar])[0]\n",
    "        \n",
    "        # gaussIdx_thisArea = np.intersect1d(gaussFit, idx_thisArea)\n",
    "        # gaussIdx_thisArea = np.intersect1d(gaussIdx_thisArea,a1_idx)\n",
    "        \n",
    "        peaks_this = peak_gauss[idx_thisArea]\n",
    "        peaks_all =  peak_gauss\n",
    "       #  peaks_all =  param_gauss[np.intersect1d(gaussFit, a1_idx),1]  \n",
    "\n",
    "        hist_thisArea, bins = np.histogram(peaks_this,bins_peak)\n",
    "        hist_thisArea_norm = hist_thisArea/np.sum(hist_thisArea)\n",
    "                    \n",
    "        hist_all, bins = np.histogram(peaks_all,bins_peak)\n",
    "        hist_all_norm = hist_all/np.sum(hist_all)\n",
    "        \n",
    "       \n",
    "        plt.hist(bins[:-1],bins,weights = hist_thisArea_norm, color = ops['colors_groups'][ar],histtype='stepfilled', alpha = 0.1,label = 'n: ' + str(len(peaks_this)))           \n",
    "        plt.hist(bins[:-1],bins,weights = hist_thisArea_norm, color =ops['colors_groups'][ar],histtype='step',linewidth = 0.75, alpha = 1)           \n",
    "        # plt.hist(bins[:-1],bins,weights = hist_all_norm, color = 'k', histtype ='step', linewidth = 0.7)\n",
    "        plt.xlim([min(bins_peak),max(bins_peak)])\n",
    "        # ax.xaxis.set_label_coords(0, 0.7)  # Move labels closer if needed\n",
    "        if len(ops['azimuths']) ==13:\n",
    "            plt.xticks([0,6,12],['-108', '0', '108'])           \n",
    "            plt.ylim([0,0.15])\n",
    "            plt.yticks([0,0.05, 0.1,0.15], ['0','5','10','15'])\n",
    "            plt.xlim([-0.2, 12.2])\n",
    "            \n",
    "            # if stats.multitest.multipletest()\n",
    "            # plt.text(10,0.27, 'p= ' + str(np.round(p_ks,10)))\n",
    "            # if len((gaussIdx_thisArea)) > 1000:\n",
    "            #     plt.text(0,0.27, 'n: ' + str(len(gaussIdx_thisArea)), fontsize=7)   \n",
    "            # else:\n",
    "            #     plt.text(0,0.27, 'n: ' + str(len(gaussIdx_thisArea)), fontsize=7)   \n",
    "                \n",
    "           \n",
    "            myPlotSettings_splitAxis(fig, ax, 'Percentage of boutons (%)', 'Sound azimuth (\\u00b0)', '', mySize=15)\n",
    "          \n",
    "                # plt.xticks([0,6,12],['', '', ''])\n",
    "                \n",
    "       \n",
    "        ax.tick_params(axis='both', length=2)  # Change tick length for both axes\n",
    "        ax.tick_params(axis='y', pad=1)  \n",
    "        ax.tick_params(axis='x', pad=1)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b583b845-11dc-4caa-be52-b9f4085eefd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploreInjectionLocation_azimuths(df0, peak0, ops,eng):\n",
    "    #%%\n",
    "    animals_thisDataset = df0['animal'].unique()\n",
    "    \n",
    "    ventralAn = np.intersect1d(animals_thisDataset, ops['ventralAnimals'])        #[109,113,128,149,154,166,168]\n",
    "    dorsalAn = np.intersect1d(animals_thisDataset, ops['dorsalAnimals'])  #[107,112,131,132,151,153,170,171,178]\n",
    "   \n",
    "    anteriorAn = np.intersect1d(animals_thisDataset,ops['anteriorAnimals'])         #[113,128,151,154,170,178]\n",
    "    posteriorAn = np.intersect1d(animals_thisDataset,ops['posteriorAnimals'])     #[107,109,112,131,132,149,153,166,168,171]\n",
    "    \n",
    "    t = []\n",
    "    for i in range(len(df0)):\n",
    "        if df0['area'].iloc[i] in ops['dorsal']:\n",
    "            t.append('Dorsal')\n",
    "        elif df0['area'].iloc[i] in ops['ventral']:\n",
    "            t.append('Ventral')\n",
    "        elif df0['area'].iloc[i] == 'V1':\n",
    "            t.append('V1')\n",
    "        else:\n",
    "            t.append('')                        \n",
    "    df0['streamIdx'] = t\n",
    "    \n",
    "    \n",
    "    \n",
    "    animals = df0['animal'].unique()\n",
    "    post_idx = np.zeros(0,); ant_idx = np.zeros(0,)\n",
    "    dorsal_idx = np.zeros(0,); ventral_idx = np.zeros(0,)\n",
    "    post_idx_V1= np.zeros(0,); ant_idx_V1 = np.zeros(0,)\n",
    "    dorsal_idx_V1 = np.zeros(0,); ventral_idx_V1 = np.zeros(0,)\n",
    "    post_idx_dorsalStream= np.zeros(0,); ant_idx_dorsalStream = np.zeros(0,)\n",
    "    dorsal_idx_dorsalStream = np.zeros(0,); ventral_idx_dorsalStream = np.zeros(0,)\n",
    "    post_idx_ventralStream= np.zeros(0,); ant_idx_ventralStream = np.zeros(0,)\n",
    "    dorsal_idx_ventralStream = np.zeros(0,); ventral_idx_ventralStream = np.zeros(0,)\n",
    "    for a in range(len(animals)):\n",
    "        idx_this = np.nonzero(np.array(df0['animal']) == animals[a])[0]\n",
    "        \n",
    "        idx_V1 = np.nonzero(np.array(df0['streamIdx']) == 'V1')[0]\n",
    "        idx_ventral = np.nonzero(np.array(df0['streamIdx']) == 'Ventral')[0]\n",
    "        idx_dorsal = np.nonzero(np.array(df0['streamIdx']) == 'Dorsal')[0]\n",
    "\n",
    "        idx_this_V1 = np.intersect1d(idx_this,idx_V1)\n",
    "        idx_this_dorsal = np.intersect1d(idx_this,idx_dorsal)\n",
    "        idx_this_ventral = np.intersect1d(idx_this,idx_ventral)\n",
    "\n",
    "        if animals[a] in posteriorAn:\n",
    "            post_idx = np.concatenate((post_idx,idx_this),0)\n",
    "            post_idx_V1 = np.concatenate((post_idx_V1,idx_this_V1),0)\n",
    "            post_idx_dorsalStream = np.concatenate((post_idx_dorsalStream,idx_this_dorsal),0)\n",
    "            post_idx_ventralStream = np.concatenate((post_idx_ventralStream,idx_this_ventral),0)\n",
    "        elif animals[a] in anteriorAn:\n",
    "            ant_idx = np.concatenate((ant_idx,idx_this),0)\n",
    "            ant_idx_V1 = np.concatenate((ant_idx_V1,idx_this_V1),0)\n",
    "            ant_idx_dorsalStream = np.concatenate((ant_idx_dorsalStream,idx_this_dorsal),0)\n",
    "            ant_idx_ventralStream = np.concatenate((ant_idx_ventralStream,idx_this_ventral),0)\n",
    "                    \n",
    "        if animals[a] in ventralAn:\n",
    "            ventral_idx = np.concatenate((ventral_idx,idx_this),0)\n",
    "            ventral_idx_V1 = np.concatenate((ventral_idx_V1,idx_this_V1),0)\n",
    "            ventral_idx_dorsalStream = np.concatenate((ventral_idx_dorsalStream,idx_this_dorsal),0)\n",
    "            ventral_idx_ventralStream = np.concatenate((ventral_idx_ventralStream,idx_this_ventral),0)\n",
    "        elif animals[a] in dorsalAn:\n",
    "            dorsal_idx = np.concatenate((dorsal_idx,idx_this),0)\n",
    "            dorsal_idx_V1 = np.concatenate((dorsal_idx_V1,idx_this_V1),0)\n",
    "            dorsal_idx_dorsalStream = np.concatenate((dorsal_idx_dorsalStream,idx_this_dorsal),0)\n",
    "            dorsal_idx_ventralStream = np.concatenate((dorsal_idx_ventralStream,idx_this_ventral),0)\n",
    "               \n",
    "    \n",
    "    #%\n",
    "    bins_peak = np.arange(0,len(ops['azimuths']), 1)\n",
    "\n",
    "    #%%   \n",
    "    #Anterior vs posterior\n",
    "    animalGroups = [anteriorAn, posteriorAn]\n",
    "    #sigLevels_ks, sigLevels_mannU = doHierarchicalBoostrap_byInjectionSite(df0, peak0, animalGroups, nBoot = 1000, nAnimals = 5, nRois = 200)\n",
    "    color_anterior = 'blue'\n",
    "    color_posterior = 'red'\n",
    "    \n",
    "    fig = plt.figure(figsize=(ops['mm']*30, ops['mm']*38), constrained_layout=True) \n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    \n",
    "    hist_all, bins = np.histogram(peak0[ant_idx.astype(int)],bins_peak)\n",
    "    hist_all_norm = hist_all/np.sum(hist_all)\n",
    "    plt.hist(bins[:-1],bins,weights = hist_all_norm, color = color_anterior,  histtype ='step',linewidth= 1.3, alpha = 0.8, label = 'Anterior Inj.')\n",
    "    # plt.hist(bins[:-1],bins,weights = hist_all_norm, color = color_ventral,  histtype ='stepfilled',alpha = 0.1, label = 'Ventral Inj.')\n",
    "\n",
    "    hist_all, bins = np.histogram(peak0[post_idx.astype(int)],bins_peak)\n",
    "    hist_all_norm = hist_all/np.sum(hist_all)\n",
    "    plt.hist(bins[:-1],bins,weights = hist_all_norm, color = color_posterior,  histtype ='step',linewidth= 1.3, alpha = 0.8, label = 'Posterior Inj.')\n",
    "    # plt.hist(bins[:-1],bins,weights = hist_all_norm, color = color_dorsal,  histtype ='stepfilled', alpha = 0.1, label = 'Dorsal Inj.')\n",
    "\n",
    "    plt.xticks([0,6,12],['-108','0','108'])   \n",
    "    plt.xlim([-0.1, 12.1])        \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Percentage of boutons (%)', 'Sound azimuth (\\u00b0)', '', mySize=6)\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)\n",
    "    plt.yticks([0,0.05, 0.1, 0.15], ['0', '5','10','15'])\n",
    "    fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\bestAzimuth_injectionLocation_AP_nice.svg'))\n",
    "\n",
    "    \n",
    "    #Dorsal vs ventral\n",
    "    animalGroups = [ventralAn, dorsalAn]\n",
    "   # sigLevels_ks, sigLevels_mannU = doHierarchicalBoostrap_byInjectionSite(df0, peak0, animalGroups, nBoot = 1000, nAnimals = 5, nRois = 200)\n",
    "    color_dorsal = 'green'\n",
    "    color_ventral = 'darkorange'\n",
    "    \n",
    "    fig = plt.figure(figsize=(ops['mm']*30, ops['mm']*38), constrained_layout=True) \n",
    "    ax = fig.add_subplot(1,1,1) \n",
    "    \n",
    "    hist_all, bins = np.histogram(peak0[ventral_idx.astype(int)],bins_peak)\n",
    "    hist_all_norm = hist_all/np.sum(hist_all)\n",
    "    plt.hist(bins[:-1],bins,weights = hist_all_norm, color = color_ventral,  histtype ='step',linewidth= 1.3, alpha = 0.8, label = 'Ventral Inj.')\n",
    "    # plt.hist(bins[:-1],bins,weights = hist_all_norm, color = color_ventral,  histtype ='stepfilled',alpha = 0.1, label = 'Ventral Inj.')\n",
    "\n",
    "    hist_all, bins = np.histogram(peak0[dorsal_idx.astype(int)],bins_peak)\n",
    "    hist_all_norm = hist_all/np.sum(hist_all)\n",
    "    plt.hist(bins[:-1],bins,weights = hist_all_norm, color = color_dorsal,  histtype ='step',linewidth= 1.3, alpha = 0.8, label = 'Dorsal Inj.')\n",
    "    # plt.hist(bins[:-1],bins,weights = hist_all_norm, color = color_dorsal,  histtype ='stepfilled', alpha = 0.1, label = 'Dorsal Inj.')\n",
    "    \n",
    "    plt.xticks([0,6,12],['-108','0','108'])   \n",
    "    plt.xlim([-0.1, 12.1])        \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Percentage of boutons (%)', 'Sound azimuth (\\u00b0)', '', mySize=6)\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)\n",
    "    plt.yticks([0,0.05, 0.1, 0.15], ['0', '5','10','15'])\n",
    "    fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\bestAzimuth_injectionLocation_DV_nice.svg'))\n",
    "\n",
    "    #%% Percentage centre-tuned\n",
    "    leftBorder = 4.4\n",
    "    rightBorder = 7.4\n",
    "    \n",
    "\n",
    "    left_tuned = np.nonzero(peak0 < leftBorder)[0]\n",
    "    right_tuned = np.nonzero(peak0 > rightBorder)[0]\n",
    "    centre_tuned0 = np.setdiff1d(np.arange(0,len(peak0)), left_tuned)\n",
    "    centre_tuned1 = np.setdiff1d(np.arange(0,len(peak0)), right_tuned)\n",
    "    centre_tuned = np.intersect1d(centre_tuned0, centre_tuned1)\n",
    "    \n",
    "    #shuffle\n",
    "    nShuffles = 1000\n",
    "    # df_gaussFit_sh = df_gaussFit.copy()\n",
    "    # shuffled_session = df_gaussFit['sessionIdx'].sample(frac=1, replace=False).reset_index(drop=True)\n",
    "    # df_gaussFit_sh['sessionIdx'] = shuffled_session\n",
    "    peak0_sh = peak0.copy(); np.random.shuffle(peak0_sh)\n",
    "    \n",
    "    # left_tuned_gauss = np.intersect1d(gaussFit, left_tuned)\n",
    "    # prop_left_all = len(left_tuned_gauss)/len(gaussFit)       \n",
    "    # right_tuned_gauss = np.intersect1d(gaussFit, right_tuned)\n",
    "    # prop_right_all = len(right_tuned_gauss)/len(gaussFit)\n",
    "    # centre_tuned_gauss = np.intersect1d(gaussFit, centre_tuned)\n",
    "    # prop_centre_all = len(centre_tuned_gauss)/len(gaussFit)\n",
    "    seshIdx_unique = np.unique(df0['sessionIdx'])\n",
    "    prop_left = np.empty(len(seshIdx_unique));prop_left[:] = np.nan\n",
    "    prop_right = np.empty(len(seshIdx_unique));prop_right[:] = np.nan\n",
    "    prop_centre = np.empty(len(seshIdx_unique));prop_centre[:] = np.nan\n",
    "\n",
    "    for s in range(len(seshIdx_unique)):\n",
    "        idx_thisSession = np.nonzero(np.array(df0['sessionIdx']) == seshIdx_unique[s])[0]\n",
    "        \n",
    "        if len(idx_thisSession) <10:\n",
    "            continue\n",
    "        left_thisSesh = np.intersect1d(idx_thisSession, left_tuned)\n",
    "        right_thisSesh = np.intersect1d(idx_thisSession, right_tuned)\n",
    "        centre_thisSesh = np.intersect1d(idx_thisSession, centre_tuned)\n",
    "        \n",
    "        \n",
    "        prop_left[s] = len(left_thisSesh)/len(idx_thisSession)\n",
    "        prop_right[s] = len(right_thisSesh)/len(idx_thisSession)\n",
    "        prop_centre[s] = len(centre_thisSesh)/len(idx_thisSession)\n",
    "\n",
    "    sessionRef = makeSessionReference(df0)   \n",
    "    \n",
    "    nSessions = len(sessionRef['seshAnimal'])\n",
    "    dorsal_idx = np.nonzero(np.array([sessionRef['seshAnimal'][i] in dorsalAn for i in range(nSessions)]))[0]\n",
    "    ventral_idx = np.nonzero(np.array([sessionRef['seshAnimal'][i] in ventralAn for i in range(nSessions)]))[0]\n",
    "    posterior_idx = np.nonzero(np.array([sessionRef['seshAnimal'][i] in posteriorAn for i in range(nSessions)]))[0]\n",
    "    anterior_idx = np.nonzero(np.array([sessionRef['seshAnimal'][i] in anteriorAn for i in range(nSessions)]))[0]\n",
    "\n",
    "    v1_idx = np.nonzero(np.array([sessionRef['seshAreas'][i] =='V1' for i in range(nSessions)]))[0]\n",
    "    dorsalAreas_idx = np.nonzero(np.array([sessionRef['seshAreas'][i] in ops['dorsal'] for i in range(nSessions)]))[0]\n",
    "    ventralAreas_idx = np.nonzero(np.array([sessionRef['seshAreas'][i] in ops['ventral'] for i in range(nSessions)]))[0]\n",
    "\n",
    "    def excludeNans(data):\n",
    "        notNan = np.nonzero(np.isnan(data) < 0.5)[0]\n",
    "        return data[notNan]\n",
    "\n",
    "\n",
    "#     propCentre_dorsalInj_all = excludeNans(prop_centre[dorsal_idx]); \n",
    "#     propCentre_ventralInj_all = excludeNans(prop_centre[ventral_idx])\n",
    "#     propCentre_anteriorInj_all = excludeNans(prop_centre[anterior_idx])\n",
    "#     propCentre_posteriorInj_all = excludeNans(prop_centre[posterior_idx])\n",
    "    \n",
    "#     propCentre_dorsalInj_v1 = excludeNans(prop_centre[np.intersect1d(v1_idx, dorsal_idx)])\n",
    "#     propCentre_ventralInj_v1 = excludeNans(prop_centre[np.intersect1d(v1_idx, ventral_idx)])\n",
    "#     propCentre_anteriorInj_v1 = excludeNans(prop_centre[np.intersect1d(v1_idx, anterior_idx)])\n",
    "#     propCentre_posteriorInj_v1 = excludeNans(prop_centre[np.intersect1d(v1_idx, posterior_idx)])\n",
    "    \n",
    "#     propCentre_dorsalInj_dors = excludeNans(prop_centre[np.intersect1d(dorsalAreas_idx, dorsal_idx)])\n",
    "#     propCentre_ventralInj_dors = excludeNans(prop_centre[np.intersect1d(dorsalAreas_idx, ventral_idx)])\n",
    "#     propCentre_anteriorInj_dors = excludeNans(prop_centre[np.intersect1d(dorsalAreas_idx, anterior_idx)])\n",
    "#     propCentre_posteriorInj_dors = excludeNans(prop_centre[np.intersect1d(dorsalAreas_idx, posterior_idx)])\n",
    "    \n",
    "#     propCentre_dorsalInj_vent = excludeNans(prop_centre[np.intersect1d(ventralAreas_idx, dorsal_idx)])\n",
    "#     propCentre_ventralInj_vent = excludeNans(prop_centre[np.intersect1d(ventralAreas_idx, ventral_idx)])\n",
    "#     propCentre_anteriorInj_vent = excludeNans(prop_centre[np.intersect1d(ventralAreas_idx, anterior_idx)])\n",
    "#     propCentre_posteriorInj_vent = excludeNans(prop_centre[np.intersect1d(ventralAreas_idx, posterior_idx)])\n",
    "    \n",
    "    #%%\n",
    "    notOut = np.nonzero(np.array(sessionRef['seshAreas']) != 'OUT')[0]\n",
    "    notNan = np.nonzero(np.isnan(np.array(prop_centre)) <0.5)[0]\n",
    "    these = np.intersect1d(notOut,notNan)\n",
    "    df_forTest = pd.DataFrame({'prop_centre': np.array(prop_centre)[these],\n",
    "                               'area': np.array(sessionRef['seshAreas'])[these], \n",
    "                               'animal':  np.array(sessionRef['seshAnimal'])[these], \n",
    "                               'Inj_DV': np.array(sessionRef['pos_DV'])[these],\n",
    "                               'Inj_AP': np.array(sessionRef['pos_AP'])[these],\n",
    "                               'prop_ventral': np.array(sessionRef['prop_ventral'])[these]})\n",
    "            \n",
    "    df_forTest['Inj_DV'] = df_forTest['Inj_DV'] - min(df_forTest['Inj_DV'])  \n",
    "    df_forTest['Inj_AP'] = abs(df_forTest['Inj_AP'] - max(df_forTest['Inj_AP'])) \n",
    "\n",
    "    df_path= os.path.join(ops['outputPath'],'df_forLMM.csv')\n",
    "    df_forTest.to_csv(df_path)\n",
    "    formula = 'prop_centre ~ 1 + Inj_DV + (1|animal)'\n",
    "    # formula = 'meanElevs_green ~ 1 + fitElevs_red + (1|animal)'\n",
    "\n",
    "    savePath = os.path.join(ops['outputPath'], 'LMM_green.mat')\n",
    "    \n",
    "    #run LMM and load results\n",
    "    res, fitLines, fitCI = eng.linearMixedModel_fromPython(df_path, formula,savePath, nargout=3) \n",
    "\n",
    "    mat_file = scipy.io.loadmat(savePath)   \n",
    "    res = getDict_fromMatlabStruct(mat_file, 'res')\n",
    "    \n",
    "    intercept = res['Intercept'][0][0] # from matlab LMM \n",
    "    slope = res['Inj_DV'][0][0]\n",
    "    slope_p = res['Inj_DV'][0][1]\n",
    "    xVals = np.arange(0,max(df_forTest['Inj_DV']),1)\n",
    "    yVals = intercept + slope*xVals\n",
    "     \n",
    "    r_spearman,p_spearman = scipy.stats.spearmanr(df_forTest['Inj_DV'], df_forTest['prop_centre'])\n",
    "\n",
    "    #\n",
    "    #this is the nice one\n",
    "    fig = plt.figure(figsize =(ops['mm']*37,ops['mm']*35), constrained_layout = True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.scatter(np.array(df_forTest['Inj_DV']), np.array(df_forTest['prop_centre']), c= 'k', s =1)\n",
    "    x_axis = 'Inj_DV'\n",
    "    # fitLine = np.array(fitLines[x_axis])\n",
    "    # fitLine_down = np.array(fitCI[x_axis])[:,0]\n",
    "    # fitLine_up = np.array(fitCI[x_axis])[:,1]\n",
    "    # xVals = np.linspace(min(df_forTest[x_axis]), max(df_forTest[x_axis]), len(fitLine))\n",
    "    # plt.fill_between(xVals, fitLine_up, fitLine_down, facecolor = 'gray',alpha = 0.3)\n",
    "    # plt.plot(xVals, fitLine, c = 'k', linewidth = 1, linestyle ='dashed') \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Percentage centre-\\ntuned boutons (%)', 'Injection centre position (\\u03BCm)','', mySize=6)\n",
    "    plt.text(70,0.65,'r: ' + str(np.round(r_spearman,4)) + '\\np: ' + str(np.round(p_spearman,4)))\n",
    "    plt.xticks([0,40,80,120], ['0', '400', '800', '1200'])\n",
    "    plt.yticks([0,0.2, 0.4, 0.6, 0.8],['0','20','40','60','80'])\n",
    "    ax.tick_params(axis='y', pad=1)  \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "        \n",
    "    fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\propCentre_bySession_againstDV_pos.svg'))\n",
    "\n",
    "    \n",
    "    # df_path= os.path.join(outputPath,'df_freqs_forLMM.csv')\n",
    "    # df_forTest.to_csv(df_path)\n",
    "    formula = 'prop_centre ~ 1 + Inj_AP + (1|animal)'\n",
    "    # formula = 'meanElevs_green ~ 1 + fitElevs_red + (1|animal)'\n",
    "\n",
    "    savePath = os.path.join(ops['outputPath'], 'LMM_green.mat')\n",
    "    \n",
    "    r_spearman,p_spearman = scipy.stats.spearmanr(df_forTest['Inj_AP'], df_forTest['prop_centre'])\n",
    "\n",
    "    #run LMM and load results\n",
    "    res, fitLines, fitCI = eng.linearMixedModel_fromPython(df_path, formula,savePath, nargout=3) \n",
    "\n",
    "    mat_file = scipy.io.loadmat(savePath)   \n",
    "    res = getDict_fromMatlabStruct(mat_file, 'res')\n",
    "    \n",
    "    intercept = res['Intercept'][0][0] # from matlab LMM \n",
    "    slope = res['Inj_AP'][0][0]\n",
    "    slope_p = res['Inj_AP'][0][1]\n",
    "    xVals = np.arange(0,max(df_forTest['Inj_AP']),1)\n",
    "    yVals = intercept + slope*xVals\n",
    "     \n",
    "    #\n",
    "    #this is the nice one\n",
    "    fig = plt.figure(figsize =(ops['mm']*37,ops['mm']*35), constrained_layout = True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.scatter(np.array(df_forTest['Inj_AP']), np.array(df_forTest['prop_centre']), c= 'k', s =1)\n",
    "    # x_axis = 'Inj_AP'\n",
    "    # fitLine = np.array(fitLines[x_axis])\n",
    "    # fitLine_down = np.array(fitCI[x_axis])[:,0]\n",
    "    # fitLine_up = np.array(fitCI[x_axis])[:,1]\n",
    "    # xVals = np.linspace(min(df_freqs_forTest[x_axis]), max(df_freqs_forTest[x_axis]), len(fitLine))\n",
    "    # plt.fill_between(xVals, fitLine_up, fitLine_down, facecolor = 'gray',alpha = 0.3)\n",
    "    # plt.plot(xVals, fitLine, c = 'k', linewidth = 1, linestyle ='dashed') \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Percentage centre-\\ntuned boutons (%)', 'Injection centre position (\\u03BCm)','', mySize=6)\n",
    "    plt.text(55,0.65,'r: ' + str(np.round(r_spearman,4)) + '\\np: ' + str(np.round(p_spearman,4)))\n",
    "    plt.xticks([0,50,100], ['0', '500', '1000'])\n",
    "    plt.yticks([0,0.2, 0.4, 0.6, 0.8],['0','20','40','60','80'])\n",
    "    ax.tick_params(axis='y', pad=1)  \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "    \n",
    "    fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\propCentre_bySession_againstAP_pos.svg'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa301aa6-090f-45c0-b906-ca8cbbe600e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotProportionCentre_onMap_red(fig,ax, ref,ref2, map_v1,df, ops,cmap='OrRd', b=300):\n",
    "    \n",
    "    df = df[~df['x'].isnull()]\n",
    "    df = df[~df['y'].isnull()]\n",
    "    df = df[df['x'] != 0]\n",
    "    df = df[df['y'] != 0]\n",
    "    df = df[df['area'] != 'OUT']\n",
    "\n",
    "   #\n",
    "    \n",
    "    # for b in binSize:\n",
    "    leftBorder = 1.6666\n",
    "    \n",
    "       \n",
    "    # b =300\n",
    "    centre_tuned = np.nonzero(np.array(df['aziPeak']) < leftBorder)[0]\n",
    "    # centre_tuned0 = np.setdiff1d(np.arange(0,len(np.array(df['peak']))), left_tuned)\n",
    "    # centre_tuned1 = np.setdiff1d(np.arange(0,len(np.array(df['peak']))), right_tuned)\n",
    "    # centre_tuned = np.intersect1d(centre_tuned0, centre_tuned1)\n",
    "    \n",
    "    # lateral_tuned = np.setdiff1d(np.arange(0,len(df)), centre_tuned)\n",
    "    \n",
    "    binned_map = makeSpatialBinnedMap(ref,spatialBin =b) \n",
    "\n",
    "    binned_prop_map_centre = makeProportions_bySpatialBin_v3(df,binned_map, centre_tuned, thresh = 5, mask='none', V1_mask=[])\n",
    "    \n",
    "    binned_values_map_smooth = smooth_spatialBins(binned_prop_map_centre, spatialBin =b, nSmoothBins=1)\n",
    "\n",
    "    def get_midPoint(x, a, b, c, d):\n",
    "        return c + (x - a) * (d - c) / (b - a)\n",
    "    \n",
    "    # ref2 = imageio.imread(os.path.join(refPath,'ReferenceMap_allen_black_nice_uncropped.png'))\n",
    "\n",
    "    \n",
    "    # fig = plt.figure(figsize=(self.mm*100, self.mm*70), constrained_layout=True)       \n",
    "      \n",
    "    # chance = len(centre_tuned)/len(df)\n",
    "   # chance = 0.18118882788254953\n",
    "\n",
    "    vmax = 0.6 #np.nanmax(binned_values_map_smooth)\n",
    "    vmin = 0\n",
    "    # midPoint =0.5\n",
    "   #  cmap = 'coolwarm'\n",
    "   #  midPoint = get_midPoint(chance, vmin,vmax, 0, 1)\n",
    "   #  colors = sns.color_palette(cmap, n_colors =100, as_cmap = True)\n",
    "   #  cmap_shift = shiftedColorMap(colors, start=0, midpoint=midPoint, stop=1, name='shiftedcmap')\n",
    "   # # \n",
    "#%%\n",
    "    # cmap_shift = 'Purples'\n",
    "\n",
    "    # fig = plt.figure(figsize=(ops['mm']*70, ops['mm']*70), constrained_layout=True)       \n",
    "        \n",
    "    # ax = fig.add_subplot(1,1,1)\n",
    "    plt.imshow(ref2)\n",
    "    # plt.imshow(ref)\n",
    "    pad = np.empty((13,513));pad[:] = np.nan\n",
    "    binned_map_adj = np.concatenate((pad,binned_values_map_smooth),0)\n",
    "    binned_map_adj = binned_map_adj[:,:-40]\n",
    "    pad = np.empty((398,37));pad[:] = np.nan\n",
    "    binned_map_adj = np.concatenate((pad,binned_map_adj),1)\n",
    "\n",
    "    # plt.imshow(binned_values_map,cmap=colors, vmin =4, vmax=8)\n",
    "    plt.imshow(binned_map_adj,cmap=cmap, vmin =vmin, vmax=vmax,alpha = 0.95)\n",
    "    # plt.colorbar(fraction=0.038, pad=0.04)\n",
    "    # ax.spines[\"top\"].set_color('k')            \n",
    "    # ax.spines[\"top\"].set_linewidth(1)\n",
    "    # ax.spines[\"left\"].set_color('k')            \n",
    "    # ax.spines[\"left\"].set_linewidth(1)\n",
    "    # ax.spines[\"bottom\"].set_color('k')            \n",
    "    # ax.spines[\"bottom\"].set_linewidth(1)\n",
    "    # ax.spines[\"right\"].set_color('k')            \n",
    "    # ax.spines[\"right\"].set_linewidth(1)\n",
    "    plt.yticks([],[])\n",
    "    plt.xticks([],[])\n",
    "    plt.axis('off')\n",
    "    # plt.title('Centre')\n",
    "    cbar = plt.colorbar(ticks = [0,0.3, 0.6],fraction=0.038, pad=0.04)\n",
    "    cbar.ax.set_yticklabels(['0', '30', '60'], fontsize=15)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c0f020-5362-4bdb-99c5-57877aeeff6f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plotElevation_byArea(df,maps,peak,eng,ops,nShuffles, injectionSubset=[]):\n",
    "    \n",
    "    noArea_idx = np.nonzero(np.array(df['area']) == 'OUT')[0]\n",
    "    \n",
    "    badRoiPosition1 = np.nonzero(np.array(df['x']) ==0)[0]\n",
    "    badRoiPosition2 = np.nonzero(np.array(df['y']) ==0)[0]\n",
    "    badRoiPosition = np.unique(np.concatenate((badRoiPosition1,badRoiPosition2),0))\n",
    "    \n",
    "    noArea_idx = np.unique(np.concatenate((noArea_idx,badRoiPosition),0))\n",
    "           \n",
    "    elevPeak = getElevation_greenAud(df, maps, peak, onlyPeakSide = 1)\n",
    "    # contraIdx = np.nonzero(np.array(df_fit_1d_green_aud_full_elev['gaussian_peak']) > 6)[0]\n",
    "\n",
    "    includeIdx_green_elev = np.setdiff1d(np.arange(0,len(df)), noArea_idx)\n",
    " \n",
    "    ventral_idx =np.nonzero(np.array([df['animal'].iloc[i] in ops['ventralAnimals'] for i in range(len(df))]))[0]\n",
    "    dorsal_idx =np.nonzero(np.array([df['animal'].iloc[i] in ops['dorsalAnimals'] for i in range(len(df))]))[0]\n",
    "    anterior_idx =np.nonzero(np.array([df['animal'].iloc[i] in ops['anteriorAnimals'] for i in range(len(df))]))[0]\n",
    "    posterior_idx =np.nonzero(np.array([df['animal'].iloc[i] in ops['posteriorAnimals'] for i in range(len(df))]))[0]\n",
    "    \n",
    "    if len(injectionSubset) > 0:\n",
    "        if injectionSubset == 'ventral':\n",
    "            includeIdx_green_elev = np.intersect1d(ventral_idx,  includeIdx_green_elev)\n",
    "        elif injectionSubset == 'dorsal':\n",
    "            includeIdx_green_elev = np.intersect1d(dorsal_idx,  includeIdx_green_elev)\n",
    "        elif injectionSubset == 'anterior':\n",
    "            includeIdx_green_elev= np.intersect1d(anterior_idx,  includeIdx_green_elev)\n",
    "        elif injectionSubset == 'posterior':\n",
    "            includeIdx_green_elev = np.intersect1d(posterior_idx,  includeIdx_green_elev)\n",
    "\n",
    "    df_green_elev = df.iloc[includeIdx_green_elev]\n",
    "    df_green_elev['elevPeak'] = elevPeak[includeIdx_green_elev]\n",
    "    \n",
    "    \n",
    "    data0 = elevPeak[includeIdx_green_elev]\n",
    "    df0= df_green_elev\n",
    "    \n",
    "    #%\n",
    "    fig = plt.figure(figsize=(ops['mm']*60, ops['mm']*60), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    bins_peak = np.array([0,2,4,6])\n",
    "\n",
    "    hist_all, bins = np.histogram(data0,bins_peak)\n",
    "    hist_all_norm = hist_all/np.sum(hist_all)\n",
    "    plt.hist(bins[:-1],bins,weights = hist_all_norm, color = '#C8C7C7',  histtype ='stepfilled',alpha = 0.4, orientation='horizontal')\n",
    "    plt.hist(bins[:-1],bins,weights = hist_all_norm, color = 'k', histtype ='step', linewidth = 0.75, orientation='horizontal')\n",
    "    plt.ylim([min(bins_peak)-0.1,max(bins_peak)])\n",
    "    plt.yticks([1, 3, 5],['-36','0','36'])           \n",
    "\n",
    "    plt.xlim([0,0.5])\n",
    "    plt.xticks([0,0.25,0.5],['0','25','50'])           \n",
    "\n",
    "    # plt.yticks([0,0.05, 0.1, 0.15], ['0','5','10','15'])\n",
    "    # plt.ylim([-3, 6.02])\n",
    "    # plt.text(0,0.14, 'n: ' + str(len(peak)), fontsize=5)     \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best sound elevation (deg)', 'Percentage of boutons (%)', '', mySize=15)\n",
    "    # ax.spines['bottom'].set_bounds(0,12)\n",
    "    ax.tick_params(axis='y', pad=1)  \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "    \n",
    "    #get grean peak by session   \n",
    "    #green\n",
    "    peak_elev_bySession = []\n",
    "    peak_elev_bySession_sh = []\n",
    "    sessionIdx= np.unique(np.array(df0['sessionIdx']))\n",
    "    for s in range(len(sessionIdx)):\n",
    "        idx_thisSession = np.nonzero(np.array(df0['sessionIdx']) == sessionIdx[s])[0]\n",
    "              \n",
    "      \n",
    "        peak_elev = data0[idx_thisSession]\n",
    "        \n",
    "        if len(idx_thisSession) < 10:\n",
    "            peak_elev_bySession.append(np.nan)\n",
    "        else:\n",
    "            peak_elev_bySession.append(np.nanmean(peak_elev))\n",
    "        \n",
    "        sh = np.zeros((len(idx_thisSession), nShuffles))\n",
    "        for n in range(nShuffles):\n",
    "            idx = np.random.choice(np.arange(len(data0)), len(idx_thisSession))\n",
    "            sh[:,n] = data0[idx]\n",
    "        \n",
    "        peak_elev_bySession_sh.append(sh)\n",
    "\n",
    "          \n",
    "    sessionRef = makeSessionReference(df0)\n",
    "    inj_DV, inj_AP= [],[]\n",
    "    for j in range(len(sessionRef['seshAnimal'])):\n",
    "        if sessionRef['seshAnimal'][j] in ops['ventralAnimals']:\n",
    "            inj_DV.append('Ventral')\n",
    "        elif sessionRef['seshAnimal'][j] in ops['dorsalAnimals']:\n",
    "            inj_DV.append('Dorsal')\n",
    "            \n",
    "        if sessionRef['seshAnimal'][j] in ops['anteriorAnimals']:\n",
    "            inj_AP.append('Anterior')\n",
    "        elif sessionRef['seshAnimal'][j] in ops['posteriorAnimals']:\n",
    "            inj_AP.append('Posterior')\n",
    "\n",
    "    # peak_azi_bySession = np.array(peak_azi_bySession)\n",
    "    peakElev_byArea = []\n",
    "    peakElev_byArea_sh = []\n",
    "\n",
    "    for ar in range(len(ops['areas'])):  \n",
    "        idx = np.nonzero(np.array(sessionRef['seshAreas']) == ops['areas'][ar])[0]\n",
    "        \n",
    "        peak_bySession_this = np.array([peak_elev_bySession[idx[i]] for i in range(len(idx))])\n",
    "        peak_bySession_this_clean = peak_bySession_this[np.nonzero(np.isnan(peak_bySession_this) < 0.5)[0]]\n",
    "\n",
    "        peakElev_byArea.append(peak_bySession_this_clean)\n",
    "        \n",
    "        peak_bySession_this_sh = np.array([peak_elev_bySession_sh[idx[i]] for i in range(len(idx))])\n",
    "        # peak_bySession_this_clean = peak_bySession_this_sh[np.nonzero(np.isnan(peak_bySession_this_sh) < 0.5)[0]]\n",
    "\n",
    "        peakElev_byArea_sh.append(peak_bySession_this_sh)\n",
    "    \n",
    "    \n",
    "\n",
    "    # median_azi1 = [np.array([np.nanmedian(peakAzi_byArea[ar][i]) for i in range(len(peakAzi_byArea[ar]))]) for ar in range(len(areas))]\n",
    "    \n",
    "    notV1 = np.nonzero(np.array(sessionRef['seshAreas']) != 'V1')[0]\n",
    "    notNan = np.nonzero(np.isnan(np.array(peak_elev_bySession)) <0.5)[0]\n",
    "    # thisIdx =notNan\n",
    "    thisIdx = np.intersect1d(notV1,notNan)\n",
    "    # seshMapGood = np.nonzero(np.array(sessionRef['seshMapGood']) == 1)[0]\n",
    "    # thisIdx = np.intersect1d(thisIdx, seshMapGood)\n",
    "\n",
    "    df_forTest = pd.DataFrame({'peakElev_bySession': np.array(peak_elev_bySession)[thisIdx],                                    \n",
    "                            'area': np.array(sessionRef['seshAreas'])[thisIdx],\n",
    "                            'stream': np.array(sessionRef['seshStream'])[thisIdx],\n",
    "                            'elev': np.array(sessionRef['seshElev'])[thisIdx],\n",
    "                            'animal':  np.array(sessionRef['seshAnimal'])[thisIdx],\n",
    "                            'Inj_DV': np.array(inj_DV)[thisIdx],\n",
    "                            'Inj_AP': np.array(inj_AP)[thisIdx]})\n",
    "    \n",
    "    df_path = os.path.join(ops['outputPath'], 'df_forTest.csv')\n",
    "\n",
    "    df_forTest.to_csv(df_path)\n",
    "\n",
    "\n",
    "    formula = 'peakElev_bySession ~ area + Inj_DV + Inj_AP + (1|animal)'                 \n",
    "    p_LMM, all_pVals = eng.linearMixedModel_fromPython_anova_multiVar(df_path, formula, nargout=2)\n",
    "\n",
    "    \n",
    "    \n",
    "    # formula = 'peakElev_bySession ~ elev + (1|animal)'                 \n",
    "    # savePath = os.path.join(ops['outputPath'], 'LMM_green_aud.mat')\n",
    "     \n",
    "     #run LMM and load results\n",
    "    # res, fitLines, fitCI = eng.linearMixedModel_fromPython(df_path, formula,savePath, nargout=3) \n",
    "      \n",
    "    # mat_file = scipy.io.loadmat(savePath)   \n",
    "    # res = getDict_fromMatlabStruct(mat_file, 'res')\n",
    "       #%%        \n",
    "    fig = plt.figure(figsize=(ops['mm']*100, ops['mm']*100), constrained_layout =True)\n",
    "       \n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        median_elev0 = np.array([np.nanmedian(peakElev_byArea[ar][i]) for i in range(len(peakElev_byArea[ar]))])\n",
    "        median_elev = np.nanmedian(median_elev0)\n",
    "        plt.plot([ar-0.25, ar+0.25], [median_elev,median_elev] , linewidth = 2, c = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],zorder = 2)\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.05,size = len(median_elev0)) \n",
    "        plt.scatter(xVals_scatter, np.array(median_elev0), s = 10, facecolors = 'white' , edgecolors =  ops['myColorsDict']['HVA_colors'][ops['areas'][ar]], linewidths =0.5,alpha=0.3,zorder =1)\n",
    "        \n",
    "        \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best sound elevation (deg)', '', 'p: ' + str(np.round(p_LMM,3)), mySize=15)\n",
    "    plt.xticks(np.arange(0, len(ops['areas'])), ops['areas'], rotation =90)\n",
    "    plt.ylim([0.888888, 3.66666])\n",
    "    plt.yticks([2-(20/18),2-(10/18),2, 2 + (10/18), 2+(20/18), 2+(30/18)], ['-20', '-10', '0', '10', '20', '30'])\n",
    "    if p_LMM < 0.05:\n",
    "        p_mannWhitney, compIdx = doMannWhitneyU_forBoxplots(peakElev_byArea, multiComp = 'fdr')\n",
    "        cnt = 0\n",
    "        for c in range(len(compIdx)):\n",
    "            if p_mannWhitney[c] < 0.05:\n",
    "                pos = compIdx[c].split('_')\n",
    "                plt.hlines(3.2+cnt, int(pos[0]), int(pos[1]), color = 'k', linewidth =0.5)\n",
    "                cnt += 0.1\n",
    "    ax.tick_params(axis='y', pad=1)  \n",
    "    ax.tick_params(axis='x', pad=1)  \n",
    "    # fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\bestElevation_byArea.svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c78edd8c-7d86-4b61-8965-2094511c202e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotElevation_byStream(df, peak, maps, eng, ops):\n",
    "    \n",
    "    noArea_idx = np.nonzero(np.array(df['area']) == 'OUT')[0]\n",
    "        \n",
    "    badRoiPosition1 = np.nonzero(np.array(df['x']) ==0)[0]\n",
    "    badRoiPosition2 = np.nonzero(np.array(df['y']) ==0)[0]\n",
    "    badRoiPosition = np.unique(np.concatenate((badRoiPosition1,badRoiPosition2),0))\n",
    "    \n",
    "    noArea_idx = np.unique(np.concatenate((noArea_idx,badRoiPosition),0))\n",
    "           \n",
    "    elevPeak = getElevation_greenAud(df, maps, peak, onlyPeakSide =1)\n",
    "    # contraIdx = np.nonzero(np.array(df_fit_1d_green_aud_full_elev['gaussian_peak']) > 6)[0]\n",
    "\n",
    "    includeIdx_green_elev = np.setdiff1d(np.arange(0,len(df)), noArea_idx)\n",
    "\n",
    "    df_green_elev = df.iloc[includeIdx_green_elev]\n",
    "    df_green_elev['elevPeak'] = elevPeak[includeIdx_green_elev]\n",
    "    \n",
    "    \n",
    "    data0 = elevPeak[includeIdx_green_elev]\n",
    "    df0= df_green_elev\n",
    "    \n",
    "    #get grean peak by session   \n",
    "    #green\n",
    "    peak_elev_bySession = []\n",
    "    peak_elev_bySession_sh = []\n",
    "    sessionIdx= np.unique(np.array(df0['sessionIdx']))\n",
    "    for s in range(len(sessionIdx)):\n",
    "        idx_thisSession = np.nonzero(np.array(df0['sessionIdx']) == sessionIdx[s])[0]\n",
    "              \n",
    "      \n",
    "        peak_elev = data0[idx_thisSession]\n",
    "        \n",
    "        if len(idx_thisSession) < 10:\n",
    "            peak_elev_bySession.append(np.nan)\n",
    "        else:\n",
    "            peak_elev_bySession.append(np.nanmean(peak_elev))\n",
    "        \n",
    "        # sh = np.zeros((len(idx_thisSession), nShuffles))\n",
    "        # for n in range(nShuffles):\n",
    "        #     idx = np.random.choice(np.arange(len(data0)), len(idx_thisSession))\n",
    "        #     sh[:,n] = data0[idx]\n",
    "        \n",
    "        # peak_elev_bySession_sh.append(sh)\n",
    "        \n",
    "    sessionRef = makeSessionReference(df0)   \n",
    " \n",
    "    meanElev_byGroup = []\n",
    "    for ar in range(len(ops['groups'])):\n",
    "        idx_thisArea = np.nonzero(np.array(sessionRef['seshStream']) == ops['groups'][ar])[0]\n",
    "        \n",
    "        med_this = np.array([peak_elev_bySession[idx_thisArea[i]] for i in range(len(idx_thisArea))])\n",
    "        idx =np.nonzero(np.isnan(med_this) < 0.05)[0]\n",
    "        med_this = med_this[idx]\n",
    "        meanElev_byGroup.append(med_this)\n",
    "        \n",
    "    # notV1 = np.nonzero(np.array(sessionRef['seshStream']) != 'V1')[0]\n",
    "    notNan = np.nonzero(np.isnan(np.array(peak_elev_bySession)) <0.5)[0]\n",
    "    thisIdx =notNan\n",
    "    # thisIdx = np.intersect1d(notV1,notNan)\n",
    "    # seshMapGood = np.nonzero(np.array(sessionRef['seshMapGood']) == 1)[0]\n",
    "    # thisIdx = np.intersect1d(thisIdx, seshMapGood)\n",
    "    df_forTest = pd.DataFrame({'peakElev_bySession': np.array(peak_elev_bySession)[thisIdx],                                    \n",
    "                            'area': np.array(sessionRef['seshAreas'])[thisIdx],\n",
    "                            'stream': np.array(sessionRef['seshStream'])[thisIdx],\n",
    "                            'elev': np.array(sessionRef['seshElev'])[thisIdx],\n",
    "                            'animal':  np.array(sessionRef['seshAnimal'])[thisIdx],\n",
    "                            'Inj_DV': np.array(sessionRef['pos_DV'])[thisIdx],\n",
    "                            'Inj_AP': np.array(sessionRef['pos_AP'])[thisIdx],\n",
    "                            'prop_ventral': np.array(sessionRef['prop_ventral'])[thisIdx]})\n",
    "    \n",
    "    df_path = os.path.join(ops['outputPath'], 'df_forTest.csv')\n",
    "\n",
    "    df_forTest.to_csv(df_path)\n",
    "        \n",
    "    formula = 'peakElev_bySession ~ stream + Inj_DV + Inj_AP + (1|animal)'                 \n",
    "    p_LMM, all_pVals = eng.linearMixedModel_fromPython_anova_multiVar(df_path, formula, nargout=2)\n",
    "\n",
    "    #%%\n",
    "    fig = plt.figure(figsize=(ops['mm']*80, ops['mm']*80), constrained_layout =True)\n",
    "\n",
    "    ax = fig.add_subplot(1,1,1)    \n",
    "    for ar in range(1,len(ops['groups'])):\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.1,size = len(meanElev_byGroup[ar])) \n",
    "        plt.plot([ar-0.3,ar+0.3], [np.nanmedian(meanElev_byGroup[ar]),np.nanmedian(meanElev_byGroup[ar])], linewidth = 2, c = ops['colors_groups'][ar],zorder = 2)\n",
    "        plt.scatter(xVals_scatter, np.array(meanElev_byGroup[ar]), s = 10, facecolors = 'white' , edgecolors = ops['colors_groups'][ar], linewidths =0.5,alpha =0.3,zorder = 1)\n",
    "           \n",
    "        \n",
    "        # t, p_signRank = stats.wilcoxon(meanElev_byGroup[ar]-medElev_sh)\n",
    "        # print(str(p_signRank))\n",
    "        # if p_signRank <  0.00511: ##adjusted for multicomp\n",
    "        #     plt.text(ar,0.8, '*', fontsize=10)\n",
    "    # if p_LMM < 0.05:\n",
    "    #     p_mannWhitney, compIdx = doMannWhitneyU_forBoxplots(meanElev_byGroup, multiComp = 'hs')\n",
    "    #     cnt = 0\n",
    "    #     for c in range(len(compIdx)):\n",
    "    #         if p_mannWhitney[c] < 0.05:\n",
    "    #             pos = compIdx[c].split('_')\n",
    "    #             plt.hlines(2.7+cnt, int(pos[0]), int(pos[1]), color = 'k', linewidth =0.5)\n",
    "    #             cnt += 0.02    \n",
    "        \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best sound elevation (deg)', '', 'p: ' + str(np.round(p_LMM,3)), mySize=15)  \n",
    "    plt.xticks(np.arange(1,len(ops['groups'])), ['Ventral','Dorsal' ])\n",
    "    plt.ylim([0.888888, 2+(30/18)])\n",
    "    plt.yticks([2-(20/18),2-(10/18),2, 2 + (10/18), 2+(20/18), 2+(30/18)], ['-20', '-10', '0', '10', '20', '30'])\n",
    "    ax.tick_params(axis='x', pad=1)  \n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "\n",
    "    #%% Plot distribution by stream\n",
    "    t = []\n",
    "    for i in range(len(df0)):\n",
    "        if df0['area'].iloc[i] in ops['dorsal']:\n",
    "            t.append('Dorsal')\n",
    "        elif df0['area'].iloc[i] in ops['ventral']:\n",
    "            t.append('Ventral')\n",
    "        elif df0['area'].iloc[i] == 'V1':\n",
    "            t.append('V1')\n",
    "        else:\n",
    "            t.append('')\n",
    "\n",
    "    df0['streamIdx'] = t\n",
    "    \n",
    "    groups = ['Ventral', 'Dorsal']\n",
    "    elev_byStream =[]\n",
    "    for g in range(len(groups)):\n",
    "        these = np.nonzero(np.array(df0['streamIdx']) == groups[g])[0]\n",
    "        \n",
    "        elev_byStream.append(data0[these])\n",
    "        \n",
    "    fig = plt.figure(figsize=(ops['mm']*80, ops['mm']*80), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    bins_peak = np.array([0,2,4,6])\n",
    "\n",
    "    colors = [ops['myColorsDict']['HVA_colors']['ventral'],ops['myColorsDict']['HVA_colors']['dorsal']]\n",
    "    for g in range(len(groups)):\n",
    "        hist_all, bins = np.histogram(elev_byStream[g],bins_peak)\n",
    "        hist_all_norm = hist_all/np.sum(hist_all)\n",
    "        plt.hist(bins[:-1],bins,weights = hist_all_norm, color = colors[g], histtype ='stepfilled',alpha = 0.1, orientation='horizontal')\n",
    "        plt.hist(bins[:-1],bins,weights = hist_all_norm, color = colors[g], histtype ='step', linewidth = 0.75, orientation='horizontal')\n",
    "        \n",
    "    plt.ylim([min(bins_peak)-0.1,max(bins_peak)])\n",
    "    plt.yticks([1, 3, 5],['-36','0','36'])           \n",
    "\n",
    "    plt.xlim([0,0.5])\n",
    "    plt.xticks([0,0.25,0.5],['0','25','50'])           \n",
    "\n",
    "    # plt.yticks([0,0.05, 0.1, 0.15], ['0','5','10','15'])\n",
    "    # plt.ylim([-3, 6.02])\n",
    "    # plt.text(0,0.14, 'n: ' + str(len(peak)), fontsize=5)     \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best sound elevation (deg)', 'Percentage of boutons (%)', '', mySize=15)\n",
    "    # ax.spines['bottom'].set_bounds(0,12)\n",
    "    ax.tick_params(axis='y', pad=1)  \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e91c26-e90b-435b-b47e-399583e04073",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBestAzimuth_red_onMap(fig, df, ref, ref2,map_V1, b=250):\n",
    "    \n",
    "    df = df[~df['x'].isnull()]\n",
    "    df = df[~df['y'].isnull()]\n",
    "    df = df[df['x'] != 0]\n",
    "    df = df[df['y'] != 0]\n",
    "    df = df[df['area'] != 'OUT']\n",
    "    \n",
    "#     mapsPath =  'Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\retinotopyMaps\\\\'\n",
    "#     map_V1 = imageio.imread(os.path.join(mapsPath,'Reference_map_allen_V1Marked.png'))\n",
    "        \n",
    "    # b = 250\n",
    "    binned_map = makeSpatialBinnedMap(ref,spatialBin =b) \n",
    "    binned_values_map = makeMeanValue_bySpatialBin_v2(df, binned_map,thresh =5,  varName = 'aziPeak', mask='none', V1_mask = map_V1)\n",
    "    \n",
    "    binned_values_map_smooth = smooth_spatialBins(binned_values_map, spatialBin =b, nSmoothBins=1)\n",
    "    # binned_values_map_smooth = binned_values_map\n",
    "    cmap = 'coolwarm_r'\n",
    "    # cmap = nice_cmaps[f]\n",
    "\n",
    "    colors = sns.color_palette(cmap, n_colors =100, as_cmap = True)\n",
    "        \n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.imshow(ref2)\n",
    "    \n",
    "    pad = np.empty((13,513));pad[:] = np.nan\n",
    "    binned_map_adj = np.concatenate((pad,binned_values_map_smooth),0)\n",
    "    binned_map_adj = binned_map_adj[:,:-40]\n",
    "    pad = np.empty((398,37));pad[:] = np.nan\n",
    "    binned_map_adj = np.concatenate((pad,binned_map_adj),1)\n",
    "\n",
    "    plt.imshow(binned_map_adj,cmap=colors, alpha =0.95, vmin =20/18, vmax = 80/18)\n",
    "    plt.yticks([],[])\n",
    "    plt.xticks([],[])\n",
    "    plt.axis('off')\n",
    "    # if 'freq' in dataType:\n",
    "    cbar = plt.colorbar(ticks = [20/18,50/18,80/18],fraction=0.038, pad=0.04)\n",
    "    cbar.ax.set_yticklabels(['20', '50', '80'],fontsize=15)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfc2caf-9690-4213-bb0c-76c66475312a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBestElevation_onMap(fig, df, maps, peak, ref, ref2, map_V1, b=250):\n",
    "  \n",
    "    # elev = getElevation_greenAud(df, maps, peak)\n",
    "    elev = getElevation_greenAud(df, maps, peak)\n",
    "    \n",
    "    df['peak'] = elev\n",
    "    # df = df.iloc[includeIdx]\n",
    "    \n",
    "    df = df[~df['x'].isnull()]\n",
    "    df = df[~df['y'].isnull()]\n",
    "    df = df[df['x'] != 0]\n",
    "    df = df[df['y'] != 0]\n",
    "    df = df[df['area'] != 'OUT']\n",
    "    \n",
    "    # b = 300\n",
    "    binned_map = makeSpatialBinnedMap(ref,spatialBin =b) \n",
    "    binned_values_map = makeMeanValue_bySpatialBin_v2(df, binned_map,thresh =5,  varName = 'peak', mask = 'none', V1_mask = map_V1)\n",
    "    \n",
    "    binned_values_map_smooth = smooth_spatialBins(binned_values_map, spatialBin =b, nSmoothBins=1)\n",
    "    # binned_values_map_smooth = binned_values_map\n",
    "\n",
    "    cmap = 'coolwarm'\n",
    "    # cmap = nice_cmaps[f]\n",
    "\n",
    "    colors = sns.color_palette(cmap, n_colors =100, as_cmap = True)\n",
    "        \n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.imshow(ref2)\n",
    "    \n",
    "    pad = np.empty((13,513));pad[:] = np.nan\n",
    "    binned_map_adj = np.concatenate((pad,binned_values_map_smooth),0)\n",
    "    binned_map_adj = binned_map_adj[:,:-40]\n",
    "    pad = np.empty((398,37));pad[:] = np.nan\n",
    "    binned_map_adj = np.concatenate((pad,binned_map_adj),1)\n",
    "\n",
    "    plt.imshow(binned_map_adj,cmap=colors,vmin =1.166, vmax=2.8333, alpha =0.95)\n",
    "    # plt.imshow(binned_values_map,cmap=colors, vmin =1, vmax=3, alpha = 1)\n",
    "\n",
    "    # plt.annotate('', xy=(xVals[0]+midPoint_x,yVals[0]), xytext=(xVals[-1]+midPoint_x,yVals[-1]), arrowprops=dict(arrowstyle='<->', linewidth=1.5, color = 'k'))\n",
    "    # plt.text(30, 30, 'p: ' + str(np.round(res['pos_proj'][0][1],3)))\n",
    "    # plt.axis('off')  \n",
    "    # ax.spines[\"top\"].set_color('k')            \n",
    "    # ax.spines[\"top\"].set_linewidth(1)\n",
    "    # ax.spines[\"left\"].set_color('k')            \n",
    "    # ax.spines[\"left\"].set_linewidth(1)\n",
    "    # ax.spines[\"bottom\"].set_color('k')            \n",
    "    # ax.spines[\"bottom\"].set_linewidth(1)\n",
    "    # ax.spines[\"right\"].set_color('k')            \n",
    "    # ax.spines[\"right\"].set_linewidth(1)\n",
    "    plt.yticks([],[])\n",
    "    plt.xticks([],[])\n",
    "    plt.axis('off')\n",
    "    # if 'freq' in dataType:\n",
    "    cbar = plt.colorbar(ticks = [1.166,2,2.8333],fraction=0.038, pad=0.04)\n",
    "    cbar.ax.set_yticklabels(['-15', '0', '15'],fontsize=15)\n",
    "    # plt.title('Mean sound elevation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd4b4a1-a929-4a34-b845-ccf1253c964c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotBestElevation_red_onMap(fig, df, ref, ref2,map_V1, b=250):\n",
    "    \n",
    "    # df = df_red\n",
    "    # df = df.iloc[includeIdx]\n",
    "    data = np.array(df['elevPeak'])\n",
    "    df['elevPeak_inv'] = abs(np.nanmax(data)- data)   #flip it around so that max is top led location\n",
    "    \n",
    "    df = df[~df['x'].isnull()]\n",
    "    df = df[~df['y'].isnull()]\n",
    "    df = df[df['x'] != 0]\n",
    "    df = df[df['y'] != 0]\n",
    "    df = df[df['area'] != 'OUT']\n",
    "       \n",
    "    binned_map = makeSpatialBinnedMap(ref,spatialBin =b) \n",
    "    binned_values_map = makeMeanValue_bySpatialBin_v2(df, binned_map,thresh =5,  varName = 'elevPeak_inv', mask ='', V1_mask = map_V1)\n",
    "    \n",
    "    binned_values_map_smooth = smooth_spatialBins(binned_values_map, spatialBin =b, nSmoothBins=1)\n",
    "    # binned_values_map_smooth = binned_values_map\n",
    "\n",
    "    cmap = 'coolwarm'\n",
    "    # cmap = nice_cmaps[f]\n",
    "\n",
    "    colors = sns.color_palette(cmap, n_colors =100, as_cmap = True)\n",
    "        \n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.imshow(ref2)\n",
    "    \n",
    "    \n",
    "    pad = np.empty((13,513));pad[:] = np.nan\n",
    "    binned_map_adj = np.concatenate((pad,binned_values_map_smooth),0)\n",
    "    binned_map_adj = binned_map_adj[:,:-40]\n",
    "    pad = np.empty((398,37));pad[:] = np.nan\n",
    "    binned_map_adj = np.concatenate((pad,binned_map_adj),1)\n",
    "\n",
    "    plt.imshow(binned_map_adj,cmap=colors,vmin =2-(30/18), vmax=2+(30/18), alpha =0.95)\n",
    "    # plt.imshow(binned_values_map,cmap=colors, vmin =1, vmax=3, alpha = 1)\n",
    "\n",
    "    # plt.annotate('', xy=(xVals[0]+midPoint_x,yVals[0]), xytext=(xVals[-1]+midPoint_x,yVals[-1]), arrowprops=dict(arrowstyle='<->', linewidth=1.5, color = 'k'))\n",
    "    # plt.text(30, 30, 'p: ' + str(np.round(res['pos_proj'][0][1],3)))\n",
    "    # plt.axis('off')  \n",
    "    # ax.spines[\"top\"].set_color('k')            \n",
    "    # ax.spines[\"top\"].set_linewidth(1)\n",
    "    # ax.spines[\"left\"].set_color('k')            \n",
    "    # ax.spines[\"left\"].set_linewidth(1)\n",
    "    # ax.spines[\"bottom\"].set_color('k')            \n",
    "    # ax.spines[\"bottom\"].set_linewidth(1)\n",
    "    # ax.spines[\"right\"].set_color('k')            \n",
    "    # ax.spines[\"right\"].set_linewidth(1)\n",
    "    plt.yticks([],[])\n",
    "    plt.xticks([],[])\n",
    "    plt.axis('off')\n",
    "    # if 'freq' in dataType:\n",
    "    cbar = plt.colorbar(ticks = [2-(30/18),2,2+(30/18)],fraction=0.038, pad=0.04)\n",
    "    cbar.ax.set_yticklabels(['-30', '0', '30'],fontsize=15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ad181a-9555-48b9-b362-f35f00fa96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exploreInjectionLocation_elevation(df, peak,maps, ops,eng):\n",
    "    \n",
    "    nShuffles =100\n",
    "    noArea_idx = np.nonzero(np.array(df['area']) == 'OUT')[0]\n",
    "    \n",
    "    badRoiPosition1 = np.nonzero(np.array(df['x']) ==0)[0]\n",
    "    badRoiPosition2 = np.nonzero(np.array(df['y']) ==0)[0]\n",
    "    badRoiPosition = np.unique(np.concatenate((badRoiPosition1,badRoiPosition2),0))\n",
    "    \n",
    "    noArea_idx = np.unique(np.concatenate((noArea_idx,badRoiPosition),0))\n",
    "           \n",
    "    elevPeak = getElevation_greenAud(df, maps, peak, onlyPeakSide = 1)\n",
    "    # contraIdx = np.nonzero(np.array(df_fit_1d_green_aud_full_elev['gaussian_peak']) > 6)[0]\n",
    "\n",
    "    includeIdx_green_elev = np.setdiff1d(np.arange(0,len(df)), noArea_idx)\n",
    "\n",
    "    df_green_elev = df.iloc[includeIdx_green_elev]\n",
    "    df_green_elev['elevPeak'] = elevPeak[includeIdx_green_elev]\n",
    "    \n",
    "    peak0 = elevPeak[includeIdx_green_elev]\n",
    "    df0= df_green_elev\n",
    "    \n",
    "    \n",
    "    animals_thisDataset = df0['animal'].unique()\n",
    "    \n",
    "    ventralAn = np.intersect1d(animals_thisDataset, ops['ventralAnimals'])        #[109,113,128,149,154,166,168]\n",
    "    dorsalAn = np.intersect1d(animals_thisDataset, ops['dorsalAnimals'])  #[107,112,131,132,151,153,170,171,178]\n",
    "   \n",
    "    anteriorAn = np.intersect1d(animals_thisDataset,ops['anteriorAnimals'])         #[113,128,151,154,170,178]\n",
    "    posteriorAn = np.intersect1d(animals_thisDataset,ops['posteriorAnimals'])     #[107,109,112,131,132,149,153,166,168,171]\n",
    "    \n",
    "    t = []\n",
    "    for i in range(len(df0)):\n",
    "        if df0['area'].iloc[i] in ops['dorsal']:\n",
    "            t.append('Dorsal')\n",
    "        elif df0['area'].iloc[i] in ops['ventral']:\n",
    "            t.append('Ventral')\n",
    "        elif df0['area'].iloc[i] == 'V1':\n",
    "            t.append('V1')\n",
    "        else:\n",
    "            t.append('')                        \n",
    "    df0['streamIdx'] = t\n",
    "    \n",
    "    animals = df0['animal'].unique()\n",
    "    post_idx = np.zeros(0,); ant_idx = np.zeros(0,)\n",
    "    dorsal_idx = np.zeros(0,); ventral_idx = np.zeros(0,)\n",
    "    post_idx_V1= np.zeros(0,); ant_idx_V1 = np.zeros(0,)\n",
    "    dorsal_idx_V1 = np.zeros(0,); ventral_idx_V1 = np.zeros(0,)\n",
    "    post_idx_dorsalStream= np.zeros(0,); ant_idx_dorsalStream = np.zeros(0,)\n",
    "    dorsal_idx_dorsalStream = np.zeros(0,); ventral_idx_dorsalStream = np.zeros(0,)\n",
    "    post_idx_ventralStream= np.zeros(0,); ant_idx_ventralStream = np.zeros(0,)\n",
    "    dorsal_idx_ventralStream = np.zeros(0,); ventral_idx_ventralStream = np.zeros(0,)\n",
    "    for a in range(len(animals)):\n",
    "        idx_this = np.nonzero(np.array(df0['animal']) == animals[a])[0]\n",
    "        \n",
    "        idx_V1 = np.nonzero(np.array(df0['streamIdx']) == 'V1')[0]\n",
    "        idx_ventral = np.nonzero(np.array(df0['streamIdx']) == 'Ventral')[0]\n",
    "        idx_dorsal = np.nonzero(np.array(df0['streamIdx']) == 'Dorsal')[0]\n",
    "\n",
    "        idx_this_V1 = np.intersect1d(idx_this,idx_V1)\n",
    "        idx_this_dorsal = np.intersect1d(idx_this,idx_dorsal)\n",
    "        idx_this_ventral = np.intersect1d(idx_this,idx_ventral)\n",
    "\n",
    "        if animals[a] in posteriorAn:\n",
    "            post_idx = np.concatenate((post_idx,idx_this),0)\n",
    "            post_idx_V1 = np.concatenate((post_idx_V1,idx_this_V1),0)\n",
    "            post_idx_dorsalStream = np.concatenate((post_idx_dorsalStream,idx_this_dorsal),0)\n",
    "            post_idx_ventralStream = np.concatenate((post_idx_ventralStream,idx_this_ventral),0)\n",
    "        elif animals[a] in anteriorAn:\n",
    "            ant_idx = np.concatenate((ant_idx,idx_this),0)\n",
    "            ant_idx_V1 = np.concatenate((ant_idx_V1,idx_this_V1),0)\n",
    "            ant_idx_dorsalStream = np.concatenate((ant_idx_dorsalStream,idx_this_dorsal),0)\n",
    "            ant_idx_ventralStream = np.concatenate((ant_idx_ventralStream,idx_this_ventral),0)\n",
    "                    \n",
    "        if animals[a] in ventralAn:\n",
    "            ventral_idx = np.concatenate((ventral_idx,idx_this),0)\n",
    "            ventral_idx_V1 = np.concatenate((ventral_idx_V1,idx_this_V1),0)\n",
    "            ventral_idx_dorsalStream = np.concatenate((ventral_idx_dorsalStream,idx_this_dorsal),0)\n",
    "            ventral_idx_ventralStream = np.concatenate((ventral_idx_ventralStream,idx_this_ventral),0)\n",
    "        elif animals[a] in dorsalAn:\n",
    "            dorsal_idx = np.concatenate((dorsal_idx,idx_this),0)\n",
    "            dorsal_idx_V1 = np.concatenate((dorsal_idx_V1,idx_this_V1),0)\n",
    "            dorsal_idx_dorsalStream = np.concatenate((dorsal_idx_dorsalStream,idx_this_dorsal),0)\n",
    "            dorsal_idx_ventralStream = np.concatenate((dorsal_idx_ventralStream,idx_this_ventral),0)\n",
    "    \n",
    "    #%%\n",
    "    peak_elev_bySession = []\n",
    "    sessionIdx= np.unique(np.array(df0['sessionIdx']))\n",
    "    for s in range(len(sessionIdx)):\n",
    "        idx_thisSession = np.nonzero(np.array(df0['sessionIdx']) == sessionIdx[s])[0]\n",
    "              \n",
    "      \n",
    "        peak_elev = peak0[idx_thisSession]\n",
    "        \n",
    "        if len(idx_thisSession) < 10:\n",
    "            peak_elev_bySession.append(np.nan)\n",
    "        else:\n",
    "            peak_elev_bySession.append(np.nanmean(peak_elev))\n",
    "        \n",
    "        sh = np.zeros((len(idx_thisSession), nShuffles))\n",
    "        for n in range(nShuffles):\n",
    "            idx = np.random.choice(np.arange(len(peak0)), len(idx_thisSession))\n",
    "            sh[:,n] = peak0[idx]\n",
    "       \n",
    "\n",
    "    sessionRef = makeSessionReference(df0)   \n",
    "    \n",
    "    nSessions = len(sessionRef['seshAnimal'])\n",
    "    dorsal_idx = np.nonzero(np.array([sessionRef['seshAnimal'][i] in dorsalAn for i in range(nSessions)]))[0]\n",
    "    ventral_idx = np.nonzero(np.array([sessionRef['seshAnimal'][i] in ventralAn for i in range(nSessions)]))[0]\n",
    "    posterior_idx = np.nonzero(np.array([sessionRef['seshAnimal'][i] in posteriorAn for i in range(nSessions)]))[0]\n",
    "    anterior_idx = np.nonzero(np.array([sessionRef['seshAnimal'][i] in anteriorAn for i in range(nSessions)]))[0]\n",
    "\n",
    "    v1_idx = np.nonzero(np.array([sessionRef['seshAreas'][i] =='V1' for i in range(nSessions)]))[0]\n",
    "    dorsalAreas_idx = np.nonzero(np.array([sessionRef['seshAreas'][i] in ops['dorsal'] for i in range(nSessions)]))[0]\n",
    "    ventralAreas_idx = np.nonzero(np.array([sessionRef['seshAreas'][i] in ops['ventral'] for i in range(nSessions)]))[0]\n",
    "\n",
    "    def excludeNans(data):\n",
    "        notNan = np.nonzero(np.isnan(data) < 0.5)[0]\n",
    "        return data[notNan]\n",
    "    \n",
    "    peak_elev_bySession = np.array(peak_elev_bySession)\n",
    "\n",
    "    bestElev_dorsalInj_all = excludeNans(peak_elev_bySession[dorsal_idx]); \n",
    "    bestElev_ventralInj_all = excludeNans(peak_elev_bySession[ventral_idx])\n",
    "    bestElev_anteriorInj_all = excludeNans(peak_elev_bySession[anterior_idx])\n",
    "    bestElev_posteriorInj_all = excludeNans(peak_elev_bySession[posterior_idx])\n",
    "    \n",
    "#     bestElev_dorsalInj_v1 = excludeNans(peak_elev_bySession[np.intersect1d(v1_idx, dorsal_idx)])\n",
    "#     bestElev_ventralInj_v1 = excludeNans(peak_elev_bySession[np.intersect1d(v1_idx, ventral_idx)])\n",
    "#     bestElev_anteriorInj_v1 = excludeNans(peak_elev_bySession[np.intersect1d(v1_idx, anterior_idx)])\n",
    "#     bestElev_posteriorInj_v1 = excludeNans(peak_elev_bySession[np.intersect1d(v1_idx, posterior_idx)])\n",
    "    \n",
    "#     bestElev_dorsalInj_dors = excludeNans(peak_elev_bySession[np.intersect1d(dorsalAreas_idx, dorsal_idx)])\n",
    "#     bestElev_ventralInj_dors = excludeNans(peak_elev_bySession[np.intersect1d(dorsalAreas_idx, ventral_idx)])\n",
    "#     bestElev_anteriorInj_dors = excludeNans(peak_elev_bySession[np.intersect1d(dorsalAreas_idx, anterior_idx)])\n",
    "#     bestElev_posteriorInj_dors = excludeNans(peak_elev_bySession[np.intersect1d(dorsalAreas_idx, posterior_idx)])\n",
    "    \n",
    "#     bestElev_dorsalInj_vent = excludeNans(peak_elev_bySession[np.intersect1d(ventralAreas_idx, dorsal_idx)])\n",
    "#     bestElev_ventralInj_vent = excludeNans(peak_elev_bySession[np.intersect1d(ventralAreas_idx, ventral_idx)])\n",
    "#     bestElev_anteriorInj_vent = excludeNans(peak_elev_bySession[np.intersect1d(ventralAreas_idx, anterior_idx)])\n",
    "#     bestElev_posteriorInj_vent = excludeNans(peak_elev_bySession[np.intersect1d(ventralAreas_idx, posterior_idx)])\n",
    "    \n",
    "    #%%\n",
    "    color_anterior = 'blue'\n",
    "    color_posterior = 'red'\n",
    "    color_dorsal = 'green'\n",
    "    color_ventral = 'darkorange'\n",
    "    \n",
    "    #%% for paper, just all\n",
    "    fig = plt.figure(figsize=(ops['mm']*29,ops['mm']*31), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    #all\n",
    "    xVals_scatter = np.random.normal(loc =0,scale =0.05,size = len(bestElev_ventralInj_all)) \n",
    "    plt.plot([-0.25,+0.25], [np.nanmedian(bestElev_ventralInj_all),np.nanmedian(bestElev_ventralInj_all)], linewidth = 2, c = color_ventral,alpha=1,zorder = 2)\n",
    "    plt.scatter(xVals_scatter, np.array(bestElev_ventralInj_all), s = 10, facecolors ='white' , edgecolor = color_ventral,zorder = 1,linewidth=0.5, alpha =0.3)\n",
    "    xVals_scatter = np.random.normal(loc =1,scale =0.05,size = len(bestElev_dorsalInj_all)) \n",
    "    plt.plot([1-0.25,1+0.25], [np.nanmedian(bestElev_dorsalInj_all),np.nanmedian(bestElev_dorsalInj_all)], linewidth = 2, c = color_dorsal,alpha=1,zorder = 2)\n",
    "    plt.scatter(xVals_scatter, np.array(bestElev_dorsalInj_all), s = 10, facecolors ='white' , edgecolor = color_dorsal,zorder = 1,linewidth=0.5, alpha =0.3)\n",
    "    U, p = stats.mannwhitneyu(bestElev_dorsalInj_all, bestElev_ventralInj_all)\n",
    "    plt.text(0.3, 3.5, 'p=' + str(np.round(p,3)), fontsize=6)\n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best sound elevation (\\u00b0)', '', '', mySize=6)\n",
    "    plt.xticks([0,1], ['Ventral', 'Dorsal'])\n",
    "    plt.ylim([0.888888, 3.66666])\n",
    "    plt.yticks([2-(20/18),2-(10/18),2, 2 + (10/18), 2+(20/18), 2+(30/18)], ['-20', '-10', '0', '10', '20', '30'])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1) \n",
    "    fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\bestElevation_DV_medians.svg'))\n",
    "\n",
    "    \n",
    "    fig = plt.figure(figsize=(ops['mm']*29,ops['mm']*31), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    #all\n",
    "    xVals_scatter = np.random.normal(loc =0,scale =0.05,size = len(bestElev_posteriorInj_all)) \n",
    "    plt.plot([0-0.25,0+0.25], [np.nanmedian(bestElev_posteriorInj_all),np.nanmedian(bestElev_posteriorInj_all)], linewidth = 2, c = color_posterior,alpha=1,zorder = 2)\n",
    "    plt.scatter(xVals_scatter, np.array(bestElev_posteriorInj_all), s = 10, facecolors ='white' , edgecolor = color_posterior,zorder = 1,linewidth=0.5, alpha =0.3)\n",
    "    xVals_scatter = np.random.normal(loc =1,scale =0.05,size = len(bestElev_anteriorInj_all)) \n",
    "    plt.plot([1-0.25,1+0.25], [np.nanmedian(bestElev_anteriorInj_all),np.nanmedian(bestElev_anteriorInj_all)], linewidth = 2, c = color_anterior,alpha=1,zorder = 2)\n",
    "    plt.scatter(xVals_scatter, np.array(bestElev_anteriorInj_all), s = 10, facecolors ='white' , edgecolor = color_anterior,zorder = 1,linewidth=0.5, alpha =0.3)\n",
    "    U, p = stats.mannwhitneyu(bestElev_anteriorInj_all, bestElev_posteriorInj_all)\n",
    "    plt.text(0.3, 3.5, 'p=' + str(np.round(p,3)), fontsize=6)\n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best sound elevation (\\u00b0)', '', '', mySize=6)\n",
    "    plt.xticks([0,1], ['Posterior', 'Anterior'])\n",
    "    plt.ylim([0.888888, 3.66666])\n",
    "    plt.yticks([2-(20/18),2-(10/18),2, 2 + (10/18), 2+(20/18), 2+(30/18)], ['-20', '-10', '0', '10', '20', '30'])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1) \n",
    "    fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\bestElevation_AP_medians.svg'))\n",
    "\n",
    "    #%% scatter against position\n",
    "    \n",
    "    notOut = np.nonzero(np.array(sessionRef['seshAreas']) != 'OUT')[0]\n",
    "    notNan = np.nonzero(np.isnan(np.array(peak_elev_bySession)) <0.5)[0]\n",
    "    these = np.intersect1d(notOut,notNan)\n",
    "    df_forTest = pd.DataFrame({'peakElev': np.array(peak_elev_bySession)[these],\n",
    "                               'area': np.array(sessionRef['seshAreas'])[these], \n",
    "                               'animal':  np.array(sessionRef['seshAnimal'])[these], \n",
    "                               'Inj_DV': np.array(sessionRef['pos_DV'])[these],\n",
    "                               'Inj_AP': np.array(sessionRef['pos_AP'])[these],\n",
    "                               'prop_ventral': np.array(sessionRef['prop_ventral'])[these]})\n",
    "            \n",
    "    df_forTest['Inj_DV'] = df_forTest['Inj_DV'] - min(df_forTest['Inj_DV'])  \n",
    "    df_forTest['Inj_AP'] = abs(df_forTest['Inj_AP'] - max(df_forTest['Inj_AP'])) \n",
    "\n",
    "    df_path= os.path.join(ops['outputPath'],'df_forLMM.csv')\n",
    "    df_forTest.to_csv(df_path)\n",
    "    formula = 'peakElev ~ 1 + Inj_DV + (1|animal)'\n",
    "    # formula = 'meanElevs_green ~ 1 + fitElevs_red + (1|animal)'\n",
    "\n",
    "    savePath = os.path.join(ops['outputPath'], 'LMM_green.mat')\n",
    "    \n",
    "    res, fitLines, fitCI = eng.linearMixedModel_fromPython(df_path, formula,savePath, nargout=3) \n",
    "\n",
    "    mat_file = scipy.io.loadmat(savePath)   \n",
    "    res = getDict_fromMatlabStruct(mat_file, 'res')\n",
    "    \n",
    "    intercept = res['Intercept'][0][0] # from matlab LMM \n",
    "    slope = res['Inj_DV'][0][0]\n",
    "    slope_p = res['Inj_DV'][0][1]\n",
    "    xVals = np.arange(0,max(df_forTest['Inj_DV']),1)\n",
    "    yVals = intercept + slope*xVals\n",
    "     \n",
    "    r_spearman,p_spearman = scipy.stats.spearmanr(df_forTest['Inj_DV'], df_forTest['peakElev'])\n",
    "\n",
    "    #\n",
    "    #this is the nice one\n",
    "    fig = plt.figure(figsize =(ops['mm']*36,ops['mm']*35), constrained_layout = True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.scatter(np.array(df_forTest['Inj_DV']), np.array(df_forTest['peakElev']), c= 'k', s =1)\n",
    "    x_axis = 'Inj_DV'\n",
    "    fitLine = np.array(fitLines[x_axis])\n",
    "    fitLine_down = np.array(fitCI[x_axis])[:,0]\n",
    "    fitLine_up = np.array(fitCI[x_axis])[:,1]\n",
    "    xVals = np.linspace(min(df_forTest[x_axis]), max(df_forTest[x_axis]), len(fitLine))\n",
    "    plt.fill_between(xVals, fitLine_up, fitLine_down, facecolor = 'gray',alpha = 0.3)\n",
    "    plt.plot(xVals, fitLine, c = 'k', linewidth = 1, linestyle ='dashed') \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best sound elevation (\\u00b0)', 'Injection centre position (\\u03BCm)','', mySize=6)\n",
    "    plt.text(70,3.1,'r: ' + str(np.round(r_spearman,4)) + '\\np: ' + str(np.round(p_spearman,4)))\n",
    "    plt.xticks([0,40,80,120], ['0', '400', '800', '1200'])\n",
    "    # plt.yticks([0,0.2, 0.4, 0.6, 0.8],['0','20','40','60','80'])\n",
    "    ax.tick_params(axis='y', pad=1)  \n",
    "    ax.tick_params(axis='x', pad=1) \n",
    "    plt.ylim([0.888888, 3.66666])\n",
    "    plt.yticks([2-(20/18),2-(10/18),2, 2 + (10/18), 2+(20/18), 2+(30/18)], ['-20', '-10', '0', '10', '20', '30'])\n",
    "        \n",
    "    fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\peakElev_bySession_againstDV_pos.svg'))\n",
    "\n",
    "    \n",
    "    formula = 'peakElev ~ 1 + Inj_AP + (1|animal)'\n",
    "    # formula = 'meanElevs_green ~ 1 + fitElevs_red + (1|animal)'\n",
    "\n",
    "    savePath = os.path.join(ops['outputPath'], 'LMM_green.mat')\n",
    "    \n",
    "    res, fitLines, fitCI = eng.linearMixedModel_fromPython(df_path, formula,savePath, nargout=3) \n",
    "\n",
    "    mat_file = scipy.io.loadmat(savePath)   \n",
    "    res = getDict_fromMatlabStruct(mat_file, 'res')\n",
    "    \n",
    "    intercept = res['Intercept'][0][0] # from matlab LMM \n",
    "    slope = res['Inj_AP'][0][0]\n",
    "    slope_p = res['Inj_AP'][0][1]\n",
    "    xVals = np.arange(0,max(df_forTest['Inj_AP']),1)\n",
    "    yVals = intercept + slope*xVals\n",
    "     \n",
    "    r_spearman,p_spearman = scipy.stats.spearmanr(df_forTest['Inj_AP'], df_forTest['peakElev'])\n",
    "\n",
    "    #\n",
    "    #this is the nice one\n",
    "    fig = plt.figure(figsize =(ops['mm']*36,ops['mm']*35), constrained_layout = True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.scatter(np.array(df_forTest['Inj_AP']), np.array(df_forTest['peakElev']), c= 'k', s =1)\n",
    "    x_axis = 'Inj_AP'\n",
    "    fitLine = np.array(fitLines[x_axis])\n",
    "    fitLine_down = np.array(fitCI[x_axis])[:,0]\n",
    "    fitLine_up = np.array(fitCI[x_axis])[:,1]\n",
    "    xVals = np.linspace(min(df_forTest[x_axis]), max(df_forTest[x_axis]), len(fitLine))\n",
    "    plt.fill_between(xVals, fitLine_up, fitLine_down, facecolor = 'gray',alpha = 0.3)\n",
    "    plt.plot(xVals, fitLine, c = 'k', linewidth = 1, linestyle ='dashed') \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best sound elevation (\\u00b0)', 'Injection centre position (\\u03BCm)','', mySize=6)\n",
    "    plt.text(1,3.1,'r: ' + str(np.round(r_spearman,4)) + '\\np: ' + str(np.round(p_spearman,4)))\n",
    "    plt.xticks([0,50,100], ['0', '500', '1000'])\n",
    "    # plt.yticks([0,0.2, 0.4, 0.6, 0.8],['0','20','40','60','80'])\n",
    "    ax.tick_params(axis='y', pad=1)  \n",
    "    ax.tick_params(axis='x', pad=1) \n",
    "    plt.ylim([0.888888, 3.66666])\n",
    "    plt.yticks([2-(20/18),2-(10/18),2, 2 + (10/18), 2+(20/18), 2+(30/18)], ['-20', '-10', '0', '10', '20', '30'])\n",
    "        \n",
    "    fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\peakElev_bySession_againstAP_pos.svg'))\n",
    " \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273ed9b8-d3c0-4a46-97e1-caaa6b79c27c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAzimuthDistance(df,peak,gaussFit, df_red, ops, eng,nShuffles=100):\n",
    "         \n",
    "    contraIdx = np.nonzero(peak > 6)[0]\n",
    "    idx = np.intersect1d(gaussFit, contraIdx)\n",
    "    \n",
    "    outOnes = np.nonzero(np.array(df['area']) == 'OUT')[0]\n",
    "    inOnes = np.setdiff1d(np.arange(0, len(df)), outOnes)\n",
    "    \n",
    "    idx0 = np.intersect1d(idx,inOnes)\n",
    "    \n",
    "    \n",
    "    data0 = peak[idx0] -6\n",
    "    df0 = df.iloc[idx0]\n",
    "    \n",
    "    \n",
    "    data1 = np.array(df_red['aziPeak'])  #flip it around so that max is top led location\n",
    "    peakAzi_byArea_red = []\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        idx_thisArea = np.nonzero(np.array(df_red['area']) == ops['areas'][ar])[0]\n",
    "        \n",
    "        azi_thisArea = df_red.iloc[idx_thisArea]['aziPeak']\n",
    "    \n",
    "        peakAzi_byArea_red.append(np.nanmean(azi_thisArea))\n",
    "        \n",
    "    #get grean peak by session   \n",
    "    #green\n",
    "    aziShuffle = np.random.choice(np.arange(len(data0)), 100)\n",
    "    peak_azi_bySession = []\n",
    "    peak_azi_bySession_sh = []\n",
    "    sessionIdx= np.unique(np.array(df0['sessionIdx']))\n",
    "    for s in range(len(sessionIdx)):\n",
    "        idx_thisSession = np.nonzero(np.array(df0['sessionIdx']) == sessionIdx[s])[0]\n",
    "              \n",
    "      \n",
    "        peak_azi = data0[idx_thisSession]\n",
    "        \n",
    "        if len(idx_thisSession) < 10:\n",
    "            peak_azi_bySession.append(np.nan)\n",
    "        else:\n",
    "\n",
    "            peak_azi_bySession.append(np.nanmean(peak_azi))\n",
    "        \n",
    "        sh = np.zeros((len(idx_thisSession), nShuffles))\n",
    "        for n in range(nShuffles):\n",
    "            idx = np.random.choice(np.arange(len(data0)), len(idx_thisSession))\n",
    "            sh[:,n] = data0[idx]\n",
    "        \n",
    "        peak_azi_bySession_sh.append(sh)\n",
    "      \n",
    "    sessionRef = makeSessionReference(df0)\n",
    "    # peak_azi_bySession = np.array(peak_azi_bySession)\n",
    "    #alternative shuffling: \n",
    "    aziShuffles_green_all = []\n",
    "    for n in range(1000):\n",
    "        aziShuffle = np.random.choice(np.arange(len(data0)), 100)\n",
    "        aziShuffles_green_all.append(data0[aziShuffle])\n",
    "    \n",
    "    \n",
    "    peakAzi_byArea = []\n",
    "    peakAzi_byArea_sh = []\n",
    "\n",
    "    for ar in range(len(ops['areas'])):  \n",
    "        idx = np.nonzero(np.array(sessionRef['seshAreas']) == ops['areas'][ar])[0]\n",
    "        \n",
    "        peak_bySession_this = np.array([peak_azi_bySession[idx[i]] for i in range(len(idx))])\n",
    "        peak_bySession_this_clean = peak_bySession_this[np.nonzero(np.isnan(peak_bySession_this) < 0.5)[0]]\n",
    "\n",
    "        peakAzi_byArea.append(peak_bySession_this_clean)\n",
    "        \n",
    "        peak_bySession_this_sh = np.array([peak_azi_bySession_sh[idx[i]] for i in range(len(idx))])\n",
    "        # peak_bySession_this_clean = peak_bySession_this_sh[np.nonzero(np.isnan(peak_bySession_this_sh) < 0.5)[0]]\n",
    "\n",
    "        peakAzi_byArea_sh.append(peak_bySession_this_sh)\n",
    "    \n",
    "    # median_azi1 = [np.array([np.nanmedian(peakAzi_byArea[ar][i]) for i in range(len(peakAzi_byArea[ar]))]) for ar in range(len(areas))]\n",
    "    \n",
    "    notV1 = np.nonzero(np.array(sessionRef['seshAreas']) != 'V1')[0]\n",
    "    notNan = np.nonzero(np.isnan(np.array(peak_azi_bySession)) <0.5)[0]\n",
    "    # thisIdx =notNan\n",
    "    thisIdx = np.intersect1d(notV1,notNan)\n",
    "    # seshMapGood = np.nonzero(np.array(sessionRef['seshMapGood']) == 1)[0]\n",
    "    # thisIdx = np.intersect1d(thisIdx, seshMapGood)\n",
    "\n",
    "    df_forTest = pd.DataFrame({'peakAzi_bySession': np.array(peak_azi_bySession)[thisIdx],                                    \n",
    "                            'area': np.array(sessionRef['seshAreas'])[thisIdx],\n",
    "                            'stream': np.array(sessionRef['seshStream'])[thisIdx],\n",
    "                            'azi': np.array(sessionRef['seshAzi'])[thisIdx],\n",
    "                            'animal':  np.array(sessionRef['seshAnimal'])[thisIdx]})\n",
    "    \n",
    "    df_path = os.path.join(ops['outputPath'], 'df_forTest.csv')\n",
    "\n",
    "    df_forTest.to_csv(df_path)\n",
    "\n",
    "\n",
    "    formula = 'peakAzi_bySession ~ area + (1|animal)'                 \n",
    "    p_LMM = eng.linearMixedModel_fromPython_anova(df_path, formula, nargout=1)\n",
    "    \n",
    "    \n",
    "    formula = 'peakAzi_bySession ~ azi + (1|animal)'                 \n",
    "    savePath = os.path.join(ops['outputPath'], 'LMM_green_aud.mat')\n",
    "     \n",
    "     #run LMM and load results\n",
    "    res, fitLines, fitCI = eng.linearMixedModel_fromPython(df_path, formula,savePath, nargout=3) \n",
    "      \n",
    "    mat_file = scipy.io.loadmat(savePath)   \n",
    "    res = getDict_fromMatlabStruct(mat_file, 'res')\n",
    "\n",
    "\n",
    "    #Now same for red\n",
    "    peak_azi_bySession_red = []\n",
    "  \n",
    "    sessionIdx= np.unique(np.array(df_red['sessionIdx']))\n",
    "    for s in range(len(sessionIdx)):\n",
    "        idx_thisSession = np.nonzero(np.array(df_red['sessionIdx']) == sessionIdx[s])[0]\n",
    "              \n",
    "        peak_azi = data1[idx_thisSession]\n",
    "        \n",
    "        peak_azi_bySession_red.append(np.nanmedian(peak_azi))\n",
    "           \n",
    "    sessionRef = makeSessionReference(df_red)\n",
    "    peak_azi_bySession_red = np.array(peak_azi_bySession_red)\n",
    "    \n",
    "    peakAzi_byArea_red = []\n",
    "    for ar in range(len(ops['areas'])):  \n",
    "        idx = np.nonzero(np.array(sessionRef['seshAreas']) == ops['areas'][ar])[0]\n",
    "        \n",
    "        peak_bySession_this = peak_azi_bySession_red[idx]\n",
    "        # notNan = np.nonzero(np.isnan(np.array(peak_bySession_this)) <0.5)[0]\n",
    "        \n",
    "        peak_bySession_this_clean = peak_bySession_this[np.nonzero(np.isnan(peak_bySession_this) < 0.5)[0]]\n",
    "\n",
    "        peakAzi_byArea_red.append(peak_bySession_this_clean)\n",
    "            \n",
    "    notV1 = np.nonzero(np.array(sessionRef['seshAreas']) != 'V1')[0]\n",
    "    notNan = np.nonzero(np.isnan(np.array(peak_azi_bySession_red)) <0.5)[0]\n",
    "    thisIdx =notNan\n",
    "    thisIdx = np.intersect1d(notV1,notNan)\n",
    "\n",
    "    df_forTest = pd.DataFrame({'peakAzi_bySession': np.array(peak_azi_bySession_red)[thisIdx],                                    \n",
    "                            'area': np.array(sessionRef['seshAreas'])[thisIdx],\n",
    "                            'stream': np.array(sessionRef['seshStream'])[thisIdx],\n",
    "                            'animal':  np.array(sessionRef['seshAnimal'])[thisIdx]})\n",
    "    \n",
    "    df_path = os.path.join(ops['outputPath'], 'df_forTest.csv')\n",
    "\n",
    "    df_forTest.to_csv(df_path)\n",
    "\n",
    "\n",
    "    formula = 'peakAzi_bySession ~ area + (1|animal)'                 \n",
    "    p_LMM = eng.linearMixedModel_fromPython_anova(df_path, formula, nargout=1)\n",
    "    # t, p_kruskal = stats.kruskal(*peakAzi_byArea_red[1::], nan_policy ='omit')\n",
    "    #%%\n",
    "    fig = plt.figure(figsize=(ops['mm']*80, ops['mm']*80), constrained_layout =True)\n",
    "    \n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        median_azi = np.nanmean(peakAzi_byArea_red[ar])\n",
    "        \n",
    "        plt.plot([ar-0.3, ar+0.3], [median_azi,median_azi] , linewidth = 2, c = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],zorder = 2)\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.05,size = len(peakAzi_byArea_red[ar])) \n",
    "        plt.scatter(xVals_scatter, np.array(peakAzi_byArea_red[ar]), s = 10, facecolors = 'white' , edgecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]], linewidths =0.5,alpha=0.3,zorder = 1)\n",
    "        \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best visual azimuth (deg)', '', str(p_LMM), mySize=15)\n",
    "    plt.xticks(np.arange(0, len(ops['areas'])), ops['areas'], rotation =90)\n",
    "    plt.yticks([0,2,4,6], ['0', '36', '72', '108'])\n",
    "    plt.ylim([-0.1,6.2])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "\n",
    "    # fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\azimuthByArea_red.svg'))\n",
    "#\n",
    "    # if p_LMM < 0.05:\n",
    "    #     p_mannWhitney, compIdx = doMannWhitneyU_forBoxplots(peakElev_byArea_red, multiComp = 'hs')\n",
    "    #     cnt = 0\n",
    "    #     for c in range(len(compIdx)):\n",
    "    #         if p_mannWhitney[c] < 0.05:\n",
    "    #             pos = compIdx[c].split('_')\n",
    "    #             plt.hlines(3.7+cnt, int(pos[0]), int(pos[1]), color = 'k', linewidth =0.5)\n",
    "    #             cnt += 0.05\n",
    "    #%%\n",
    "    ##% Distance between green and red\n",
    "    fig = plt.figure(figsize=(ops['mm']*80, ops['mm']*80), constrained_layout =True)\n",
    "    # fig = plt.figure(figsize=(self.mm*50, self.mm*50), constrained_layout =True)\n",
    "\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    for ar in range(1,len(ops['areas'])):\n",
    "        median_red = np.nanmedian(peakAzi_byArea_red[ar])\n",
    "        \n",
    "        vals_thisArea = peakAzi_byArea[ar]\n",
    "        \n",
    "        notNan = np.nonzero(np.isnan(np.array(vals_thisArea)) <0.5)[0]\n",
    "        vals_thisArea = np.array(vals_thisArea)[notNan]\n",
    "        \n",
    "        \n",
    "        distance = [np.median(abs(vals_thisArea[i] - median_red)) for i in range(len(vals_thisArea))]\n",
    "        median_distance = np.nanmedian(distance)\n",
    "        \n",
    "        distances_sh = []\n",
    "        for i in range(len(aziShuffles_green_all)):\n",
    "            distances_sh.append(np.nanmedian(abs(aziShuffles_green_all[i] - median_red)))\n",
    "        \n",
    "        upper = np.percentile(np.array(distances_sh), 95)\n",
    "        lower = np.percentile(np.array(distances_sh), 5)\n",
    "\n",
    "        vals_thisArea_sh = peakAzi_byArea_sh[ar]\n",
    "        vals_sh = []\n",
    "        for i in range(len(vals_thisArea_sh)):\n",
    "            vals_sh.append(np.median([abs(vals_thisArea_sh[i][:,n] - median_red) for n in range(nShuffles)]))\n",
    "                    \n",
    "        vals_sh = np.array(vals_sh)[notNan]\n",
    "        median_sh = np.nanmedian(np.array(vals_sh))\n",
    "        \n",
    "        # plt.plot([ar-0.3, ar+0.3], [lower, lower], linestyle ='dashed', c = 'k')\n",
    "        # plt.plot([ar-0.3, ar+0.3], [upper, upper], linestyle ='dashed', c = 'k')\n",
    "\n",
    "        plt.plot([ar-0.25, ar+0.25], [median_distance,median_distance] , linewidth = 2, c = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],zorder = 2)\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.05,size = len(distance)) \n",
    "        plt.scatter(xVals_scatter, np.array(distance), s = 10, facecolors = 'white' , edgecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]], linewidths =0.5,alpha=0.3,zorder = 1)\n",
    "        \n",
    "        plt.plot([ar-0.25, ar+0.25], [median_sh,median_sh] , linewidth = 2, c = 'silver',zorder = 2)\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.05,size = len(distance)) \n",
    "        # plt.scatter(xVals_scatter, np.array(vals_sh), s = 5, facecolors = 'white' , edgecolors = 'lightgray', linewidths =0.5,zorder = 1)\n",
    "        \n",
    "        U,p = stats.mannwhitneyu(distance, vals_sh)\n",
    "        adj_p = statsmodels.stats.multitest.multipletests(np.repeat(p,9), method='fdr_bh')[1][0]\n",
    "        # print(str(p))\n",
    "        \n",
    "        if adj_p < 0.05 and adj_p > 0.01:\n",
    "            plt.text(ar-0.2, 2, '*', fontsize=15)\n",
    "        elif adj_p < 0.01 and adj_p > 0.001:\n",
    "             plt.text(ar-0.2, 2, '**', fontsize=15)\n",
    "        elif adj_p < 0.001:\n",
    "             plt.text(ar-0.2, 2, '***', fontsize=15)\n",
    "             \n",
    "        \n",
    "          \n",
    "        \n",
    "        \n",
    "        \n",
    "        # distance_sh = abs(peak_areaShuffle[ar,:] - median_red)\n",
    "        # upper = np.percentile(distance_sh, 97.5)\n",
    "        # lower = np.percentile(distance_sh, 2.5)\n",
    "        \n",
    "        # plt.fill_between([ar-0.3,ar+0.3],[lower, lower], [upper,upper], color= 'gray', alpha = 0.2)\n",
    "        # # plt.hlines(pVals_ks[ar], ar - 0.3,ar + 0.3, color = 'r', label='real')            \n",
    "        # plt.hlines(lower,ar-0.3,ar+0.3, linewidth = 0.5, color = self.myColorsDict['color_gray_dashedline'],zorder =0)      \n",
    "        # plt.hlines(upper,ar-0.3,ar+0.3, linewidth = 0.5, color = self.myColorsDict['color_gray_dashedline'],zorder =0) \n",
    "        \n",
    "        \n",
    "    # myPlotSettings_splitAxis(fig,ax, 'Azimuth distance (\\u00B0)', '', '',mySize=6)\n",
    "    myPlotSettings_splitAxis(fig,ax, 'Azimuth distance (deg)', '', '',mySize=15)\n",
    "    plt.xticks(np.arange(1,len(ops['areas'])), ops['areas'][1::], rotation =90, fontsize=15)\n",
    "    deg_per_N = 18\n",
    "    yPos = np.array([0,35,70])\n",
    "    yPos0 = yPos/deg_per_N\n",
    "    plt.yticks(yPos0, ['0', '35', '70'])\n",
    "    # plt.ylim([-0.1, 3.9])\n",
    "    plt.ylim([-0.1, yPos0[-1]])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_fontsize(5) \n",
    "\n",
    "    # fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\azimuthDistance_byArea.svg'))\n",
    "\n",
    "   \n",
    "    #%%\n",
    "#     fig = plt.figure(figsize=(ops['mm']*80, ops['mm']*80), constrained_layout =True)\n",
    "#     ax = fig.add_subplot(1,1,1)\n",
    "#     vals_red, vals_green = [],[]\n",
    "#     for ar in range(1,len(ops['areas'])):\n",
    "#         median_red = np.nanmedian(peakAzi_byArea_red[ar])\n",
    "#         # print(str(median_red))\n",
    "#         vals_thisArea = peakAzi_byArea[ar]\n",
    "        \n",
    "#         notNan = np.nonzero(np.isnan(np.array(vals_thisArea)) <0.5)[0]\n",
    "#         vals_thisArea = np.array(vals_thisArea)[notNan]\n",
    "       \n",
    "#         plt.scatter(np.repeat(median_red,len(vals_thisArea)), vals_thisArea, s = 3, facecolors = 'white' , edgecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]], linewidths =0.25,alpha=0.9, zorder = 1)\n",
    "#         plt.scatter(median_red, np.median(vals_thisArea), s = 5, facecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]], edgecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]], linewidths =1,zorder = 2)\n",
    "    \n",
    "#         vals_green.append(np.median(vals_thisArea))\n",
    "#         vals_red.append(median_red)\n",
    "\n",
    "#         # if ar ==1:\n",
    "#         #     vals_green= vals_thisArea         \n",
    "#         #     vals_red= np.repeat(median_red,len(vals_thisArea))\n",
    "#         # else:\n",
    "#         #     vals_green= np.concatenate((vals_green, vals_thisArea),0)       \n",
    "#         #     vals_red= np.concatenate((vals_red, np.repeat(median_red,len(vals_thisArea))),0)       \n",
    "#     vals_red = np.array(vals_red)\n",
    "#     vals_green = np.array(vals_green)\n",
    "\n",
    "#     df_forTest = pd.DataFrame({'median_green': vals_green, \n",
    "#                                'median_red': vals_red})\n",
    "\n",
    "#     formula = 'median_green~ median_red'\n",
    "\n",
    "#     df_path= os.path.join(ops['outputPath'],'df_bySession_green_freq_forLMM.csv')\n",
    "#     df_forTest.to_csv(df_path)\n",
    "    \n",
    "#     savePath = os.path.join(ops['outputPath'], 'LMM_freq_green_aud.mat')\n",
    "    \n",
    "    #run LMM and load results\n",
    "#     res, fitLines, fitCI = eng.linearMixedModel_fromPython(df_path, formula,savePath, nargout=3) \n",
    "\n",
    "#     mat_file = scipy.io.loadmat(savePath)   \n",
    "#     res = getDict_fromMatlabStruct(mat_file, 'res')\n",
    "\n",
    "#     lm = doLinearRegression(vals_red, vals_green)\n",
    "#     x_axis = 'median_red'\n",
    "#     fitLine = np.array(fitLines[x_axis])\n",
    "#     fitLine_down = np.array(fitCI[x_axis])[:,0]\n",
    "#     fitLine_up = np.array(fitCI[x_axis])[:,1]\n",
    "#     xVals = np.linspace(min(df_forTest[x_axis]), max(df_forTest[x_axis]), len(fitLine))   \n",
    "#     plt.fill_between(xVals, fitLine_up, fitLine_down, facecolor = 'silver',alpha = 0.3)\n",
    "#     plt.plot(xVals, fitLine, c = 'k',linestyle='dashed',linewidth = 0.5)\n",
    "\n",
    "\n",
    "#     myPlotSettings_splitAxis(fig, ax, '', '', '',mySize=6)\n",
    "#     plt.yticks([20/18,60/18,100/18], ['20', '60', '100'])\n",
    "#     plt.ylim([20/18,100/18])\n",
    "#     plt.xticks([20/18,60/18,100/18], ['20', '60', '100'])\n",
    "#     plt.xlim([20/18,100/18])\n",
    "#     plt.plot([0,6],[0,6], color='gray', linewidth=0.25)\n",
    "#     # plt.plot(lm['x_vals'], lm['y_vals'], c = 'b')\n",
    "#     plt.text(20/18,5, 'r: ' + str(np.round(lm['corr'],3)) + '\\np: ' + str(np.round(res[x_axis][0][1],3)), fontsize=5)\n",
    "#     ax.tick_params(axis='y', pad=1)   \n",
    "#     ax.tick_params(axis='x', pad=1)   \n",
    "\n",
    "    # fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\azimuthCorrelation_byArea.svg'))\n",
    "    \n",
    "    #%%\n",
    "    # return vals_green, vals_red"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "259c1394-218b-4513-8b2d-50fa22c4c4d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotAzimuth_acrossMod_matchedFOV(df,peak,gaussFit, df_red,ops,eng):\n",
    "    \n",
    "    outOnes = np.nonzero(np.array(df['area']) == 'OUT')[0]\n",
    "    inOnes = np.setdiff1d(np.arange(0, len(df)), outOnes)\n",
    "    \n",
    "    idx0 = np.intersect1d(inOnes,gaussFit)\n",
    "    \n",
    "    contraIdx = np.nonzero(peak >= 6)[0]\n",
    "    idx = np.intersect1d(idx0,contraIdx)\n",
    "    \n",
    "    df_green = df.iloc[idx]\n",
    "    peak_green = peak[idx]\n",
    "    df_green['aziPeak_fit'] = peak_green-6\n",
    "    \n",
    "    outOnes = np.nonzero(np.array(df_red['area']) == 'OUT')[0]\n",
    "    inOnes = np.setdiff1d(np.arange(0, len(df_red)), outOnes)\n",
    "    \n",
    "    df_red = df_red.iloc[inOnes]\n",
    "    \n",
    "    sessionRef_0 = makeSessionReference(df_green)\n",
    "    sessionRef_1 = makeSessionReference(df_red)\n",
    "    \n",
    "    df_red['aziPeak_fit'] = df_red['aziPeak']\n",
    "    df_red['elevPeak_fit'] = abs(df_red['elevPeak'] - max(df_red['elevPeak'])) #inverting it for plotting purposes\n",
    "\n",
    "    #first do azimuth only\n",
    "    sessionRef_0 = makeSessionReference(df_green)\n",
    "    sessionRef_1 = makeSessionReference(df_red)\n",
    "    \n",
    "    sessionIdx_0 = np.unique(np.array(df_green['sessionIdx']))\n",
    "    sessionIdx_1 = np.unique(np.array(df_red['sessionIdx']))\n",
    "    commonOnes = np.intersect1d(sessionIdx_0,sessionIdx_1)\n",
    "    \n",
    "    seshAreas_common = []\n",
    "    for i in range(len(commonOnes)):\n",
    "        rel_idx = np.nonzero(sessionRef_0['seshIdx'] == commonOnes[i])[0]      \n",
    "        seshAreas_common.append(sessionRef_0['seshAreas'][rel_idx[0]])\n",
    "\n",
    "    areas_green, fitAzis_green,areas_red, fitAzis_red,fitElevs_red, sessionIdx, animal_g= [],[],[],[],[],[],[]\n",
    "    sessionX, sessionY, sessionElev, sessionAzi = [], [], [], []\n",
    "    for s in range(len(commonOnes)):  \n",
    "        sessionIdx.append(commonOnes[s])\n",
    "\n",
    "        #green\n",
    "        idx_thisSession_g = np.nonzero(np.array(df_green['sessionIdx']) == commonOnes[s])[0]\n",
    "        \n",
    "        df_green_this = df_green.iloc[idx_thisSession_g]\n",
    "        \n",
    "        fitAzis_green.append(np.nanmedian(np.array(df_green_this['aziPeak_fit'])))\n",
    "        \n",
    "        # idx_thisSession_g0 = np.nonzero(np.array(df_green_elev['sessionIdx']) == commonOnes_a1[s])[0]\n",
    "        \n",
    "        # df_green_this = df_green_elev.iloc[idx_thisSession_g0]\n",
    "        \n",
    "        # meanElevs_green.append(np.nanmean(np.array(df_green_this['elevPeak'])))\n",
    "\n",
    "        theseAreas = np.array(df_green_this['area'])\n",
    "        areas1, counts = np.unique(theseAreas, return_counts=True)\n",
    "                   \n",
    "        if len(areas1) > 0:   \n",
    "            areas_green.append(areas1[np.argmax(counts)])                   \n",
    "        else:\n",
    "            areas_green.append('OUT')\n",
    "            \n",
    "        animal_g.append(np.array(df_green_this['animal'])[0])\n",
    "        if s ==0:\n",
    "            df_green_commonOnes_a1 = df_green_this\n",
    "        else:\n",
    "            df_green_commonOnes_a1 = pd.concat([df_green_commonOnes_a1, df_green_this])\n",
    "        \n",
    "        #red\n",
    "        idx_thisSession_r = np.nonzero(np.array(df_red['sessionIdx']) == commonOnes[s])[0]\n",
    "        \n",
    "        df_red_this = df_red.iloc[idx_thisSession_r]\n",
    "        \n",
    "        fitAzis_red.append(np.nanmedian(np.array(df_red_this['aziPeak_fit'])))\n",
    "        fitElevs_red.append(np.nanmedian(np.array(df_red_this['elevPeak_fit'])))\n",
    "\n",
    "        \n",
    "        theseAreas = np.array(df_red_this['area'])\n",
    "        areas1, counts = np.unique(theseAreas, return_counts=True)\n",
    "                   \n",
    "        if len(areas1) > 0:   \n",
    "            areas_red.append(areas1[np.argmax(counts)])                   \n",
    "        else:\n",
    "            areas_red.append('OUT')\n",
    "            \n",
    "        if s ==0:\n",
    "            df_red_commonOnes_a1 = df_red_this\n",
    "        else:\n",
    "            df_red_commonOnes_a1 = pd.concat([df_red_commonOnes_a1, df_red_this])\n",
    "        \n",
    "    \n",
    "    inV1 = np.nonzero(np.array(areas_green) == 'V1')[0]\n",
    "     \n",
    "    \n",
    "    combDict = {'fitAzis_green': np.array(fitAzis_green)[inV1],\n",
    "                # 'meanElevs_green': np.array(meanElevs_green),\n",
    "                     'area_green': np.array(areas_green)[inV1],\n",
    "                     'sessionIdx': np.array(sessionIdx)[inV1],\n",
    "                     'animal': np.array(animal_g)[inV1],\n",
    "                     'fitAzis_red': np.array(fitAzis_red)[inV1],\n",
    "                     'fitElevs_red': np.array(fitElevs_red)[inV1],\n",
    "                     'area_red': np.array(areas_red)[inV1]}    \n",
    "    combDF = pd.DataFrame(data= combDict)\n",
    "    #\n",
    "    # run LMM \n",
    "    # combDF.to_csv(os.path.join(outputPath,'df_bySession_greenAndRed_fitAziPeak_a1Only_allData.csv'))\n",
    "    #prepare for LMM\n",
    "    df_path= os.path.join(ops['outputPath'],'df_bySession_greenVsRed_forLMM.csv')\n",
    "    combDF.to_csv(df_path)\n",
    "    formula = 'fitAzis_green ~ 1 + fitAzis_red + (1|animal)'\n",
    "    # formula = 'meanElevs_green ~ 1 + fitElevs_red + (1|animal)'\n",
    "\n",
    "    savePath = os.path.join(ops['outputPath'], 'LMM_greenVsRed_bySession.mat')\n",
    "    \n",
    "    #run LMM and load results\n",
    "    res, fitLines, fitCI = eng.linearMixedModel_fromPython(df_path, formula,savePath, nargout=3) \n",
    "\n",
    "    mat_file = scipy.io.loadmat(savePath)   \n",
    "    res = getDict_fromMatlabStruct(mat_file, 'res')\n",
    "    \n",
    "    # if len(data_bySession) < len(commonOnes_a1):\n",
    "    #     print('empty sessions, attention!')\n",
    "        \n",
    "    azimuths = [ '0', '36', '72', '108']\n",
    "    # azimuths = ['0', '36', '72', '108']\n",
    "    \n",
    "    intercept = res['Intercept'][0][0] # from matlab LMM \n",
    "    slope = res['fitAzis_red'][0][0]\n",
    "    slope_p = res['fitAzis_red'][0][1]\n",
    "    xVals = np.arange(0,6.1,0.1)\n",
    "    yVals = intercept + slope*xVals\n",
    "     \n",
    "    #\n",
    "    #this is the nice one\n",
    "    fig = plt.figure(figsize =(ops['mm']*80,ops['mm']*80), constrained_layout = True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.plot([0,6], [0,6], color = 'gray', linewidth = 0.3)\n",
    "    plt.scatter(np.array(combDict['fitAzis_red']), np.array(combDict['fitAzis_green']), c= 'k', s =1)\n",
    "    x_axis = 'fitAzis_red'\n",
    "    fitLine = np.array(fitLines[x_axis])\n",
    "    fitLine_down = np.array(fitCI[x_axis])[:,0]\n",
    "    fitLine_up = np.array(fitCI[x_axis])[:,1]\n",
    "    xVals = np.linspace(min(combDF[x_axis]), max(combDF[x_axis]), len(fitLine))\n",
    "    plt.fill_between(xVals, fitLine_up, fitLine_down, facecolor = 'gray',alpha = 0.3)\n",
    "    plt.plot(xVals, fitLine, c = 'k', linewidth = 1, linestyle ='dashed') \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best sound azimuth, \\n Ac boutons (\\u00B0)', 'Best visual azimuth, \\n V1 neurons (\\u00B0)','', mySize=15)\n",
    "    plt.text(3,1,'p: ' + str(np.round(slope_p,3)),fontsize=15)\n",
    "    plt.xticks([0,2,4,6], azimuths)\n",
    "    plt.yticks([0,2,4,6], azimuths)\n",
    "    plt.ylim([0,6])\n",
    "    plt.xlim([0,6])\n",
    "    ax.tick_params(axis='y', pad=1)  \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "\n",
    "    # fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\bestAzimuth_acrossMod_matchedFOV.svg'))\n",
    "\n",
    "    #%% NOw correlate it with proportion of centre-tuned boutons\n",
    "    outOnes = np.nonzero(np.array(df['area']) == 'OUT')[0]\n",
    "    inOnes = np.setdiff1d(np.arange(0, len(df)), outOnes)\n",
    "    \n",
    "    idx0 = np.intersect1d(inOnes,gaussFit)\n",
    "    \n",
    "    # contraIdx = np.nonzero(peak >= 6)[0]\n",
    "    # idx = np.intersect1d(idx0,contraIdx)\n",
    "    \n",
    "    df_gaussFit = df.iloc[idx0]\n",
    "    peak_gauss = peak[idx0]\n",
    "    # df_green['aziPeak_fit'] = peak_green-6\n",
    "    \n",
    "    leftBorder = 4.4\n",
    "    rightBorder = 7.6\n",
    " \n",
    "    left_tuned = np.nonzero(peak_gauss < leftBorder)[0]\n",
    "    right_tuned = np.nonzero(peak_gauss > rightBorder)[0]\n",
    "    centre_tuned0 = np.setdiff1d(np.arange(0,len(peak_gauss)), left_tuned)\n",
    "    centre_tuned1 = np.setdiff1d(np.arange(0,len(peak_gauss)), right_tuned)\n",
    "    centre_tuned = np.intersect1d(centre_tuned0, centre_tuned1)\n",
    "    \n",
    "    #shuffle\n",
    "    nShuffles = 1000\n",
    "    # df_gaussFit_sh = df_gaussFit.copy()\n",
    "    # shuffled_session = df_gaussFit['sessionIdx'].sample(frac=1, replace=False).reset_index(drop=True)\n",
    "    # df_gaussFit_sh['sessionIdx'] = shuffled_session\n",
    "    peak_gauss_sh = peak_gauss.copy(); np.random.shuffle(peak_gauss_sh)\n",
    "    \n",
    "    # left_tuned_gauss = np.intersect1d(gaussFit, left_tuned)\n",
    "    # prop_left_all = len(left_tuned_gauss)/len(gaussFit)       \n",
    "    # right_tuned_gauss = np.intersect1d(gaussFit, right_tuned)\n",
    "    # prop_right_all = len(right_tuned_gauss)/len(gaussFit)\n",
    "    # centre_tuned_gauss = np.intersect1d(gaussFit, centre_tuned)\n",
    "    # prop_centre_all = len(centre_tuned_gauss)/len(gaussFit)\n",
    "    seshIdx_unique = np.unique(df_gaussFit['sessionIdx'])\n",
    "    prop_left = np.empty(len(seshIdx_unique));prop_left[:] = np.nan\n",
    "    prop_right = np.empty(len(seshIdx_unique));prop_right[:] = np.nan\n",
    "    prop_centre = np.empty(len(seshIdx_unique));prop_centre[:] = np.nan\n",
    " \n",
    "    for s in range(len(seshIdx_unique)):\n",
    "        idx_thisSession = np.nonzero(np.array(df_gaussFit['sessionIdx']) == seshIdx_unique[s])[0]\n",
    "        \n",
    "        if len(idx_thisSession) <10:\n",
    "            continue\n",
    "        left_thisSesh = np.intersect1d(idx_thisSession, left_tuned)\n",
    "        right_thisSesh = np.intersect1d(idx_thisSession, right_tuned)\n",
    "        centre_thisSesh = np.intersect1d(idx_thisSession, centre_tuned)\n",
    "        \n",
    "        \n",
    "        prop_left[s] = len(left_thisSesh)/len(idx_thisSession)\n",
    "        prop_right[s] = len(right_thisSesh)/len(idx_thisSession)\n",
    "        prop_centre[s] = len(centre_thisSesh)/len(idx_thisSession)\n",
    " \n",
    "    df_green = df_gaussFit\n",
    "    sessionRef_0 = makeSessionReference(df_green)\n",
    "    sessionRef_1 = makeSessionReference(df_red)\n",
    "    \n",
    "    sessionIdx_0 = np.unique(np.array(df_green['sessionIdx']))\n",
    "    sessionIdx_1 = np.unique(np.array(df_red['sessionIdx']))\n",
    "    commonOnes = np.intersect1d(sessionIdx_0,sessionIdx_1)\n",
    "    \n",
    "    commonOnes_idx = np.squeeze(np.array([np.nonzero(np.array(sessionRef_0['seshIdx']) == commonOnes[i])[0] for i in range(len(commonOnes))]))\n",
    "    propCentre_green = prop_centre[commonOnes_idx]\n",
    "    \n",
    "    seshAreas_common = []\n",
    "    for i in range(len(commonOnes)):\n",
    "        rel_idx = np.nonzero(sessionRef_0['seshIdx'] == commonOnes[i])[0]      \n",
    "        seshAreas_common.append(sessionRef_0['seshAreas'][rel_idx[0]])\n",
    "\n",
    "    areas_green, areas_red, fitAzis_red,fitElevs_red, sessionIdx, animal_g= [],[],[],[],[],[]\n",
    "    sessionX, sessionY, sessionElev, sessionAzi = [], [], [], []\n",
    "    for s in range(len(commonOnes)):  \n",
    "        sessionIdx.append(commonOnes[s])\n",
    "\n",
    "        #green\n",
    "        idx_thisSession_g = np.nonzero(np.array(df_green['sessionIdx']) == commonOnes[s])[0]\n",
    "        \n",
    "        df_green_this = df_green.iloc[idx_thisSession_g]\n",
    "        \n",
    "        theseAreas = np.array(df_green_this['area'])\n",
    "        areas1, counts = np.unique(theseAreas, return_counts=True)\n",
    "                   \n",
    "        if len(areas1) > 0:   \n",
    "            areas_green.append(areas1[np.argmax(counts)])                   \n",
    "        else:\n",
    "            areas_green.append('OUT')\n",
    "            \n",
    "        animal_g.append(np.array(df_green_this['animal'])[0])\n",
    "        if s ==0:\n",
    "            df_green_commonOnes_a1 = df_green_this\n",
    "        else:\n",
    "            df_green_commonOnes_a1 = pd.concat([df_green_commonOnes_a1, df_green_this])\n",
    "        \n",
    "        #red\n",
    "        idx_thisSession_r = np.nonzero(np.array(df_red['sessionIdx']) == commonOnes[s])[0]\n",
    "        \n",
    "        df_red_this = df_red.iloc[idx_thisSession_r]\n",
    "        \n",
    "        fitAzis_red.append(np.nanmedian(np.array(df_red_this['aziPeak_fit'])))\n",
    "        fitElevs_red.append(np.nanmedian(np.array(df_red_this['elevPeak_fit'])))\n",
    "\n",
    "        \n",
    "        theseAreas = np.array(df_red_this['area'])\n",
    "        areas1, counts = np.unique(theseAreas, return_counts=True)\n",
    "                   \n",
    "        if len(areas1) > 0:   \n",
    "            areas_red.append(areas1[np.argmax(counts)])                   \n",
    "        else:\n",
    "            areas_red.append('OUT')\n",
    "            \n",
    "        if s ==0:\n",
    "            df_red_commonOnes_a1 = df_red_this\n",
    "        else:\n",
    "            df_red_commonOnes_a1 = pd.concat([df_red_commonOnes_a1, df_red_this])\n",
    "        \n",
    "    \n",
    "    inV1 = np.nonzero(np.array(areas_green) == 'V1')[0]\n",
    "     \n",
    "    \n",
    "    combDict = {'propCentre': np.array(propCentre_green)[inV1],\n",
    "                # 'meanElevs_green': np.array(meanElevs_green),\n",
    "                     'area_green': np.array(areas_green)[inV1],\n",
    "                     'sessionIdx': np.array(sessionIdx)[inV1],\n",
    "                     'animal': np.array(animal_g)[inV1],\n",
    "                     'fitAzis_red': np.array(fitAzis_red)[inV1],\n",
    "                     'fitElevs_red': np.array(fitElevs_red)[inV1],\n",
    "                     'area_red': np.array(areas_red)[inV1]}    \n",
    "    combDF = pd.DataFrame(data= combDict)\n",
    "    #\n",
    "    # run LMM \n",
    "    # combDF.to_csv(os.path.join(outputPath,'df_bySession_greenAndRed_fitAziPeak_a1Only_allData.csv'))\n",
    "    #prepare for LMM\n",
    "    # df_path= os.path.join(ops['outputPath'],'df_bySession_greenVsRed_forLMM.csv')\n",
    "    # combDF.to_csv(df_path)\n",
    "    # formula = 'propCentre ~ 1 + fitAzis_red + (1|animal)'\n",
    "    # # formula = 'meanElevs_green ~ 1 + fitElevs_red + (1|animal)'\n",
    "\n",
    "    # savePath = os.path.join(ops['outputPath'], 'LMM_greenVsRed_bySession.mat')\n",
    "    \n",
    "    # #run LMM and load results\n",
    "    # res, fitLines, fitCI = eng.linearMixedModel_fromPython(df_path, formula,savePath, nargout=3) \n",
    "\n",
    "    # mat_file = scipy.io.loadmat(savePath)   \n",
    "    # res = getDict_fromMatlabStruct(mat_file, 'res')\n",
    "    \n",
    "    # if len(data_bySession) < len(commonOnes_a1):\n",
    "    #     print('empty sessions, attention!')\n",
    "        \n",
    "    azimuths = [ '0', '36', '72', '108']\n",
    "    # azimuths = ['0', '36', '72', '108']\n",
    "    \n",
    "    # intercept = res['Intercept'][0][0] # from matlab LMM \n",
    "    # slope = res['fitAzis_red'][0][0]\n",
    "    # slope_p = res['fitAzis_red'][0][1]\n",
    "    # xVals = np.arange(0,6.1,0.1)\n",
    "    # yVals = intercept + slope*xVals\n",
    "    \n",
    "    #Proportion, so doing spearman correlation\n",
    "    r_spearman,p_spearman = scipy.stats.spearmanr(combDict['fitAzis_red'], combDict['propCentre'])\n",
    "\n",
    "    #\n",
    "    #this is the nice one\n",
    "    fig = plt.figure(figsize =(ops['mm']*80,ops['mm']*80), constrained_layout = True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    # plt.plot([0,6], [0,6], color = 'gray', linewidth = 0.3)\n",
    "    plt.scatter(np.array(combDict['fitAzis_red']), np.array(combDict['propCentre']), c= 'k', s =1)\n",
    "    # x_axis = 'fitAzis_red'\n",
    "    # fitLine = np.array(fitLines[x_axis])\n",
    "    # fitLine_down = np.array(fitCI[x_axis])[:,0]\n",
    "    # fitLine_up = np.array(fitCI[x_axis])[:,1]\n",
    "    # xVals = np.linspace(min(combDF[x_axis]), max(combDF[x_axis]), len(fitLine))\n",
    "    # plt.fill_between(xVals, fitLine_up, fitLine_down, facecolor = 'gray',alpha = 0.3)\n",
    "    # plt.plot(xVals, fitLine, c = 'k', linewidth = 1, linestyle ='dashed') \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Percentage centre-\\ntuned AC-boutons (%)', 'Best visual azimuth, \\n V1 neurons (\\u00B0)','', mySize=15)\n",
    "    plt.text(4,0.45,'r= ' + str(np.round(r_spearman,3)) + '\\np= ' + str(np.round(p_spearman,3)), fontsize=15)\n",
    "    plt.xticks([0,2,4,6], azimuths)\n",
    "    plt.yticks([0,0.2,0.4,0.6], ['0', '20', '40', '60'])\n",
    "    # plt.ylim([0,0.6])\n",
    "    # plt.xlim([0,6])\n",
    "    ax.tick_params(axis='y', pad=1)  \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "\n",
    "    fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\bestAzimuth_vs_propCentre_acrossMod_matchedFOV.svg'))\n",
    "\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14e36a9-62c4-4753-9253-fd9bfb9c16f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotPropCentre_againstAzi_spatialBins(ref,map_V1,df, df_red,ops, b =300, mask='none', propCentre_green=1, propCentre_red =1):\n",
    "\n",
    "    df = df[~df['x'].isnull()]\n",
    "    df = df[~df['y'].isnull()]\n",
    "    df = df[df['x'] != 0]\n",
    "    df = df[df['y'] != 0]\n",
    "    df = df[df['area'] != 'OUT']\n",
    "    \n",
    "    mapsPath =  'Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\retinotopyMaps\\\\'\n",
    "    map_V1 = imageio.imread(os.path.join(mapsPath,'Reference_map_allen_V1Marked.png'))\n",
    "    \n",
    "    # idx = np.nonzero(np.array([df['sessionIdx'].iloc[i] in commonOnes for i in range(len(df))]))[0]\n",
    "    # df = df.iloc[idx]\n",
    "    \n",
    "    # propCentre_green =1\n",
    "    # propCentre_red =1\n",
    "    # for b in binSize:\n",
    "    if propCentre_green:\n",
    "        leftBorder = 4.4\n",
    "        rightBorder = 7.6\n",
    "           \n",
    "        # b = 300\n",
    "        left_tuned = np.nonzero(np.array(df['peak']) < leftBorder)[0]\n",
    "        right_tuned = np.nonzero(np.array(df['peak']) > rightBorder)[0]\n",
    "        centre_tuned0 = np.setdiff1d(np.arange(0,len(np.array(df['peak']))), left_tuned)\n",
    "        centre_tuned1 = np.setdiff1d(np.arange(0,len(np.array(df['peak']))), right_tuned)\n",
    "        centre_tuned = np.intersect1d(centre_tuned0, centre_tuned1)\n",
    "        \n",
    "        binned_map = makeSpatialBinnedMap(ref,spatialBin =b) \n",
    "        \n",
    "        binned_prop_map_centre = makeProportions_bySpatialBin_v3(df,binned_map, centre_tuned, thresh = 5, mask = mask, V1_mask=map_V1)\n",
    "    \n",
    "        bins_unique = np.unique(binned_map)\n",
    "        \n",
    "        binValues_green = getBinValues(binned_map, binned_prop_map_centre, ops['map_colors'], ops['colors_LUT'])\n",
    "        y_title = 'Best sound azimuth \\nAC-boutons (%)'\n",
    "\n",
    "    else:\n",
    "        contraTuned = np.nonzero(np.array(df['peak']) >=6)[0]\n",
    "        df = df.iloc[contraTuned]\n",
    "        df['peak'] = df['peak'] -6\n",
    "        binned_map = makeSpatialBinnedMap(ref,spatialBin =b) \n",
    "        binned_values_map = makeMeanValue_bySpatialBin_v2(df, binned_map,thresh =5,  varName = 'peak', mask = mask, V1_mask = map_V1)\n",
    "        bins_unique = np.unique(binned_map)\n",
    "    \n",
    "        binValues_green = getBinValues(binned_map, binned_values_map, ops['map_colors'], ops['colors_LUT'])\n",
    "        y_title = 'Best sound azimuth \\nAC-boutons (%)'\n",
    "\n",
    "    \n",
    "\n",
    "    df_red = df_red[~df_red['x'].isnull()]\n",
    "    df_red = df_red[~df_red['y'].isnull()]\n",
    "    df_red = df_red[df_red['x'] != 0]\n",
    "    df_red = df_red[df_red['y'] != 0]\n",
    "    df_red = df_red[df_red['area'] != 'OUT']\n",
    "    \n",
    "    # idx = np.nonzero(np.array([df_red['sessionIdx'].iloc[i] in commonOnes for i in range(len(df_red))]))[0]\n",
    "    # df_red = df_red.iloc[idx]\n",
    "    \n",
    "    if propCentre_red:\n",
    "        leftBorder = 1.6666\n",
    "    \n",
    "        centre_tuned = np.nonzero(np.array(df_red['aziPeak']) < leftBorder)[0]\n",
    "       \n",
    "        binned_map = makeSpatialBinnedMap(ref,spatialBin =b) \n",
    "    \n",
    "        binned_prop_map_centre_red = makeProportions_bySpatialBin_v3(df_red,binned_map, centre_tuned, thresh = 5, mask='none', V1_mask=[])\n",
    "       \n",
    "        binValues_red = getBinValues(binned_map, binned_prop_map_centre_red, ops['map_colors'], ops['colors_LUT'])\n",
    "        x_title = 'Percentage centre-tuned \\nVC-neurons (%)'\n",
    "    #against real azimuth\n",
    "    else:\n",
    "    # b = 250\n",
    "        binned_map = makeSpatialBinnedMap(ref,spatialBin =b) \n",
    "        binned_values_map = makeMeanValue_bySpatialBin_v2(df_red, binned_map,thresh =5,  varName = 'aziPeak', mask = mask, V1_mask = map_V1)\n",
    "        \n",
    "        binValues_red = getBinValues(binned_map, binned_values_map, ops['map_colors'], ops['colors_LUT'])\n",
    "        x_title = 'Best visual azimuth \\nVC-neurons (%)'\n",
    "\n",
    "        \n",
    "    #against proportion centre-tuned\n",
    "    vals_green, vals_red, valArea = [],[],[]\n",
    "    for i in range(len(binValues_red)):\n",
    "        if not np.isnan(binValues_red['values'][i]) and not np.isnan(binValues_green['values'][i]) and not binValues_green['binArea'][i] =='OUT':\n",
    "            vals_green.append(binValues_green['values'][i])\n",
    "            vals_red.append(binValues_red['values'][i])\n",
    "            valArea.append(binValues_green['binArea'][i])\n",
    "\n",
    "    vals_green = np.array(vals_green)\n",
    "    vals_red = np.array(vals_red)\n",
    "    if mask == 'V1':\n",
    "        title = 'V1 spatial bins only'\n",
    "    elif mask == 'HVAs':\n",
    "        title = 'HVA spatial bins only'\n",
    "    else:\n",
    "        title = 'All spatial bins'\n",
    "        \n",
    "    areaColors = ops['myColorsDict']['HVA_colors']\n",
    "    colors = np.array([areaColors[valArea[j]] for j in range(len(valArea))])\n",
    "   \n",
    "    #%%\n",
    "    r,p = scipy.stats.spearmanr(vals_red, vals_green)\n",
    "\n",
    "    fig = plt.figure(figsize=(ops['mm']*30,ops['mm']*30), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.scatter(vals_red, vals_green, s =5, facecolors =colors,alpha =0.5, linewidth=0)\n",
    "    # r,p = scipy.stats.spearmanr(vals_red, vals_green)\n",
    "    # lm = doLinearRegression(vals_red, vals_green)\n",
    "    # plt.plot(lm['x_vals'], lm['y_vals'],c = 'k',linestyle='dashed',linewidth = 0.5)\n",
    "    plt.text(0.1,0.4, 'r: ' + str(np.round(r,3)) + '\\np: ' + str(np.round(p,3)), fontsize=5)\n",
    "    myPlotSettings_splitAxis(fig, ax, y_title, x_title, '',mySize=6)\n",
    "    if propCentre_green:\n",
    "        plt.yticks([0,0.25, 0.5], ['0','25','50'])\n",
    "    else:\n",
    "        plt.yticks([0,2, 4,6], ['0','36','72','108'])\n",
    "    if propCentre_red:\n",
    "        plt.xticks([0,0.4, 0.8], ['0','40','80'])\n",
    "    else:\n",
    "        plt.xticks([0,2,4,6], ['0','36','72','108'])\n",
    "\n",
    "    # plt.xticks([20/18,50/18,80/18], ['20', '50', '80'])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)\n",
    "    \n",
    "\n",
    "# def plotPropCentre_againstAzi_spatialBins(ref,map_V1,df, df_red,ops, b =300, mask='none'):\n",
    "#     # df = df0\n",
    "    \n",
    "#     df = df[~df['x'].isnull()]\n",
    "#     df = df[~df['y'].isnull()]\n",
    "#     df = df[df['x'] != 0]\n",
    "#     df = df[df['y'] != 0]\n",
    "#     df = df[df['area'] != 'OUT']\n",
    "    \n",
    "#     # for b in binSize:\n",
    "#     leftBorder = 4.4\n",
    "#     rightBorder = 7.6\n",
    "       \n",
    "#     # b = 300\n",
    "#     left_tuned = np.nonzero(np.array(df['peak']) < leftBorder)[0]\n",
    "#     right_tuned = np.nonzero(np.array(df['peak']) > rightBorder)[0]\n",
    "#     centre_tuned0 = np.setdiff1d(np.arange(0,len(np.array(df['peak']))), left_tuned)\n",
    "#     centre_tuned1 = np.setdiff1d(np.arange(0,len(np.array(df['peak']))), right_tuned)\n",
    "#     centre_tuned = np.intersect1d(centre_tuned0, centre_tuned1)\n",
    "    \n",
    "#     binned_map = makeSpatialBinnedMap(ref,spatialBin =b) \n",
    "    \n",
    "#     binned_prop_map_centre = makeProportions_bySpatialBin_v3(df,binned_map, centre_tuned, thresh = 5, mask = mask, V1_mask=map_V1)\n",
    "\n",
    "#     bins_unique = np.unique(binned_map)\n",
    "#     binValues_green = getBinValues(binned_map, binned_prop_map_centre, ops['map_colors'], ops['colors_LUT'])\n",
    "\n",
    "#     df_red = df_red[~df_red['x'].isnull()]\n",
    "#     df_red = df_red[~df_red['y'].isnull()]\n",
    "#     df_red = df_red[df_red['x'] != 0]\n",
    "#     df_red = df_red[df_red['y'] != 0]\n",
    "#     df_red = df_red[df_red['area'] != 'OUT']\n",
    "      \n",
    "#     # b = 250\n",
    "#     binned_map = makeSpatialBinnedMap(ref,spatialBin =b) \n",
    "#     binned_values_map = makeMeanValue_bySpatialBin_v2(df_red, binned_map,thresh =5,  varName = 'aziPeak', mask = mask, V1_mask = map_V1)\n",
    "    \n",
    "#     binValues_red = getBinValues(binned_map, binned_values_map, ops['map_colors'], ops['colors_LUT'])\n",
    "    \n",
    "#     vals_green, vals_red, valArea = [],[],[]\n",
    "#     for i in range(len(binValues_red)):\n",
    "#         if not np.isnan(binValues_red['values'][i]) and not np.isnan(binValues_green['values'][i]) and not binValues_green['binArea'][i] =='OUT':\n",
    "#             vals_green.append(binValues_green['values'][i])\n",
    "#             vals_red.append(binValues_red['values'][i])\n",
    "#             valArea.append(binValues_green['binArea'][i])\n",
    "\n",
    "#     vals_green = np.array(vals_green)\n",
    "#     vals_red = np.array(vals_red)\n",
    "#     if mask == 'V1':\n",
    "#         title = 'V1 spatial bins only'\n",
    "#     elif mask == 'HVAs':\n",
    "#         title = 'HVA spatial bins only'\n",
    "#     else:\n",
    "#         title = 'All spatial bins'\n",
    "        \n",
    "#     areaColors = ops['myColorsDict']['HVA_colors']\n",
    "#     colors = np.array([areaColors[valArea[j]] for j in range(len(valArea))])\n",
    "   \n",
    "#     fig = plt.figure(figsize=(ops['mm']*100,ops['mm']*100), constrained_layout=True)\n",
    "#     ax = fig.add_subplot(1,1,1)\n",
    "#     plt.scatter(vals_red, vals_green, s =20, facecolors =colors,alpha =0.5, linewidth=0)\n",
    "#     r,p = scipy.stats.spearmanr(vals_red, vals_green)\n",
    "#     # lm = doLinearRegression(vals_red, vals_green)\n",
    "#     # plt.plot(lm['x_vals'], lm['y_vals'],c = 'k',linestyle='dashed',linewidth = 0.5)\n",
    "#     plt.text(3.2,0.4, 'r: ' + str(np.round(r,3)) + '\\np: ' + str(np.round(p,3)), fontsize=15)\n",
    "#     myPlotSettings_splitAxis(fig, ax, 'Best sound azimuth, AC-boutons (deg)', 'Best visual azimuth, VC-neurons (deg)', '',mySize=15)\n",
    "#     plt.xticks([20/18,50/18,80/18], ['20', '50', '80'])\n",
    "#     ax.tick_params(axis='y', pad=1)   \n",
    "#     ax.tick_params(axis='x', pad=1)\n",
    "#     plt.yticks([0,0.25, 0.5], ['0','25','50'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3753f8d-6b91-4515-b0e3-7ce9aef6b653",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotElevationDistance(df,maps,peak, df_red, ops, eng,nShuffles=100):\n",
    "    \n",
    "    noArea_idx = np.nonzero(np.array(df['area']) == 'OUT')[0]\n",
    "    \n",
    "    badRoiPosition1 = np.nonzero(np.array(df['x']) ==0)[0]\n",
    "    badRoiPosition2 = np.nonzero(np.array(df['y']) ==0)[0]\n",
    "    badRoiPosition = np.unique(np.concatenate((badRoiPosition1,badRoiPosition2),0))\n",
    "    \n",
    "    noArea_idx = np.unique(np.concatenate((noArea_idx,badRoiPosition),0))\n",
    "           \n",
    "\n",
    "    elevPeak = getElevation_greenAud(df, maps, peak, onlyPeakSide = 1)\n",
    "    # contraIdx = np.nonzero(np.array(df_fit_1d_green_aud_full_elev['gaussian_peak']) > 6)[0]\n",
    "\n",
    "    includeIdx_green_elev = np.setdiff1d(np.arange(0,len(df)), noArea_idx)\n",
    "\n",
    "    df_green_elev = df.iloc[includeIdx_green_elev]\n",
    "    df_green_elev['elevPeak'] = elevPeak[includeIdx_green_elev]\n",
    "    \n",
    "    \n",
    "    data0 = elevPeak[includeIdx_green_elev]\n",
    "    df0= df_green_elev\n",
    "        \n",
    "    data1 = abs(np.nanmax(np.array(df_red['elevPeak']))- np.array(df_red['elevPeak']))   #flip it around so that max is top led location\n",
    "    peakElev_byArea_red = []\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        idx_thisArea = np.nonzero(np.array(df_red['area']) == ops['areas'][ar])[0]\n",
    "        \n",
    "        elev_thisArea = df_red.iloc[idx_thisArea]['elevPeak']\n",
    "    \n",
    "        peakElev_byArea_red.append(np.nanmean(elev_thisArea))\n",
    "        \n",
    "    #get grean peak by session   \n",
    "    #green\n",
    "    peak_elev_bySession = []\n",
    "    peak_elev_bySession_sh = []\n",
    "    sessionIdx= np.unique(np.array(df0['sessionIdx']))\n",
    "    for s in range(len(sessionIdx)):\n",
    "        idx_thisSession = np.nonzero(np.array(df0['sessionIdx']) == sessionIdx[s])[0]\n",
    "              \n",
    "      \n",
    "        peak_elev = data0[idx_thisSession]\n",
    "        \n",
    "        if len(idx_thisSession) < 10:\n",
    "            peak_elev_bySession.append(np.nan)\n",
    "        else:\n",
    "\n",
    "            peak_elev_bySession.append(np.nanmean(peak_elev))\n",
    "        \n",
    "        sh = np.zeros((len(idx_thisSession), nShuffles))\n",
    "        for n in range(nShuffles):\n",
    "            idx = np.random.choice(np.arange(len(data0)), len(idx_thisSession))\n",
    "            sh[:,n] = data0[idx]\n",
    "        \n",
    "        peak_elev_bySession_sh.append(sh)\n",
    "      \n",
    "    sessionRef = makeSessionReference(df0)\n",
    "    # peak_azi_bySession = np.array(peak_azi_bySession)\n",
    "    \n",
    "    peakElev_byArea = []\n",
    "    peakElev_byArea_sh = []\n",
    "\n",
    "    for ar in range(len(ops['areas'])):  \n",
    "        idx = np.nonzero(np.array(sessionRef['seshAreas']) == ops['areas'][ar])[0]\n",
    "        \n",
    "        peak_bySession_this = np.array([peak_elev_bySession[idx[i]] for i in range(len(idx))])\n",
    "        peak_bySession_this_clean = peak_bySession_this[np.nonzero(np.isnan(peak_bySession_this) < 0.5)[0]]\n",
    "\n",
    "        peakElev_byArea.append(peak_bySession_this_clean)\n",
    "        \n",
    "        peak_bySession_this_sh = np.array([peak_elev_bySession_sh[idx[i]] for i in range(len(idx))])\n",
    "        # peak_bySession_this_clean = peak_bySession_this_sh[np.nonzero(np.isnan(peak_bySession_this_sh) < 0.5)[0]]\n",
    "\n",
    "        peakElev_byArea_sh.append(peak_bySession_this_sh)\n",
    "    \n",
    "    \n",
    "\n",
    "    # median_azi1 = [np.array([np.nanmedian(peakAzi_byArea[ar][i]) for i in range(len(peakAzi_byArea[ar]))]) for ar in range(len(areas))]\n",
    "    \n",
    "    notV1 = np.nonzero(np.array(sessionRef['seshAreas']) != 'V1')[0]\n",
    "    notNan = np.nonzero(np.isnan(np.array(peak_elev_bySession)) <0.5)[0]\n",
    "    # thisIdx =notNan\n",
    "    thisIdx = np.intersect1d(notV1,notNan)\n",
    "    seshMapGood = np.nonzero(np.array(sessionRef['seshMapGood']) == 1)[0]\n",
    "    thisIdx = np.intersect1d(thisIdx, seshMapGood)\n",
    "\n",
    "    df_forTest = pd.DataFrame({'peakElev_bySession': np.array(peak_elev_bySession)[thisIdx],                                    \n",
    "                            'area': np.array(sessionRef['seshAreas'])[thisIdx],\n",
    "                            'stream': np.array(sessionRef['seshStream'])[thisIdx],\n",
    "                            'elev': np.array(sessionRef['seshElev'])[thisIdx],\n",
    "                            'animal':  np.array(sessionRef['seshAnimal'])[thisIdx]})\n",
    "    \n",
    "    df_path = os.path.join(ops['outputPath'], 'df_forTest.csv')\n",
    "\n",
    "    df_forTest.to_csv(df_path)\n",
    "\n",
    "\n",
    "    formula = 'peakElev_bySession ~ area + (1|animal)'                 \n",
    "    p_LMM = eng.linearMixedModel_fromPython_anova(df_path, formula, nargout=1)\n",
    "    \n",
    "    \n",
    "    formula = 'peakElev_bySession ~ elev + (1|animal)'                 \n",
    "    savePath = os.path.join(ops['outputPath'], 'LMM_green_aud.mat')\n",
    "     \n",
    "     #run LMM and load results\n",
    "    res, fitLines, fitCI = eng.linearMixedModel_fromPython(df_path, formula,savePath, nargout=3) \n",
    "      \n",
    "    mat_file = scipy.io.loadmat(savePath)   \n",
    "    res = getDict_fromMatlabStruct(mat_file, 'res')\n",
    "\n",
    "\n",
    "    #Now same for red\n",
    "    peak_elev_bySession_red = []\n",
    "  \n",
    "    sessionIdx= np.unique(np.array(df_red['sessionIdx']))\n",
    "    for s in range(len(sessionIdx)):\n",
    "        idx_thisSession = np.nonzero(np.array(df_red['sessionIdx']) == sessionIdx[s])[0]\n",
    "              \n",
    "        peak_elev = data1[idx_thisSession]\n",
    "        \n",
    "        peak_elev_bySession_red.append(np.nanmedian(peak_elev))\n",
    "           \n",
    "    sessionRef = makeSessionReference(df_red)\n",
    "    peak_elev_bySession_red = np.array(peak_elev_bySession_red)\n",
    "    \n",
    "    peakElev_byArea_red = []\n",
    "    for ar in range(len(ops['areas'])):  \n",
    "        idx = np.nonzero(np.array(sessionRef['seshAreas']) == ops['areas'][ar])[0]\n",
    "        \n",
    "        peak_bySession_this = peak_elev_bySession_red[idx]\n",
    "        # notNan = np.nonzero(np.isnan(np.array(peak_bySession_this)) <0.5)[0]\n",
    "        \n",
    "        peak_bySession_this_clean = peak_bySession_this[np.nonzero(np.isnan(peak_bySession_this) < 0.5)[0]]\n",
    "\n",
    "        peakElev_byArea_red.append(peak_bySession_this_clean)\n",
    "            \n",
    "    notV1 = np.nonzero(np.array(sessionRef['seshAreas']) != 'V1')[0]\n",
    "    notNan = np.nonzero(np.isnan(np.array(peak_elev_bySession_red)) <0.5)[0]\n",
    "    thisIdx =notNan\n",
    "    thisIdx = np.intersect1d(notV1,notNan)\n",
    "\n",
    "    df_forTest = pd.DataFrame({'peakElev_bySession': np.array(peak_elev_bySession_red)[thisIdx],                                    \n",
    "                            'area': np.array(sessionRef['seshAreas'])[thisIdx],\n",
    "                            'stream': np.array(sessionRef['seshStream'])[thisIdx],\n",
    "                            'animal':  np.array(sessionRef['seshAnimal'])[thisIdx]})\n",
    "    \n",
    "    df_path = os.path.join(ops['outputPath'], 'df_forTest.csv')\n",
    "\n",
    "    df_forTest.to_csv(df_path)\n",
    "\n",
    "\n",
    "    formula = 'peakElev_bySession ~ area + (1|animal)'                 \n",
    "    p_LMM = eng.linearMixedModel_fromPython_anova(df_path, formula, nargout=1)\n",
    "    # t, p_kruskal = stats.kruskal(*peakAzi_byArea_red[1::], nan_policy ='omit')\n",
    "    #%%\n",
    "    fig = plt.figure(figsize=(ops['mm']*100, ops['mm']*100), constrained_layout =True)\n",
    "    \n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        median_elev = np.nanmean(peakElev_byArea_red[ar])\n",
    "        \n",
    "        plt.plot([ar-0.25, ar+0.25], [median_elev,median_elev] , linewidth = 2, c = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],zorder = 2)\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.05,size = len(peakElev_byArea_red[ar])) \n",
    "        plt.scatter(xVals_scatter, np.array(peakElev_byArea_red[ar]), s = 10, facecolors = 'white' , edgecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]], linewidths =0.5,alpha=0.3,zorder = 1)\n",
    "        \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best sound elevation (deg)', '', str(p_LMM), mySize=15)\n",
    "    plt.xticks(np.arange(0, len(ops['areas'])), ops['areas'], rotation =90)\n",
    "    plt.yticks([-0.222,2,4.222], ['-40','0', '40'])\n",
    "    plt.ylim([-0.222,4.222])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "\n",
    "    # if p_LMM < 0.05:\n",
    "    #     p_mannWhitney, compIdx = doMannWhitneyU_forBoxplots(peakElev_byArea_red, multiComp = 'hs')\n",
    "    #     cnt = 0\n",
    "    #     for c in range(len(compIdx)):\n",
    "    #         if p_mannWhitney[c] < 0.05:\n",
    "    #             pos = compIdx[c].split('_')\n",
    "    #             plt.hlines(3.7+cnt, int(pos[0]), int(pos[1]), color = 'k', linewidth =0.5)\n",
    "    #             cnt += 0.05\n",
    "    #%%\n",
    "    ##% Distance between green and red\n",
    "    fig = plt.figure(figsize=(ops['mm']*100, ops['mm']*100), constrained_layout =True)\n",
    "    # fig = plt.figure(figsize=(self.mm*50, self.mm*50), constrained_layout =True)\n",
    "\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    for ar in range(1,len(ops['areas'])):\n",
    "        median_red = np.nanmedian(peakElev_byArea_red[ar])\n",
    "        \n",
    "        vals_thisArea = peakElev_byArea[ar]\n",
    "        \n",
    "        notNan = np.nonzero(np.isnan(np.array(vals_thisArea)) <0.5)[0]\n",
    "        vals_thisArea = np.array(vals_thisArea)[notNan]\n",
    "        \n",
    "        \n",
    "        distance = [np.median(abs(vals_thisArea[i] - median_red)) for i in range(len(vals_thisArea))]\n",
    "        median_distance = np.nanmedian(distance)\n",
    "        \n",
    "        vals_thisArea_sh = peakElev_byArea_sh[ar]\n",
    "        vals_sh = []\n",
    "        for i in range(len(vals_thisArea_sh)):\n",
    "            vals_sh.append(np.median([abs(vals_thisArea_sh[i][:,n] - median_red) for n in range(nShuffles)]))\n",
    "                    \n",
    "        vals_sh = np.array(vals_sh)[notNan]\n",
    "        median_sh = np.nanmedian(np.array(vals_sh))\n",
    "        \n",
    "        plt.plot([ar-0.25, ar+0.25], [median_distance,median_distance] , linewidth = 2, c = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],zorder = 2)\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.05,size = len(distance)) \n",
    "        plt.scatter(xVals_scatter, np.array(distance), s = 20, facecolors = 'white' , edgecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]], linewidths =0.5,alpha=0.3,zorder = 1)\n",
    "        \n",
    "        plt.plot([ar-0.25, ar+0.25], [median_sh,median_sh] , linewidth = 2, c = 'silver',zorder = 2)\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.05,size = len(distance)) \n",
    "        # plt.scatter(xVals_scatter, np.array(vals_sh), s = 5, facecolors = 'white' , edgecolors = 'lightgray', linewidths =0.5,zorder = 1)\n",
    "        \n",
    "        U,p = stats.mannwhitneyu(distance, vals_sh)\n",
    "        adj_p = statsmodels.stats.multitest.multipletests(np.repeat(p,10), method='fdr_bh')[1][0]\n",
    "        # print(str(p))\n",
    "        if adj_p < 0.05 and adj_p > 0.01:\n",
    "            plt.text(ar-0.2, 2, '*', fontsize=15)\n",
    "        elif adj_p < 0.01 and adj_p > 0.001:\n",
    "             plt.text(ar-0.2, 2, '**', fontsize=15)\n",
    "        elif adj_p < 0.001:\n",
    "             plt.text(ar-0.4, 2, '***', fontsize=15)\n",
    " \n",
    "        \n",
    "    myPlotSettings_splitAxis(fig,ax, 'Elevation distance (deg)', '', '',mySize=15)\n",
    "    plt.xticks(np.arange(1,len(ops['areas'])), ops['areas'][1::], rotation =90)\n",
    "    deg_per_N = 18\n",
    "    yPos = np.array([0,20,40])\n",
    "    yPos0 = yPos/deg_per_N\n",
    "    plt.yticks(yPos0, ['0', '20', '40'])\n",
    "    plt.ylim([-0.1, yPos0[-1]])\n",
    "    ax.tick_params(axis='y', pad=1) \n",
    "    ax.tick_params(axis='x', pad=1) \n",
    "    for tick in ax.get_xticklabels():\n",
    "        tick.set_fontsize(5) \n",
    "\n",
    "    # fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\elevationDistance_byArea.svg'))\n",
    "\n",
    "   \n",
    "    #%%\n",
    "    fig = plt.figure(figsize=(ops['mm']*100, ops['mm']*100), constrained_layout =True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    vals_green, vals_red = [],[]\n",
    "    for ar in range(1,len(ops['areas'])):\n",
    "        median_red = np.nanmedian(peakElev_byArea_red[ar])\n",
    "        print(str(median_red))\n",
    "        vals_thisArea = peakElev_byArea[ar]\n",
    "        \n",
    "        notNan = np.nonzero(np.isnan(np.array(vals_thisArea)) <0.5)[0]\n",
    "        vals_thisArea = np.array(vals_thisArea)[notNan]\n",
    "       \n",
    "        plt.scatter(np.repeat(median_red,len(vals_thisArea)), vals_thisArea, s = 3, facecolors = 'white' , edgecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]], linewidths =0.25,alpha=0.3, zorder = 1)\n",
    "        plt.scatter(median_red, np.median(vals_thisArea), s = 20, facecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]], edgecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]], linewidths =1,zorder = 2)\n",
    "    \n",
    "        vals_green.append(np.median(vals_thisArea))\n",
    "        vals_red.append(median_red)\n",
    "\n",
    "        # if ar ==1:\n",
    "        #     vals_green= vals_thisArea         \n",
    "        #     vals_red= np.repeat(median_red,len(vals_thisArea))\n",
    "        # else:\n",
    "        #     vals_green= np.concatenate((vals_green, vals_thisArea),0)       \n",
    "        #     vals_red= np.concatenate((vals_red, np.repeat(median_red,len(vals_thisArea))),0)     \n",
    "        \n",
    "        # if ar ==1:\n",
    "        #     vals_green= np.median(vals_thisArea)       \n",
    "        #     vals_red= median_red\n",
    "        # else:\n",
    "        #     vals_green= np.concatenate((vals_green, np.median(vals_thisArea)),0)       \n",
    "        #     vals_red= np.concatenate((vals_red, median_red),0)       \n",
    "\n",
    "    vals_green = np.array(vals_green)\n",
    "    vals_red = np.array(vals_red)\n",
    "    \n",
    "    df_forTest = pd.DataFrame({'median_green': vals_green, \n",
    "                               'median_red': vals_red})\n",
    "\n",
    "    formula = 'median_green~ median_red'\n",
    "\n",
    "    df_path= os.path.join(ops['outputPath'],'df_bySession_green_freq_forLMM.csv')\n",
    "    df_forTest.to_csv(df_path)\n",
    "    \n",
    "    savePath = os.path.join(ops['outputPath'], 'LMM_freq_green_aud.mat')\n",
    "    \n",
    "    #run LMM and load results\n",
    "    res, fitLines, fitCI = eng.linearMixedModel_fromPython(df_path, formula,savePath, nargout=3) \n",
    "\n",
    "    mat_file = scipy.io.loadmat(savePath)   \n",
    "    res = getDict_fromMatlabStruct(mat_file, 'res')\n",
    "\n",
    "    lm = doLinearRegression(vals_red, vals_green)\n",
    "    x_axis = 'median_red'\n",
    "    fitLine = np.array(fitLines[x_axis])\n",
    "    fitLine_down = np.array(fitCI[x_axis])[:,0]\n",
    "    fitLine_up = np.array(fitCI[x_axis])[:,1]\n",
    "    xVals = np.linspace(min(df_forTest[x_axis]), max(df_forTest[x_axis]), len(fitLine))   \n",
    "    plt.fill_between(xVals, fitLine_up, fitLine_down, facecolor = 'silver',alpha = 0.3)\n",
    "    plt.plot(xVals, fitLine, c = 'k', linewidth = 0.5, linestyle='dashed')\n",
    "\n",
    "\n",
    "    # myPlotSettings_splitAxis(fig, ax, 'Best sound elevation (\\u00B0)', 'Median best visual elevation (\\u00B0)', '',mySize=5)\n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best sound elevation, AC-boutons', 'Best visual elevation, VC-neurons', '',mySize=15)\n",
    "\n",
    "    plt.yticks([2-(20/18),2,2+(20/18),2+(40/18)], ['-20','0', '20', '40'])\n",
    "    plt.ylim([2-(20/18),2+(40/18)])\n",
    "    plt.xticks([2-(20/18),2,2+(20/18),2+(40/18)], ['-20','0', '20', '40'])\n",
    "    plt.xlim([2-(20/18),2+(40/18)])\n",
    "    plt.plot([0,4],[0,4], color='gray', linewidth=0.25)\n",
    "    # plt.plot(lm['x_vals'], lm['y_vals'], c = 'b')\n",
    "    plt.text(2-(20/18),3.5, 'r: ' + str(np.round(lm['corr'],3)) + '\\np: ' + str(np.round(res[x_axis][0][1],3)),fontsize=15)\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "\n",
    "    # fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\elevationCorrelation_byArea.svg'))\n",
    "    #%%\n",
    "    return vals_green, vals_red\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03184c7-56ee-49fe-8880-eccc92daafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotElevation_spatialBins_acrossMod(ref,df, maps, peak,df_red,ops, b =300, mask ='none'):\n",
    "    \n",
    "    elev = getElevation_greenAud(df, maps, peak)\n",
    "    \n",
    "    df['peak'] = elev\n",
    "    # df = df.iloc[includeIdx]\n",
    "    \n",
    "    df = df[~df['x'].isnull()]\n",
    "    df = df[~df['y'].isnull()]\n",
    "    df = df[df['x'] != 0]\n",
    "    df = df[df['y'] != 0]\n",
    "    df = df[df['area'] != 'OUT']\n",
    "    \n",
    "    mapsPath =  'Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\retinotopyMaps\\\\'\n",
    "    map_V1 = imageio.imread(os.path.join(mapsPath,'Reference_map_allen_V1Marked.png'))\n",
    "        \n",
    "    binned_map = makeSpatialBinnedMap(ref,spatialBin =b) \n",
    "    binned_values_map = makeMeanValue_bySpatialBin_v2(df, binned_map,thresh =5,  varName = 'peak', mask =mask, V1_mask = map_V1)\n",
    "\n",
    "    bins_unique = np.unique(binned_map)\n",
    "    binValues_green = getBinValues(binned_map, binned_values_map, ops['map_colors'], ops['colors_LUT'])\n",
    "\n",
    "    #now red\n",
    "    df_red = df_red[~df_red['x'].isnull()]\n",
    "    df_red = df_red[~df_red['y'].isnull()]\n",
    "    df_red = df_red[df_red['x'] != 0]\n",
    "    df_red = df_red[df_red['y'] != 0]\n",
    "    df_red = df_red[df_red['area'] != 'OUT']\n",
    "    \n",
    "    data = np.array(df_red['elevPeak'])\n",
    "    df_red['elevPeak_inv'] = abs(np.nanmax(data)- data)   #flip it around so that max is top led location\n",
    "    \n",
    "    mapsPath =  'Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\retinotopyMaps\\\\'\n",
    "    map_V1 = imageio.imread(os.path.join(mapsPath,'Reference_map_allen_V1Marked.png'))\n",
    "        \n",
    "    # b = 250\n",
    "    binned_map = makeSpatialBinnedMap(ref,spatialBin =b) \n",
    "    binned_values_map = makeMeanValue_bySpatialBin_v2(df_red, binned_map,thresh =5,  varName = 'elevPeak_inv', mask = mask, V1_mask = map_V1)\n",
    "    \n",
    "    binValues_red = getBinValues(binned_map, binned_values_map, ops['map_colors'], ops['colors_LUT'])\n",
    "    \n",
    "    vals_green, vals_red, valArea = [],[],[]\n",
    "    for i in range(len(binValues_red)):\n",
    "        if not np.isnan(binValues_red['values'][i]) and not np.isnan(binValues_green['values'][i]):\n",
    "            vals_green.append(binValues_green['values'][i])\n",
    "            vals_red.append(binValues_red['values'][i])\n",
    "            valArea.append(binValues_green['binArea'][i])\n",
    "\n",
    "    vals_green = np.array(vals_green)\n",
    "    vals_red = np.array(vals_red)\n",
    "    \n",
    "    areaColors = ops['myColorsDict']['HVA_colors']\n",
    "    colors = np.array([areaColors[valArea[j]] for j in range(len(valArea))])\n",
    "\n",
    "    fig = plt.figure(figsize=(ops['mm']*100,ops['mm']*100), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.scatter(vals_red, vals_green, s=25,facecolors =colors,alpha =0.5, linewidth=0)\n",
    "    lm = doLinearRegression_withCI(vals_red, vals_green)\n",
    "    plt.plot(lm['x_vals'], lm['y_vals'],c = 'k',linestyle='dashed',linewidth = 2)\n",
    "    plt.fill_between(lm['x_vals'], lm['ci_lower'], lm['ci_upper'], facecolor = 'silver',alpha = 0.3)\n",
    "    plt.text(1,3.4, 'r: ' + str(np.round(lm['corr'],3)) + '\\np: ' + str(np.round(lm['pVal_corr'],3)), fontsize=15)\n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best sound elevation, AC-boutons', 'Best visual elevation, VC-neurons', '',mySize=15)\n",
    "    plt.yticks([2-(20/18),2,2+(20/18),2+(40/18)], ['-20','0', '20', '40'])\n",
    "    plt.xticks([2-(20/18),2,2+(20/18),2+(40/18)], ['-20','0', '20', '40'])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
