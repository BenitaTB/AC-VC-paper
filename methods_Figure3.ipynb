{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc456a1-a874-417b-ba6f-dd4dff02afeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import AxesGrid\n",
    "from scipy import stats\n",
    "import statsmodels.stats.multitest\n",
    "from sklearn.neighbors import KernelDensity\n",
    "import os\n",
    "import pims\n",
    "from tqdm import tqdm\n",
    "import sys\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import imageio\n",
    "import scipy\n",
    "from matplotlib import gridspec\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "\n",
    "%run analysis_utils.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64490c78-b3ae-4991-a462-d8933c71b105",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantifySignificance_frequencies(df,ops):\n",
    "    # df = df_freq_peak\n",
    "    areas = ops['areas']\n",
    "    #%\n",
    "    nSDs = 1\n",
    "    #####################################################\n",
    "    #get responsive ones \n",
    "    # green_aud_resp_idx, _ = G.applySignificanceTests(df, modality = 'green_aud',extra = '', sig_policy = 'responsive_maxWilcoxon', nSDs = nSDs, alpha = 0.05, capped = 1, GLM=1)\n",
    "    green_aud_resp_idx = np.load(os.path.join(ops['dataPath'],'frequencies_dataset','responsive_idx_freq_boutons.npy'))\n",
    "    df_green_aud_resp = df.iloc[green_aud_resp_idx]\n",
    "\n",
    "    green_aud_prop_resp = makeProportions_bySession_v2(df_green_aud_resp, df) #includes responsive to both\n",
    "    green_aud_prop_resp_median = np.nanmedian(green_aud_prop_resp)\n",
    "    \n",
    "    #####################################################\n",
    "    #divide responsive sessions by area\n",
    "    areas_green_aud = asignAreaToSession(df, policy='mostRois')\n",
    "    green_aud_resp_byArea = divideSessionsByArea(green_aud_prop_resp, areas, areas_green_aud)\n",
    "    \n",
    "    #############################################\n",
    "    #get selective\n",
    "    # green_aud_selective_freq, _ = G.applySignificanceTests(df, modality = 'green_aud',extra = '', dimension = 'long', sig_policy = 'selective_maxWilcoxon', nSDs = nSDs, alpha = 0.05, capped = 1, GLM=1)\n",
    "    # green_aud_selective_vol, _ = G.applySignificanceTests(df, modality = 'green_aud',extra = '', dimension = 'short', sig_policy = 'selective_maxWilcoxon', nSDs = nSDs, alpha = 0.05, capped = 1, GLM=1)\n",
    "    # # green_aud_selective_int, _ = G.applySignificanceTests(df, modality = 'green_aud',extra = '', dimension = 'int', sig_policy = 'selective_maxWilcoxon', nSDs = nSDs, alpha = 0.05, capped =1, GLM=1)\n",
    "    # np.save(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\data_axonsPaper\\\\frequencies_dataset\\\\selective_freq_idx_axons.npy'), green_aud_selective_freq)\n",
    "    # np.save(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\data_axonsPaper\\\\frequencies_dataset\\\\selective_vol_idx_axons.npy'), green_aud_selective_vol)\n",
    "    \n",
    "    green_aud_selective_freq = np.load(os.path.join(ops['dataPath'],'frequencies_dataset', 'selective_freq_idx_boutons.npy'))\n",
    "    green_aud_selective_vol = np.load(os.path.join(ops['dataPath'],'frequencies_dataset', 'selective_vol_idx_boutons.npy'))\n",
    "\n",
    "    df_sel_freq = df.iloc[green_aud_selective_freq]\n",
    "    df_sel_vol = df.iloc[green_aud_selective_vol]\n",
    "   \n",
    "    #####################################\n",
    "    #make the proportions selective\n",
    "    green_aud_prop_sel_freq = makeProportions_bySession_v2(df_sel_freq, df_green_aud_resp)\n",
    "    green_aud_prop_sel_median_freq = np.nanmedian(green_aud_prop_sel_freq)\n",
    "\n",
    "    green_aud_prop_sel_vol = makeProportions_bySession_v2(df_sel_vol, df_green_aud_resp)\n",
    "    green_aud_prop_sel_median_vol = np.nanmedian(green_aud_prop_sel_vol)\n",
    "\n",
    "    #########################################\n",
    "    #assign area to session\n",
    "    areas_green_aud = asignAreaToSession(df, policy='mostRois')\n",
    "    green_aud_sel_byArea_freq = divideSessionsByArea(green_aud_prop_sel_freq, areas, areas_green_aud)\n",
    "    green_aud_sel_byArea_vol = divideSessionsByArea(green_aud_prop_sel_vol, areas, areas_green_aud)\n",
    "  \n",
    "    # Save for LMM\n",
    "    sessionRef = makeSessionReference(df_green_aud_resp)\n",
    "\n",
    "    notOut = np.nonzero(np.array(areas_green_aud['areas']) != 'OUT')[0]\n",
    "    df_props_forTest = pd.DataFrame({'proportion_resp': np.array(green_aud_prop_resp)[notOut],\n",
    "                                     'proportion_sel_freq': np.array(green_aud_prop_sel_freq)[notOut],\n",
    "                                      'proportion_sel_vol': np.array(green_aud_prop_sel_vol)[notOut],\n",
    "                                    'area': np.array(areas_green_aud['areas'])[notOut], \n",
    "                                    'animal':  np.array(areas_green_aud['animals'])[notOut],\n",
    "                                    'Inj_DV': np.array(sessionRef['pos_DV'])[notOut],\n",
    "                                    'Inj_AP': np.array(sessionRef['pos_AP'])[notOut],\n",
    "                                    'prop_ventral': np.array(sessionRef['prop_ventral'])[notOut]})#\n",
    "    df_path = os.path.join(ops['outputPath'], 'prop_freq_forLMM.csv')\n",
    "    df_props_forTest.to_csv(df_path)\n",
    "    \n",
    "    \n",
    "    #%%\n",
    "    #Plot freq. sel alone, for main figure\n",
    "    meanLineWidth =0.25\n",
    "    meanLineWidth_small =0.25\n",
    "    fig = plt.figure(figsize=(ops['mm']*80, ops['mm']*80),constrained_layout=True)\n",
    "    ax0 = fig.add_subplot(1,1,1)\n",
    "    plt.plot([- meanLineWidth, meanLineWidth], [green_aud_prop_sel_median_freq,green_aud_prop_sel_median_freq],linewidth = 2,c = 'k',zorder =2, alpha=1)     \n",
    "    xVals_scatter = np.random.normal(loc =0,scale =0.05,size = len(green_aud_prop_sel_freq)) \n",
    "    plt.scatter(xVals_scatter, np.array(green_aud_prop_sel_freq), s = 10, facecolors = 'white' , edgecolors ='k', linewidths =0.5,zorder = 1,alpha =0.3)\n",
    "   \n",
    "    data = green_aud_sel_byArea_freq\n",
    "    # ref =  green_aud_prop_sel_median_azi\n",
    "    data_medians_byArea = np.array([np.nanmedian(data[j]) for j in range(len(data))])       \n",
    "    # pVals = doWilcoxon_againstRef(data, ref, multiComp = 'hs')\n",
    "    \n",
    "    formula = 'proportion_sel_freq ~ area + Inj_DV + Inj_AP + (1|animal)'                 \n",
    "    p_LMM, all_pVals = eng.linearMixedModel_fromPython_anova_multiVar(df_path, formula, nargout=2)\n",
    "    \n",
    "    ylim_sel = [-0.05, 1.05]       \n",
    "    # upper = [np.percentile(shuffled_prop_sel_azi[j,:], 97.5) for j in range(len(areas))]\n",
    "    # lower = [np.percentile(shuffled_prop_sel_azi[j,:], 2.5) for j in range(len(areas))]\n",
    "    # t,p_kruskal = stats.kruskal(data[0],data[1],data[2],data[3],data[4],data[5],data[6],data[7],data[8],data[9])\n",
    "    # plt.hlines(prop_sel_azi_sh, 1,len(areas) +2, linestyle = 'dashed', linewidth =1, color ='k')\n",
    "         \n",
    "    plt.vlines(1,0, ylim_sel[-1], linewidth = 0.5, color = 'gray',zorder =0)\n",
    "    for i in range(len(areas)):\n",
    "        plt.plot([i-meanLineWidth_small+2,i+meanLineWidth_small+2], [data_medians_byArea[i],data_medians_byArea[i]] , linewidth = 2, c = ops['myColorsDict']['HVA_colors'][ops['areas'][i]],zorder = 2, alpha =1)\n",
    "        xVals_scatter = np.random.normal(loc =i+2,scale =0.05,size = len(data[i])) \n",
    "        plt.scatter(xVals_scatter, data[i], s = 10, facecolors = 'white' , edgecolors =  ops['myColorsDict']['HVA_colors'][ops['areas'][i]], linewidths =0.5,zorder = 1, alpha =0.3) \n",
    "        if p_LMM < 0.05:\n",
    "            p_mannWhitney, compIdx = doMannWhitneyU_forBoxplots(data, multiComp = 'fdr')\n",
    "            cnt = 0\n",
    "            for c in range(len(compIdx)):\n",
    "                if p_mannWhitney[c] < 0.05:\n",
    "                    pos = compIdx[c].split('_')\n",
    "                    plt.hlines(ylim_sel[-1] - cnt, int(pos[0] + 2), int(pos[1] +2), colors = 'k')                    \n",
    "                    cnt +=0.01\n",
    "        # t, p_signRank = stats.wilcoxon(data[i]-prop_sel_azi_sh)\n",
    "        # if p_signRank < 0.05:\n",
    "        #     plt.text(i+2,ylim_resp[-1] -0.1, '*', fontsize=10)\n",
    "        #     print(str(p_signRank))\n",
    "        \n",
    "                \n",
    "    plt.ylim(ylim_sel)\n",
    "    # plt.yticks(yTickValues_resp)\n",
    "    # ax0.xaxis.set_ticklabels([])\n",
    "    # ax0.xaxis.set_ticks([])\n",
    "    plt.yticks([0,0.5, 1], ['0','50', '100'])\n",
    "    myPlotSettings_splitAxis(fig,ax0,'Percentage of boutons (%)','',str(p_LMM), mySize=15)  \n",
    "    plt.xticks([0,2,3,4,5,6,7,8,9,10,11], np.append('All',areas), rotation =90)\n",
    "    plt.xlim([-1, 12])\n",
    "    ax0.tick_params(axis='y', pad=1)   \n",
    "    ax0.tick_params(axis='x', pad=1) \n",
    "    # fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\propfrequencytuned_byArea.svg'))\n",
    "\n",
    "    #%% Proportions for all sessions together\n",
    "\n",
    "    ylim_resp = [-0.05,1.05]\n",
    "        \n",
    "    meanLineWidth = 0.5\n",
    "    meanLineWidth_small = 0.3\n",
    "    color_gray_dashedline = 'gray'\n",
    "   \n",
    "    fig = plt.figure(figsize=(50*ops['mm'], 80*ops['mm']), constrained_layout=True)\n",
    "\n",
    "    # green aud, responsive\n",
    "    ax0 = fig.add_subplot(1,1,1)\n",
    "    xVals_scatter = np.random.normal(loc =0,scale =0.08,size = len(green_aud_prop_resp)) \n",
    "    plt.scatter(xVals_scatter, np.array(green_aud_prop_resp), s = 8, facecolors = 'white' , edgecolors = 'k', linewidths =0.5,zorder = 1)\n",
    "    plt.plot([- 0.4, 0.4], [green_aud_prop_resp_median,green_aud_prop_resp_median],linewidth = 3,c = 'k',zorder =2)     \n",
    "\n",
    "\n",
    "    plt.ylim(ylim_resp)\n",
    "    # plt.yticks(yTickValues_resp)\n",
    "    # ax0.xaxis.set_ticklabels([])\n",
    "    # ax0.xaxis.set_ticks([])\n",
    "    myPlotSettings_splitAxis(fig,ax0,'Percentage of boutons (%)','','', mySize=15)  \n",
    "    # plt.gca().set_xticklabels([])\n",
    "    plt.xticks([0], ['Responsive'])\n",
    "    plt.ylim([0,1])\n",
    "    plt.yticks([0,0.5, 1],['0','50', '100'] )\n",
    "    \n",
    "    fig = plt.figure(figsize=(80*ops['mm'], 80*ops['mm']), constrained_layout=True)\n",
    "    \n",
    "    # green aud, responsive\n",
    "    ax0 = fig.add_subplot(1,1,1)\n",
    "    # green aud, selective\n",
    "    xVals_scatter = np.random.normal(loc =0,scale =0.08,size = len(green_aud_prop_sel_freq)) \n",
    "    plt.scatter(xVals_scatter, np.array(green_aud_prop_sel_freq), s = 8, facecolors = 'white' , edgecolors = 'k', linewidths =0.5)\n",
    "    plt.plot([- meanLineWidth_small, meanLineWidth_small], [green_aud_prop_sel_median_freq,green_aud_prop_sel_median_freq],linewidth = 3,c = 'k')     \n",
    "\n",
    "    xVals_scatter = np.random.normal(loc =1,scale =0.08,size = len(green_aud_prop_sel_vol)) \n",
    "    plt.scatter(xVals_scatter, np.array(green_aud_prop_sel_vol), s = 8, facecolors = 'white' , edgecolors = 'k', linewidths =0.5)\n",
    "    plt.plot([- meanLineWidth_small +1,meanLineWidth_small+1], [green_aud_prop_sel_median_vol,green_aud_prop_sel_median_vol],linewidth = 3,c = 'k')     \n",
    "\n",
    "    # xVals_scatter = np.random.normal(loc =2,scale =0.08,size = len(green_aud_prop_sel_int)) \n",
    "    # plt.scatter(xVals_scatter, np.array(green_aud_prop_sel_int), s = 8, facecolors = 'white' , edgecolors = 'k', linewidths =0.5)\n",
    "    # plt.plot([- meanLineWidth_small+2, meanLineWidth_small+2], [green_aud_prop_sel_median_int,green_aud_prop_sel_median_int],linewidth = 3,c = 'k')     \n",
    "\n",
    "    plt.ylim(ylim_sel)\n",
    "    plt.yticks([0,0.5,1], ['0', '50', '100'])\n",
    "    # plt.yticks(yTickValues_resp)\n",
    "    # ax0.xaxis.set_ticklabels([])\n",
    "    # ax0.xaxis.set_ticks([])\n",
    "    myPlotSettings_splitAxis(fig,ax0,'Percentage of boutons (%)','','',mySize=15)  \n",
    "    plt.xticks([0,1], ['Frequency', 'Sound intensity'], rotation = 0)\n",
    "    \n",
    "    # fig.savefig(os.path.join(pathStart, 'home', 'shared', 'Alex_analysis_camp', 'Thesis_figures','Frequencies','Prop_sel_freq.svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e3b0a21-d3e7-4410-b042-69eb1ae346dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFreqDistribution_byArea(df, data, ops, fig):\n",
    "    from matplotlib import gridspec\n",
    "    \n",
    "    gs = gridspec.GridSpec(5, 2, figure=fig, hspace=0.4, wspace=0.25,left=0.1, right=0.95, bottom=0.1, top=0.92)\n",
    "    \n",
    "    x_interp= np.linspace(0, 10.1, 1000)\n",
    "    freq_byArea = []\n",
    "    cnt = 0\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        \n",
    "        if np.mod(cnt,2) ==0:\n",
    "            k = 0\n",
    "        else:\n",
    "            k=1\n",
    "        ax = fig.add_subplot(gs[int(np.floor(cnt/2)), k])\n",
    "        # ax = fig.add_subplot(gs[ar, 0])\n",
    "\n",
    "        idx_thisArea = np.nonzero(np.array(df['area']) == ops['areas'][ar])[0]\n",
    "\n",
    "        data_thisArea = np.array(data[idx_thisArea])\n",
    "        data_all = data.copy()\n",
    "        \n",
    "        freq_byArea.append(np.squeeze(data_thisArea))\n",
    "\n",
    "        kde = KernelDensity(bandwidth=0.5, kernel='gaussian')               #density of 0.7 is nice\n",
    "        kde.fit(data_thisArea.reshape(-1,1))\n",
    "        logprob = kde.score_samples(x_interp.reshape(-1,1))\n",
    "        plt.plot(x_interp, np.exp(logprob), alpha=1, linewidth = 2, color = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]]) \n",
    "        # plt.fill_between(x_interp, np.exp(logprob), alpha=0.3, color =  ops['myColorsDict']['HVA_colors'][ops['areas'][ar]])\n",
    "        \n",
    "        kde = KernelDensity(bandwidth=0.5, kernel='gaussian')               #density of 0.7 is nice\n",
    "        kde.fit(data_all.reshape(-1,1))\n",
    "        logprob = kde.score_samples(x_interp.reshape(-1,1))\n",
    "        plt.fill_between(x_interp, np.exp(logprob), alpha=1, color = '#C8C6C6')\n",
    "\n",
    "       \n",
    "        # plt.plot(x_interp, np.exp(logprob), alpha=1, linewidth = 0.25, color = 'k') \n",
    "        # plt.scatter(np.median(data_all), 0.29, marker ='v', s= 30, color = 'k')\n",
    "        # plt.scatter(np.median(data_thisArea), 0.29, marker ='v', s= 30, color = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]])\n",
    "\n",
    "        if k ==0:\n",
    "            plt.yticks([0,0.3], ['0','30'])\n",
    "        else:\n",
    "            plt.yticks([0,0.3], ['',''])\n",
    "\n",
    "        # U, p = stats.mannwhitneyu(data_thisArea,data_all)\n",
    "        # plt.vlines(np.nanmedian(data_thisArea), 0, 0.25, color='r')\n",
    "        if ar ==8:\n",
    "            myPlotSettings_splitAxis(fig, ax, 'Percentage of boutons (%)', 'Best tone frequency (kHz)', '', mySize=15)\n",
    "            plt.xticks(np.arange(0,11,2),ops['freq_names'],rotation =0)\n",
    "        elif ar == 9:\n",
    "            myPlotSettings_splitAxis(fig, ax, '', '', '', mySize=15)\n",
    "            plt.xticks(np.arange(0,11,2),ops['freq_names'],rotation =0)\n",
    "        else:\n",
    "            ax.spines[\"bottom\"].set_visible(False)\n",
    "            plt.xticks([],[])\n",
    "            myPlotSettings_splitAxis(fig, ax, '', '', '', mySize=15)\n",
    "\n",
    "        # if p < 0.05: \n",
    "        #     plt.text(5,0.25,'*', fontsize=10)\n",
    "        if ops['areas'][ar] == 'POR':\n",
    "            plt.text(5.4, 0.26, 'POR',  fontsize=15, horizontalalignment ='center')\n",
    "            # plt.text(5.4, 0.26, ops['areas'][ar], horizontalalignment ='center', weight='bold')\n",
    "        else:\n",
    "            plt.text(5.4, 0.26, ops['areas'][ar], fontsize=15, horizontalalignment ='center')\n",
    "        # plt.text(0,0.23,  'n: ' + str(len(data_thisArea)), fontsize=5)\n",
    "        # plt.text(6,0.23,  ops['areas'][ar], fontsize=5, weight ='bold')\n",
    "        \n",
    "        plt.xlim([0,10])\n",
    "        plt.ylim([0,0.3])\n",
    "        ax.tick_params(axis='y', pad=1)   \n",
    "        ax.tick_params(axis='x', pad=1)   \n",
    "        ax.tick_params(axis='both', length=2)  # Change tick length for both axes\n",
    "\n",
    "        # plt.legend()\n",
    "        cnt += 1\n",
    "    \n",
    "    \n",
    "    # fig, ax = plt.subplots(figsize = (12,5))\n",
    "    # vp = ax.violinplot(freq_byArea, positions = np.arange(0,len(ops['areas'])), vert =True, bw_method = 0.3,widths=0.7, showmedians = False, showextrema = False)\n",
    "\n",
    "    # for ar in range(len(ops['areas'])):\n",
    "    #     body = vp['bodies'][ar]\n",
    "    #     body.set_facecolor(ops['myColorsDict']['HVA_colors'][ops['areas'][ar]])\n",
    "    #     body.set_edgecolor(ops['myColorsDict']['HVA_colors'][ops['areas'][ar]])\n",
    "    #     body.set_linewidth(1)\n",
    "    #     body.set_alpha(0.8)\n",
    "    # plt.xticks(np.arange(0,len(areas)), areas)\n",
    "    \n",
    "    \n",
    "    # plt.yticks(np.arange(0,13,2), ['-108', '-72', '-36', '0', '36', '72', '108'])\n",
    "    # myPlotSettings(fig,ax, 'Sound source azimuth','Area','') \n",
    "    fig = plt.figure(figsize=(ops['mm']*100, ops['mm']*100),constrained_layout=True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    x_interp= np.linspace(0, 10.1, 1000)\n",
    "\n",
    "    kde = KernelDensity(bandwidth=0.7, kernel='gaussian')               \n",
    "    kde.fit(data.reshape(-1,1))\n",
    "    logprob = kde.score_samples(x_interp.reshape(-1,1))\n",
    "    plt.plot(x_interp, np.exp(logprob), alpha=1, linewidth =1, color = 'k') \n",
    "    plt.fill_between(x_interp, np.exp(logprob), alpha=0.4, color = 'grey')\n",
    "    myPlotSettings_splitAxis(fig, ax, 'Percentage of boutons (%)', 'Best tone frequency (kHz)', '', mySize=15)\n",
    "    plt.xticks(np.arange(0,11,2),ops['freq_names'] )\n",
    "    plt.xlim([0,10])\n",
    "    plt.ylim([0, 0.2])\n",
    "    plt.yticks([0,0.1,0.2], ['0','10', '20'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c776b897-323e-437f-bd83-fc06b2f95c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHierarchicalBootstrap_FV(name, ops):\n",
    "    \n",
    "    path = os.path.join(ops['dataPath'], 'frequencies_dataset',name)\n",
    "    files = os.listdir(path)\n",
    "    nBatch = len(np.nonzero(np.array([name in files[i] for i in range(len(files))]) > 0.5)[0])\n",
    "    \n",
    "    median_dist_mat,p_difference_quantiles,sigLevels_quantiles,groups = getBootstrapResult(path,name, nBatch,ops,doMultiCorr=1)\n",
    "    \n",
    "    colors = sns.color_palette('binary', n_colors =100)\n",
    "    myColors = [colors[10], colors[40], colors[60], colors[80]]\n",
    "\n",
    "    xLabels = ops['areas'].copy()\n",
    "    # xLabels.append('Shuffle')\n",
    "\n",
    "    # p_adj = p_difference_quantiles.copy()\n",
    "    # for i in range(p_difference_quantiles.shape[0]):\n",
    "    #     for j in range(p_difference_quantiles.shape[1]):\n",
    "            \n",
    "    fig = plt.figure(figsize=(ops['mm']*70, ops['mm']*70),constrained_layout =True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    # plt.title('Ipsi, 5 an')\n",
    "      \n",
    "    plt.imshow(median_dist_mat, cmap = 'Oranges',vmin =0, vmax =2)\n",
    "    cbar = plt.colorbar(ticks = [0, 0.5, 1, 1.5, 2],fraction = 0.05, pad = 0.05)\n",
    "    cbar.ax.set_yticklabels(['0', '0.25', '0.5', '0.75', '1'], fontsize=7)\n",
    "    \n",
    "    plt.imshow(sigLevels_quantiles, cmap = LinearSegmentedColormap.from_list('myMap', myColors, N=4), vmax = 3) \n",
    "    cbar = plt.colorbar(ticks = [0.4, 1.15, 1.9, 2.62], fraction = 0.05, pad = 0.07)\n",
    "    cbar.ax.set_yticklabels(['N.S.', 'p < 0.05', 'p < 0.01', 'p < 0.001'], fontsize=7)\n",
    " \n",
    "    plt.xticks(np.arange(0,len(ops['areas'])), xLabels, rotation =90,fontsize=7)\n",
    "    plt.yticks(np.arange(0,len(ops['areas'])), ops['areas'],fontsize=7)\n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(1.5)\n",
    "        \n",
    "    fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\hierarchicalBootstrap_freq_medianComparison_boutons.svg'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65cabd18-a462-4806-9a54-7697995f12de",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFrequency_bySession(df, data,ops, eng,fig):\n",
    "    \n",
    "    sessionRef = makeSessionReference(df)\n",
    "   \n",
    "    sessionIdx_unique = np.array(sessionRef['seshIdx'])\n",
    "    meanFreqs = []\n",
    "    for j in range(len(sessionIdx_unique)):\n",
    "        idx_thisSession = np.nonzero(np.array(df['sessionIdx']) == sessionIdx_unique[j])[0]\n",
    "        if len(idx_thisSession) > 10:\n",
    "            meanFreqs.append(np.nanmedian(data[idx_thisSession]))\n",
    "        else:\n",
    "            meanFreqs.append(np.nan)\n",
    "\n",
    "    notOut = np.nonzero(np.array(sessionRef['seshAreas']) != 'OUT')[0]\n",
    "    notNan = np.nonzero(np.isnan(np.array(meanFreqs)) <0.5)[0]\n",
    "    these = np.intersect1d(notOut,notNan)\n",
    "    df_freqs_forTest = pd.DataFrame({'freqMedian': np.array(meanFreqs)[these],\n",
    "                                    'area': np.array(sessionRef['seshAreas'])[these], \n",
    "                                    'animal':  np.array(sessionRef['seshAnimal'])[these], \n",
    "                                    'Inj_DV': np.array(sessionRef['pos_DV'])[these],\n",
    "                                    'Inj_AP': np.array(sessionRef['pos_AP'])[these],\n",
    "                                    'prop_ventral': np.array(sessionRef['prop_ventral'])[these]})\n",
    "    \n",
    "    df_path = os.path.join(ops['outputPath'], 'freq_forLMM.csv')\n",
    "    df_freqs_forTest.to_csv(df_path)\n",
    "    \n",
    "    formula = 'freqMedian ~ area + Inj_DV + Inj_AP + (1|animal)'                 \n",
    "    p_LMM, all_pVals = eng.linearMixedModel_fromPython_anova_multiVar(df_path, formula, nargout=2)\n",
    "    # this = np.float64(all_pVals[0][0])\n",
    "    \n",
    "    #New shuffles\n",
    "    nShuffles = 1000\n",
    "    N = 200\n",
    "    freq_sh = []\n",
    "    for n in range(nShuffles):\n",
    "        rand = np.random.choice(np.arange(0,len(df)), N, replace =True)\n",
    "        \n",
    "        freq_sh.append(np.nanmedian(data[rand]))\n",
    "        \n",
    "    freq_sh = np.mean(freq_sh)\n",
    "        \n",
    "    \n",
    "    meanFreqs = np.array(meanFreqs) \n",
    "    areaIdx = np.array(sessionRef['seshAreas'])\n",
    "    meanFreqs_byArea = []\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        these = np.nonzero(areaIdx == ops['areas'][ar])\n",
    "        vals_bySession_this = meanFreqs[these]\n",
    "        vals_bySession_this_clean = vals_bySession_this[np.nonzero(np.isnan(vals_bySession_this) < 0.5)[0]]\n",
    "\n",
    "        meanFreqs_byArea.append(vals_bySession_this_clean)\n",
    "  \n",
    "    data = meanFreqs_byArea\n",
    "    data_means_byArea = np.array([np.nanmedian(data[j]) for j in range(len(data))])       \n",
    "   \n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    # plt.hlines(freq_sh, -0.5,9.5,linewidth=1, color='k', linestyle ='dashed')\n",
    "    p_wilcox_byArea =[]\n",
    "    for i in range(len(ops['areas'])):\n",
    "       \n",
    "        plt.plot([i-0.25,i+0.25], [data_means_byArea[i],data_means_byArea[i]] , linewidth = 2, c =ops['myColorsDict']['HVA_colors'][ops['areas'][i]],zorder = 2)\n",
    "        xVals_scatter = np.random.normal(loc =i,scale =0.05,size = len(data[i])) \n",
    "        plt.scatter(xVals_scatter, data[i], s = 20, facecolors = 'white' , edgecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][i]], linewidths =0.5,zorder = 1, alpha=0.3) \n",
    "       \n",
    "        U,p_wilcox = stats.wilcoxon(data[i] - freq_sh) \n",
    "        p_wilcox_byArea.append(p_wilcox)\n",
    "        #print(str(p_wilcox))\n",
    "    \n",
    "    pVals_adj = statsmodels.stats.multitest.multipletests(np.array(p_wilcox_byArea), method='fdr_bh')[1]            \n",
    "\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        if pVals_adj[ar] < 0.05:\n",
    "            plt.text(ar,9, '*', fontsize=10)\n",
    "            \n",
    "        \n",
    "    plt.yticks([0,2,4,6,8,10], ['2','4','8', '16', '32','64']) \n",
    "    plt.ylim([0,10])\n",
    "    # plt.xlim(-1, 5.5)               \n",
    "    myPlotSettings_splitAxis(fig,ax,'Median best frequency (kHz)','',str(p_LMM), mySize=15) \n",
    "\n",
    "    if p_LMM < 0.05:\n",
    "        pVals_adj_mannU, compIdx = doMannWhitneyU_forBoxplots(meanFreqs_byArea, multiComp = 'hs')\n",
    "        cnt=0     \n",
    "        for j in range(len(pVals_adj_mannU)):\n",
    "            if pVals_adj_mannU[j] < 0.05:\n",
    "                plt.hlines(6-cnt, int(compIdx[j][0]), int(compIdx[j][2]), color = 'k')\n",
    "                cnt = cnt + 0.2\n",
    "                \n",
    "    plt.xticks(np.arange(0,len(ops['areas'])), ops['areas'], rotation=90)\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "598eb8dd-29fd-462d-874b-090d41fa5a57",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFreqDistribution_byStream(df, data, ops, eng):\n",
    "    \n",
    "    t = []\n",
    "    for i in range(len(df)):\n",
    "        if df['area'].iloc[i] in ops['dorsal']:\n",
    "            t.append('Dorsal')\n",
    "        elif df['area'].iloc[i] in ops['ventral']:\n",
    "            t.append('Ventral')\n",
    "        elif df['area'].iloc[i] == 'V1':\n",
    "            t.append('V1')\n",
    "        else:\n",
    "            t.append('')\n",
    "                          \n",
    "    df['streamIdx'] = t\n",
    "       \n",
    "    #Plot it by Session\n",
    "    df['spline_peak'] = data\n",
    "    sessionRef = makeSessionReference(df, varName = ['spline_peak'])\n",
    "            \n",
    "    freq_byStream = []\n",
    "    for ar in range(len(ops['groups'])):\n",
    "        idx_thisArea = np.nonzero(np.array(sessionRef['seshStream']) == ops['groups'][ar])[0]\n",
    "        \n",
    "        freq_this = np.array(sessionRef['myVar'])[idx_thisArea]\n",
    "        idx =np.nonzero(np.isnan(freq_this) < 0.05)[0]\n",
    "        freq_this = freq_this[idx]\n",
    "        freq_byStream.append(freq_this)\n",
    "            \n",
    "    notV1 = np.nonzero(np.array(sessionRef['seshAreas']) != 'V1')[0]\n",
    "    notNan = np.nonzero(np.isnan(np.array(sessionRef['myVar'])) <0.5)[0]\n",
    "    # thisIdx =notNan\n",
    "    thisIdx = np.intersect1d(notV1,notNan)\n",
    "    # seshMapGood = np.nonzero(np.array(sessionRef['seshMapGood']) == 1)[0]\n",
    "    # thisIdx = np.intersect1d(thisIdx, seshMapGood)\n",
    "\n",
    "    df_forTest = pd.DataFrame({'freq_bySession': np.array(sessionRef['myVar'])[thisIdx],                                    \n",
    "                            'area': np.array(sessionRef['seshAreas'])[thisIdx],\n",
    "                            'stream': np.array(sessionRef['seshStream'])[thisIdx],\n",
    "                            'elev': np.array(sessionRef['seshElev'])[thisIdx],\n",
    "                            'animal':  np.array(sessionRef['seshAnimal'])[thisIdx],\n",
    "                            'Inj_DV': np.array(sessionRef['pos_DV'])[thisIdx],\n",
    "                            'Inj_AP': np.array(sessionRef['pos_AP'])[thisIdx],\n",
    "                            'prop_ventral': np.array(sessionRef['prop_ventral'])[thisIdx]\n",
    "                            })\n",
    "    \n",
    "    df_path = os.path.join(ops['outputPath'], 'df_forTest.csv')\n",
    "\n",
    "    df_forTest.to_csv(df_path)\n",
    "    \n",
    "    formula = 'freq_bySession ~ stream + Inj_DV + Inj_AP + (1|animal)'                 \n",
    "    p_LMM, all_pVals = eng.linearMixedModel_fromPython_anova_multiVar(df_path, formula, nargout=2)\n",
    "           \n",
    "    #%%\n",
    "    fig = plt.figure(figsize=(70*ops['mm'], 100*ops['mm']), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    for ar in range(1,len(ops['groups'])):\n",
    "        xVals_scatter = np.random.normal(loc =ar-1,scale =0.05,size = len(freq_byStream[ar])) \n",
    "        plt.plot([ar-1.3,ar+0.3 -1], [np.nanmedian(freq_byStream[ar]),np.nanmedian(freq_byStream[ar])], linewidth = 3, c = ops['colors_groups'][ar],zorder = 2)\n",
    "        plt.scatter(xVals_scatter, np.array(freq_byStream[ar]), s = 20, facecolors = 'white' , edgecolors =  ops['colors_groups'][ar], linewidths =1,zorder = 1,alpha=0.3)\n",
    "           \n",
    "  \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best frequency (kHz)', '', 'p: ' + str(p_LMM),mySize=15)  \n",
    "    plt.xticks([0,1], ['Ventral','Dorsal' ], rotation = 45, horizontalalignment='right')\n",
    "    plt.ylim([2,8])\n",
    "    plt.yticks([2,4,6,8], ['4', '8', '16', '32'])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "\n",
    "   # fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\bestFrequency_twoStreams.svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3729e3a-184d-4bc1-bf47-19ec8302d18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotTuningWidth_byArea(df, data, ops,eng):\n",
    "    # data = width\n",
    "    sessionRef = makeSessionReference(df)\n",
    "   \n",
    "    sessionIdx_unique = np.array(sessionRef['seshIdx'])\n",
    "    meanFreqs = []\n",
    "    for j in range(len(sessionIdx_unique)):\n",
    "        idx_thisSession = np.nonzero(np.array(df['sessionIdx']) == sessionIdx_unique[j])[0]\n",
    "        if len(idx_thisSession) > 10:\n",
    "            meanFreqs.append(np.nanmedian(data[idx_thisSession]))\n",
    "        else:\n",
    "            meanFreqs.append(np.nan)\n",
    "\n",
    "    notOut = np.nonzero(np.array(sessionRef['seshAreas']) != 'OUT')[0]\n",
    "    notNan = np.nonzero(np.isnan(np.array(meanFreqs)) <0.5)[0]\n",
    "    these = np.intersect1d(notOut,notNan)\n",
    "    df_freqs_forTest = pd.DataFrame({'freqMedian': np.array(meanFreqs)[these],\n",
    "                                    'area': np.array(sessionRef['seshAreas'])[these], \n",
    "                                    'animal':  np.array(sessionRef['seshAreas'])[these],\n",
    "                                    'Inj_DV': np.array(sessionRef['pos_DV'])[these],\n",
    "                                    'Inj_AP': np.array(sessionRef['pos_AP'])[these],\n",
    "                                    'prop_ventral': np.array(sessionRef['prop_ventral'])[these]})#\n",
    "    \n",
    "    df_path = os.path.join(ops['outputPath'], 'freq_forLMM.csv')\n",
    "    df_freqs_forTest.to_csv(df_path)\n",
    "    \n",
    "    formula = 'freqMedian ~ area + Inj_DV + Inj_AP + (1|animal)'                 \n",
    "    p_LMM, all_pVals = eng.linearMixedModel_fromPython_anova_multiVar(df_path, formula, nargout=2)\n",
    "           \n",
    "    meanFreqs = np.array(meanFreqs) \n",
    "    areaIdx = np.array(sessionRef['seshAreas'])\n",
    "    meanFreqs_byArea = []\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        these = np.nonzero(areaIdx == ops['areas'][ar])\n",
    "        vals_bySession_this = meanFreqs[these]/2\n",
    "        vals_bySession_this_clean = vals_bySession_this[np.nonzero(np.isnan(vals_bySession_this) < 0.5)[0]]\n",
    "\n",
    "        meanFreqs_byArea.append(vals_bySession_this_clean)\n",
    "  \n",
    "    #Division by 2 is to put it in octaves\n",
    "    data = meanFreqs_byArea\n",
    "    data_means_byArea = np.array([np.nanmedian(data[j]) for j in range(len(data))])       \n",
    "    # pVals = doWilcoxon_againstRef(data, ref, multiComp = 'hs')\n",
    "   \n",
    "    # upper = [np.percentile(vals_areaShuffle[j,:], 97.5) for j in range(len(ops['areas']))]\n",
    "    # lower = [np.percentile(vals_areaShuffle[j,:], 2.5) for j in range(len(ops['areas']))]\n",
    "    #%%\n",
    "    fig = plt.figure(figsize=(100*ops['mm'], 100*ops['mm']), constrained_layout=True)\n",
    "    # gs = gridspec.GridSpec(1, 1, figure=fig, hspace=0.7, wspace=0.2,left=0.1, right=0.9, bottom=0.1, top=0.95)\n",
    "    # ax = fig.add_subplot(gs[0, 0])\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    # plt.hlines(freq_sh, -0.5,9.5,linewidth=1, color='k', linestyle ='dashed')\n",
    "    p_wilcox_byArea =[]\n",
    "    for i in range(len(ops['areas'])):\n",
    "       \n",
    "        plt.plot([i-0.25,i+0.25], [data_means_byArea[i],data_means_byArea[i]] , linewidth = 2, c =ops['myColorsDict']['HVA_colors'][ops['areas'][i]],zorder = 2)\n",
    "        xVals_scatter = np.random.normal(loc =i,scale =0.05,size = len(data[i])) \n",
    "        plt.scatter(xVals_scatter, data[i], s = 10, facecolors = 'white' , edgecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][i]], linewidths =0.5,zorder = 1, alpha=0.3) \n",
    "       \n",
    "    myPlotSettings_splitAxis(fig,ax,'Tuning width (octaves)','','p: ' + str(p_LMM), mySize=15) \n",
    "    \n",
    "    if p_LMM < 0.05:\n",
    "        pVals_adj_mannU, compIdx = doMannWhitneyU_forBoxplots(meanFreqs_byArea, multiComp = 'fdr')\n",
    "        cnt=0     \n",
    "        for j in range(len(pVals_adj_mannU)):\n",
    "            if pVals_adj_mannU[j] < 0.05:\n",
    "                plt.hlines(2-cnt, int(compIdx[j][0]), int(compIdx[j][2]), color = 'k', linewidth=0.5)\n",
    "                cnt = cnt + 0.2\n",
    "                \n",
    "    plt.xticks(np.arange(0,len(ops['areas'])), ops['areas'], rotation=90)\n",
    "    plt.yticks([0.5,1,1.5, 2], ['0.5', '1', '1.5', '2'])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d567085-5871-4774-bc41-b2709d64fc2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotProportionComplexFreq(df,includeIdx, doubleIdx, ops, eng):\n",
    "    \n",
    "    #shuffle\n",
    "    nShuffles = 1000\n",
    "    seshIdx_unique = np.unique(df['sessionIdx'])\n",
    "    prop_double = np.empty(len(seshIdx_unique));prop_double[:] = np.nan\n",
    "    for s in range(len(seshIdx_unique)):\n",
    "        idx_thisSession = np.nonzero(np.array(df['sessionIdx']) == seshIdx_unique[s])[0]\n",
    "        \n",
    "        include_thisSession = np.intersect1d(includeIdx, idx_thisSession)\n",
    "        double_thisSesh = np.intersect1d(include_thisSession, doubleIdx)\n",
    "        \n",
    "        if len(include_thisSession) < 20:\n",
    "            continue\n",
    "        \n",
    "        prop_double[s] = len(double_thisSesh)/len(include_thisSession)\n",
    "\n",
    "    sessionRef = makeSessionReference(df)   \n",
    "    \n",
    "    prop_double_byArea = []\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        idx_thisArea = np.nonzero(np.array(sessionRef['seshAreas']) == ops['areas'][ar])[0]\n",
    "        \n",
    "        prop_this = np.array(prop_double[idx_thisArea])\n",
    "        idx =np.nonzero(np.isnan(prop_this) < 0.05)[0]\n",
    "        prop_this = prop_this[idx]\n",
    "        prop_double_byArea.append(prop_this)\n",
    "        \n",
    "    \n",
    "    notOut = np.nonzero(np.array(sessionRef['seshAreas']) != 'OUT')[0]\n",
    "    notNan = np.nonzero(np.isnan(np.array(prop_double)) <0.5)[0]\n",
    "    these = np.intersect1d(notOut,notNan)\n",
    "    df_props_forTest = pd.DataFrame({'prop_double_bySession': np.array(prop_double)[these],\n",
    "                                    'area': np.array(sessionRef['seshAreas'])[these], \n",
    "                                    'animal':  np.array(sessionRef['seshAnimal'])[these],\n",
    "                                    'Inj_DV': np.array(sessionRef['pos_DV'])[these],\n",
    "                                    'Inj_AP': np.array(sessionRef['pos_AP'])[these],\n",
    "                                    'prop_ventral': np.array(sessionRef['prop_ventral'])[these]})#\n",
    "    df_path = os.path.join(ops['outputPath'], 'freq_forLMM.csv')\n",
    "    df_props_forTest.to_csv(df_path)\n",
    "    \n",
    "  \n",
    "    #New shuffles\n",
    "    # nShuffles = 10000\n",
    "    # N = 500\n",
    "    # double_sh =[]\n",
    "    # for n in range(nShuffles):\n",
    "    #     rand = np.random.choice(np.arange(0,len(df)), N, replace =True)\n",
    "        \n",
    "    #     double_sh.append(len(np.intersect1d(doubleIdx, rand))/N)\n",
    "            \n",
    "    # double_sh = np.mean(double_sh)\n",
    "   \n",
    "    \n",
    "    \n",
    "   \n",
    "    formula = 'prop_double_bySession ~ area + Inj_DV + Inj_AP + (1|animal)'                 \n",
    "    p_LMM, all_pVals = eng.linearMixedModel_fromPython_anova_multiVar(df_path, formula, nargout=2)\n",
    "\n",
    "    # plt.figure()\n",
    "    # plt.scatter(df_props_forTest['Inj_DV'],df_props_forTest['prop_double_bySession'])\n",
    "    # nShuffles = 1000\n",
    "    # prop_double_areaShuffle = np.zeros((len(areas), nShuffles))\n",
    "\n",
    "    # for n in range(nShuffles):\n",
    "    #     areas_bySession = np.array(sessionRef['seshAreas'])\n",
    "    #     np.random.shuffle(areas_bySession)\n",
    "    #     for ar in range(len(areas)):  \n",
    "    #         idx = np.nonzero(areas_bySession  == areas[ar])[0]\n",
    "    #         prop_double_areaShuffle[ar,n] = np.nanmedian(prop_double[idx])\n",
    "#%%\n",
    "    #plot it\n",
    "    fig = plt.figure(figsize = (ops['mm']*100,ops['mm']*100), constrained_layout=True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "   \n",
    "    pVals_adj_mannU, compIdx = doMannWhitneyU_forBoxplots(prop_double_byArea, multiComp = 'fdr')\n",
    "    # plt.hlines(double_sh, -0.5,9.5, color='k', linestyle='dashed',linewidth=1)\n",
    "    # upper = [np.percentile(prop_double_areaShuffle[j,:], 97.5) for j in range(len(areas))]\n",
    "    # lower = [np.percentile(prop_double_areaShuffle[j,:], 2.5) for j in range(len(areas))]\n",
    "     \n",
    "    for ar in range(len(ops['areas'])):\n",
    "        xVals_scatter = np.random.normal(loc =ar,scale =0.05,size = len(prop_double_byArea[ar])) \n",
    "        plt.plot([ar-0.25,ar+0.25], [np.nanmedian(prop_double_byArea[ar]),np.nanmedian(prop_double_byArea[ar])], linewidth = 2, c = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]],zorder = 2)\n",
    "        plt.scatter(xVals_scatter, np.array(prop_double_byArea[ar]), s = 7, facecolors = 'white' , edgecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][ar]], linewidths =0.5,zorder = 1,alpha =0.3)\n",
    "        \n",
    "        # plt.fill_between([ar-0.3,ar+0.3],[lower[ar], lower[ar]], [upper[ar],upper[ar]], color= 'gray', alpha = 0.2)\n",
    "        # # plt.hlines(pVals_ks[ar], ar - 0.3,ar + 0.3, color = 'r', label='real')            \n",
    "        # plt.hlines(lower[ar],ar-0.3,ar+0.3, linewidth = 2, color = self.myColorsDict['color_gray_dashedline'],zorder =0)      \n",
    "        # plt.hlines(upper[ar],ar-0.3,ar+0.3, linewidth = 2, color = self.myColorsDict['color_gray_dashedline'],zorder =0) \n",
    "        # t,p_wilcox = stats.wilcoxon(prop_double_byArea[ar] -double_sh)\n",
    "        \n",
    "        # if p_wilcox*len(areas) < 0.05:\n",
    "        #     print(str(p_wilcox))\n",
    "        #     plt.text(ar, 0.45, '*', fontsize=10)\n",
    "            \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Percentage of complex-tuned boutons (%)', '', 'p: ' + str(np.round(p_LMM,5)), mySize=15)  \n",
    "    plt.xticks(np.arange(0,len(ops['areas'])), ops['areas'],  rotation = 90)\n",
    "    plt.ylim([0, 0.5])\n",
    "    plt.yticks([0,0.25, 0.5], ['0', '25', '50'])\n",
    "    if p_LMM< 0.05:\n",
    "        cnt = 0\n",
    "        for j in range(len(pVals_adj_mannU)):\n",
    "            if pVals_adj_mannU[j] < 0.05:\n",
    "                plt.hlines(0.9, int(compIdx[j][0]), int(compIdx[j][2]), color = 'k')\n",
    "                cnt += 0.05\n",
    "                \n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "\n",
    "    #fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\complexTuning_byArea.svg'))\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70fc3dee-c99f-4865-a0d5-ddb0f4558121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSparsityIdx_byArea(df, data, ops, eng):\n",
    "    #%%\n",
    "    sessionRef = makeSessionReference(df)\n",
    "   \n",
    "    sessionIdx_unique = np.array(sessionRef['seshIdx'])\n",
    "    meanFreqs = []\n",
    "    for j in range(len(sessionIdx_unique)):\n",
    "        idx_thisSession = np.nonzero(np.array(df['sessionIdx']) == sessionIdx_unique[j])[0]\n",
    "        if len(idx_thisSession) > 10:\n",
    "            meanFreqs.append(np.nanmedian(data[idx_thisSession]))\n",
    "        else:\n",
    "            meanFreqs.append(np.nan)\n",
    "\n",
    "    notOut = np.nonzero(np.array(sessionRef['seshAreas']) != 'OUT')[0]\n",
    "    notNan = np.nonzero(np.isnan(np.array(meanFreqs)) <0.5)[0]\n",
    "    these = np.intersect1d(notOut,notNan)\n",
    "    df_freqs_forTest = pd.DataFrame({'freqMedian': np.array(meanFreqs)[these],\n",
    "                                    'area': np.array(sessionRef['seshAreas'])[these], \n",
    "                                    'animal':  np.array(sessionRef['seshAreas'])[these],\n",
    "                                    'Inj_DV': np.array(sessionRef['pos_DV'])[these],\n",
    "                                    'Inj_AP': np.array(sessionRef['pos_AP'])[these],\n",
    "                                    'prop_ventral': np.array(sessionRef['prop_ventral'])[these]})\n",
    "    \n",
    "    df_path = os.path.join(ops['outputPath'], 'freq_forLMM.csv')\n",
    "    df_freqs_forTest.to_csv(df_path)\n",
    "    \n",
    "    formula = 'freqMedian ~ area + Inj_DV + Inj_AP + (1|animal)'                 \n",
    "    p_LMM, all_pVals = eng.linearMixedModel_fromPython_anova_multiVar(df_path, formula, nargout=2)\n",
    "\n",
    "    \n",
    "    #New shuffles\n",
    "    # nShuffles = 1000\n",
    "    # N = 200\n",
    "    # freq_sh = []\n",
    "    # for n in range(nShuffles):\n",
    "    #     rand = np.random.choice(np.arange(0,len(df)), N, replace =True)\n",
    "        \n",
    "    #     freq_sh.append(np.nanmedian(data[rand]))\n",
    "        \n",
    "    # freq_sh = np.mean(freq_sh)\n",
    "        \n",
    "    \n",
    "    meanFreqs = np.array(meanFreqs) \n",
    "    areaIdx = np.array(sessionRef['seshAreas'])\n",
    "    meanFreqs_byArea = []\n",
    "    for ar in range(len(ops['areas'])):\n",
    "        these = np.nonzero(areaIdx == ops['areas'][ar])\n",
    "        vals_bySession_this = meanFreqs[these]\n",
    "        vals_bySession_this_clean = vals_bySession_this[np.nonzero(np.isnan(vals_bySession_this) < 0.5)[0]]\n",
    "\n",
    "        meanFreqs_byArea.append(vals_bySession_this_clean)\n",
    "  \n",
    "    data0 = meanFreqs_byArea\n",
    "    data_means_byArea = np.array([np.nanmedian(data0[j]) for j in range(len(data0))])       \n",
    "    # pVals = doWilcoxon_againstRef(data, ref, multiComp = 'hs')\n",
    "   \n",
    "    # upper = [np.percentile(vals_areaShuffle[j,:], 97.5) for j in range(len(ops['areas']))]\n",
    "    # lower = [np.percentile(vals_areaShuffle[j,:], 2.5) for j in range(len(ops['areas']))]\n",
    "    \n",
    "    #%%\n",
    "    fig = plt.figure(figsize=(100*ops['mm'], 100*ops['mm']), constrained_layout=True)\n",
    "    # gs = gridspec.GridSpec(1, 1, figure=fig, hspace=0.7, wspace=0.2,left=0.1, right=0.9, bottom=0.1, top=0.95)\n",
    "    # ax = fig.add_subplot(gs[0, 0])\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    # plt.hlines(freq_sh, -0.5,9.5,linewidth=1, color='k', linestyle ='dashed')\n",
    "    p_wilcox_byArea =[]\n",
    "    for i in range(len(ops['areas'])):\n",
    "       \n",
    "        plt.plot([i-0.25,i+0.25], [data_means_byArea[i],data_means_byArea[i]] , linewidth = 2, c =ops['myColorsDict']['HVA_colors'][ops['areas'][i]],zorder = 2)\n",
    "        xVals_scatter = np.random.normal(loc =i,scale =0.05,size = len(data0[i])) \n",
    "        plt.scatter(xVals_scatter, data0[i], s = 7, facecolors = 'white' , edgecolors = ops['myColorsDict']['HVA_colors'][ops['areas'][i]], linewidths =0.5,zorder = 1, alpha=0.3) \n",
    "        \n",
    "    plt.ylim([0.5,0.9])\n",
    "    plt.yticks([0.5, 0.7, 0.9], ['0.5', '0.7', '0.9'])\n",
    "    # plt.xlim(-1, 5.5)               \n",
    "    myPlotSettings_splitAxis(fig,ax,'Sparsity Index','','p: ' + str(np.round(p_LMM,2)), mySize=15) \n",
    "    \n",
    "    if p_LMM < 0.05:\n",
    "        pVals_adj_mannU, compIdx = doMannWhitneyU_forBoxplots(meanFreqs_byArea, multiComp = 'fdr')\n",
    "        cnt=0     \n",
    "        for j in range(len(pVals_adj_mannU)):\n",
    "            if pVals_adj_mannU[j] < 0.05:\n",
    "                plt.hlines(6-cnt, int(compIdx[j][0]), int(compIdx[j][2]), color = 'k')\n",
    "                cnt = cnt + 0.2\n",
    "                \n",
    "    plt.xticks(np.arange(0,len(ops['areas'])), ops['areas'], rotation=90)\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75348eeb-d04d-4c0a-87ca-1ce064e48ed3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSignalCorrelation_byArea_FV(df, ops, computeMatrix =1):               \n",
    "\n",
    "    # maps = maps_green_aud_sig\n",
    "    #areas = ops['areas']\n",
    "    areas = ['P', 'POR', 'LI', 'LM', 'AL', 'RL', 'A', 'AM', 'PM','V1'] \n",
    "\n",
    "    name = 'signal_corr_frequencies_resp_motorSub'\n",
    "    #pairwise signal correlations are a very large NxN matrix. to avoid loading the whole matrix at once, it is loaded in by area, in chuncks\n",
    "    if computeMatrix: #takes a while\n",
    "        nBatch =40\n",
    "        corrMatrix_byArea0 = np.zeros((len(areas), len(areas)))\n",
    "        for ar0 in range(len(areas)):\n",
    "            idx_thisArea = np.nonzero(np.array(df['area']) == areas[ar0])[0]\n",
    "\n",
    "\n",
    "            corr_byArea = [[] for _ in range(len(areas))]\n",
    "            sumPrev = 0\n",
    "            for i in tqdm(range(nBatch+1)):\n",
    "                # corrs = np.load(os.path.join(outputPath, 'signal_corr_coliseum_2dim' + str(i) + '.npy'))\n",
    "                corrs = np.load(os.path.join(ops['dataPath'],'frequencies_dataset', 'signal_correlations', name, name + '_' + str(i) + '.npy'))\n",
    "\n",
    "                nRois = corrs.shape[0]\n",
    "                idx_batch = np.arange(0,nRois) + sumPrev\n",
    "\n",
    "                idx_thisArea_batch = np.intersect1d(idx_thisArea, idx_batch)\n",
    "                corrs_thisArea = corrs[idx_thisArea_batch-sumPrev,:]\n",
    "\n",
    "                for ar1 in range(len(areas)):\n",
    "                    idx_area1 = np.nonzero(np.array(df['area']) == areas[ar1])[0]\n",
    "\n",
    "                    these_corr = corrs_thisArea[:,idx_area1].reshape(-1,1)\n",
    "                    notNanIdx = np.nonzero(~np.isnan(these_corr)==1)[0]\n",
    "                    these_corr = these_corr[notNanIdx]\n",
    "\n",
    "                    corr_byArea[ar1].append(these_corr)\n",
    "\n",
    "                sumPrev = nRois + sumPrev\n",
    "            for j in range(len(areas)):\n",
    "                for k in range(len(corr_byArea[j])-1):\n",
    "                    if k ==0:\n",
    "                        this = corr_byArea[j][k]\n",
    "                    else:\n",
    "                        this = np.concatenate((this,corr_byArea[j][k]),0)\n",
    "                corrMatrix_byArea0[ar0, j] = np.nanmean(this)\n",
    "    else:\n",
    "        corrMatrix_byArea0 = np.load(os.path.join(ops['dataPath'], 'frequencies_dataset','signal_correlations', 'signalCorr_matrix_freqs_resp_motorSub.npy'))\n",
    "\n",
    "        \n",
    "    fig = plt.figure(figsize= (ops['mm']*100,ops['mm']*100), constrained_layout =True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "   \n",
    "    plt.imshow(corrMatrix_byArea0, cmap = 'Reds', vmin=0, vmax =0.04)\n",
    "   \n",
    "    plt.xticks(np.arange(0,len(areas)), areas, rotation = 90, fontsize=15)\n",
    "    plt.yticks(np.arange(0,len(areas)), areas,fontsize=15)\n",
    "    cbar = plt.colorbar(fraction = 0.05,ticks=[0, 0.02,0.04])\n",
    "    cbar.ax.set_yticklabels([0, 0.02,0.04],fontsize=10)\n",
    "    \n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(0.75)   \n",
    "        \n",
    "    plt.title('Signal correlation')\n",
    "    \n",
    "    #%% ###########################################################################################################\n",
    "    boot_df = np.load(os.path.join(ops['dataPath'], 'frequencies_dataset','signal_correlations','signal_corr_frequencies_resp_motorSub', \n",
    "                                   'corrs_frequencies_resp_byStream_allData.npy'), allow_pickle=True).item()\n",
    "\n",
    "    diff_dd_dv = boot_df['mean_dd'] - boot_df['mean_dv']\n",
    "    diff_vv_dv = boot_df['mean_vv'] - boot_df['mean_dv']\n",
    "\n",
    "    p_dd_dv = np.float64(getBootstrapDiffP(diff_dd_dv))*2    \n",
    "    p_vv_dv = np.float64(getBootstrapDiffP(diff_vv_dv))*2      \n",
    "    \n",
    "    color_dorsal = ops['myColorsDict']['HVA_colors']['AM']\n",
    "    color_ventral = ops['myColorsDict']['HVA_colors']['POR']\n",
    "    color_mixed = '#A160A4'\n",
    "    \n",
    "    fig = plt.figure(figsize=(ops['mm']*26, ops['mm']*39), constrained_layout=True)\n",
    "    ax= fig.add_subplot(1,1,1)\n",
    "    plt.bar(0,np.median(boot_df['mean_vv']), color= color_ventral, alpha = 0.7, edgecolor=color_ventral)\n",
    "    plt.vlines(0, np.percentile(boot_df['mean_vv'],2.5), np.percentile(boot_df['mean_vv'],97.5), color='k', linewidth=0.5)\n",
    "    plt.bar(1,np.median(boot_df['mean_dd']), color= color_dorsal, alpha = 0.7, edgecolor=color_dorsal)\n",
    "    plt.vlines(1, np.percentile(boot_df['mean_dd'],2.5), np.percentile(boot_df['mean_dd'],97.5), color='k', linewidth=0.5)\n",
    "    plt.bar(2,np.median(boot_df['mean_dv']), color= color_mixed, alpha = 0.7, edgecolor=color_mixed)\n",
    "    plt.vlines(2, np.percentile(boot_df['mean_dv'],2.5), np.percentile(boot_df['mean_dv'],97.5), color='k', linewidth=0.5)\n",
    "\n",
    "\n",
    "    plt.hlines(0,-0.5,2.5,color = 'dimgray', linewidth=0.5, linestyle='dashed')\n",
    "    myPlotSettings_splitAxis(fig, ax, 'Signal correlation', '', 'p_ven-ven_vs_ven-dor: ' + str(p_vv_dv) + '\\np_dor-dor_vs_ven-dor: ' + str(p_dd_dv), mySize=6)\n",
    "    plt.xticks([0,1,2], ['Ventral-Ventral','Dorsal-Dorsal', 'Ventral-Dorsal'], rotation = 45, horizontalalignment='right')\n",
    "    plt.ylim([-0.0005, 0.02])\n",
    "    plt.yticks([ 0, 0.01, 0.02],['0', '0.01', '0.02'])\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "    # plt.text(0,np.percentile(boot_df['mean_vv'],97.5), p_vv_dv, color = 'k')\n",
    "    # plt.text(0.5,np.percentile(boot_df['mean_dd'],97.5), p_dd_dv, color = 'k')\n",
    "\n",
    "    #fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\signalCorr_byStream_frequencies_resp_barplots_hierarchical_allData.svg'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a03a290d-aeec-44ff-82b3-f94ded1edb97",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotFrequency_againstSource(df, data, ops, eng):\n",
    " \n",
    "    sessionRef = makeSessionReference(df)\n",
    "   \n",
    "    sessionIdx_unique = np.array(sessionRef['seshIdx'])\n",
    "    meanFreqs = []\n",
    "    for j in range(len(sessionIdx_unique)):\n",
    "        idx_thisSession = np.nonzero(np.array(df['sessionIdx']) == sessionIdx_unique[j])[0]\n",
    "        if len(idx_thisSession) > 10:\n",
    "            meanFreqs.append(np.nanmedian(data[idx_thisSession]))\n",
    "        else:\n",
    "            meanFreqs.append(np.nan)\n",
    "            \n",
    "    notOut = np.nonzero(np.array(sessionRef['seshAreas']) != 'OUT')[0]\n",
    "    notNan = np.nonzero(np.isnan(np.array(meanFreqs)) <0.5)[0]\n",
    "    these = np.intersect1d(notOut,notNan)\n",
    "    df_freqs_forTest = pd.DataFrame({'freqMedian': np.array(meanFreqs)[these],\n",
    "                                    'area': np.array(sessionRef['seshAreas'])[these], \n",
    "                                    'animal':  np.array(sessionRef['seshAnimal'])[these], \n",
    "                                    'Inj_DV': np.array(sessionRef['pos_DV'])[these],\n",
    "                                    'Inj_AP': np.array(sessionRef['pos_AP'])[these],\n",
    "                                    'prop_ventral': np.array(sessionRef['prop_ventral'])[these]})\n",
    "            \n",
    "    df_freqs_forTest['Inj_DV'] = df_freqs_forTest['Inj_DV'] - min(df_freqs_forTest['Inj_DV'])  \n",
    "    df_freqs_forTest['Inj_AP'] = abs(df_freqs_forTest['Inj_AP'] - max(df_freqs_forTest['Inj_AP']))  \n",
    "\n",
    " #%%\n",
    "    df_path= os.path.join(ops['outputPath'],'df_freqs_forLMM.csv')\n",
    "    df_freqs_forTest.to_csv(df_path)\n",
    "    formula = 'freqMedian ~ 1 + Inj_DV + (1|animal)'\n",
    "    # formula = 'meanElevs_green ~ 1 + fitElevs_red + (1|animal)'\n",
    "\n",
    "    savePath = os.path.join(ops['outputPath'], 'LMM_green.mat')\n",
    "    \n",
    "    #run LMM and load results\n",
    "    res, fitLines, fitCI = eng.linearMixedModel_fromPython(df_path, formula,savePath, nargout=3) \n",
    "\n",
    "    mat_file = scipy.io.loadmat(savePath)   \n",
    "    res = getDict_fromMatlabStruct(mat_file, 'res')\n",
    "    \n",
    "    intercept = res['Intercept'][0][0] # from matlab LMM \n",
    "    slope = res['Inj_DV'][0][0]\n",
    "    slope_p = res['Inj_DV'][0][1]\n",
    "    xVals = np.arange(0,max(df_freqs_forTest['Inj_DV']),1)\n",
    "    yVals = intercept + slope*xVals\n",
    "     \n",
    "    #\n",
    "    #this is the nice one\n",
    "    fig = plt.figure(figsize =(ops['mm']*43,ops['mm']*40), constrained_layout = True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.scatter(np.array(df_freqs_forTest['Inj_DV']), np.array(df_freqs_forTest['freqMedian']), c= 'k', s =1)\n",
    "    x_axis = 'Inj_DV'\n",
    "    fitLine = np.array(fitLines[x_axis])\n",
    "    fitLine_down = np.array(fitCI[x_axis])[:,0]\n",
    "    fitLine_up = np.array(fitCI[x_axis])[:,1]\n",
    "    xVals = np.linspace(min(df_freqs_forTest[x_axis]), max(df_freqs_forTest[x_axis]), len(fitLine))\n",
    "    plt.fill_between(xVals, fitLine_up, fitLine_down, facecolor = 'gray',alpha = 0.3)\n",
    "    plt.plot(xVals, fitLine, c = 'k', linewidth = 1, linestyle ='dashed') \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best frequency (kHz)', 'Injection centre position (\\u03BCm)','', mySize=6)\n",
    "    plt.text(3,8,'p: ' + str(np.round(slope_p,4)))\n",
    "    plt.xticks([0,50,100,150], ['0', '500', '1000', '1500'])\n",
    "    plt.yticks([2,4,6,8],[4,8,16,32])\n",
    "    ax.tick_params(axis='y', pad=1)  \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "        \n",
    "    fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\bestFreq_bySession_againstDV_pos.svg'))\n",
    "\n",
    "    \n",
    "    df_path= os.path.join(ops['outputPath'],'df_freqs_forLMM.csv')\n",
    "    df_freqs_forTest.to_csv(df_path)\n",
    "    formula = 'freqMedian ~ 1 + Inj_AP + (1|animal)'\n",
    "    # formula = 'meanElevs_green ~ 1 + fitElevs_red + (1|animal)'\n",
    "\n",
    "    savePath = os.path.join(ops['outputPath'], 'LMM_green.mat')\n",
    "    \n",
    "    #run LMM and load results\n",
    "    res, fitLines, fitCI = eng.linearMixedModel_fromPython(df_path, formula,savePath, nargout=3) \n",
    "\n",
    "    mat_file = scipy.io.loadmat(savePath)   \n",
    "    res = getDict_fromMatlabStruct(mat_file, 'res')\n",
    "    \n",
    "    intercept = res['Intercept'][0][0] # from matlab LMM \n",
    "    slope = res['Inj_AP'][0][0]\n",
    "    slope_p = res['Inj_AP'][0][1]\n",
    "    xVals = np.arange(0,max(df_freqs_forTest['Inj_AP']),1)\n",
    "    yVals = intercept + slope*xVals\n",
    "     \n",
    "    #\n",
    "    #this is the nice one\n",
    "    fig = plt.figure(figsize =(ops['mm']*43,ops['mm']*40), constrained_layout = True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "    plt.scatter(np.array(df_freqs_forTest['Inj_AP']), np.array(df_freqs_forTest['freqMedian']), c= 'k', s =1)\n",
    "    x_axis = 'Inj_AP'\n",
    "    fitLine = np.array(fitLines[x_axis])\n",
    "    fitLine_down = np.array(fitCI[x_axis])[:,0]\n",
    "    fitLine_up = np.array(fitCI[x_axis])[:,1]\n",
    "    xVals = np.linspace(min(df_freqs_forTest[x_axis]), max(df_freqs_forTest[x_axis]), len(fitLine))\n",
    "    plt.fill_between(xVals, fitLine_up, fitLine_down, facecolor = 'gray',alpha = 0.3)\n",
    "    plt.plot(xVals, fitLine, c = 'k', linewidth = 1, linestyle ='dashed') \n",
    "    myPlotSettings_splitAxis(fig, ax, 'Best frequency (kHz)', 'Injection centre position (\\u03BCm)','', mySize=6)\n",
    "    plt.text(3,8,'p: ' + str(np.round(slope_p,4)))\n",
    "    plt.xticks([0,50,100], ['0', '500', '1000'])\n",
    "    plt.yticks([2,4,6,8],[4,8,16,32])\n",
    "    ax.tick_params(axis='y', pad=1)  \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "    \n",
    "    fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\bestFreq_bySession_againstAP_pos.svg'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f87e032-c6c9-44e2-af4e-a110868effc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def quantifySignificance_coliseum_v2(df,ops):\n",
    "    \n",
    "    areas = ops['areas']\n",
    "    #####################################################\n",
    "    #get responsive ones \n",
    "    # green_aud_resp_idx, _ = self.applySignificanceTests(df, modality = modality,extra = extra, \n",
    "    #                                                       sig_policy = 'responsive_maxWilcoxon', nSDs = 1, alpha = 0.05, capped = 0, GLM=1)\n",
    "    green_aud_resp_idx= np.load(os.path.join(ops['dataPath'], 'locations_dataset','responsive_idx_coliseum_boutons.npy'))\n",
    "\n",
    "    df_green_aud_resp = df.iloc[green_aud_resp_idx]\n",
    "\n",
    "    green_aud_prop_resp = makeProportions_bySession_v2(df_green_aud_resp, df) #includes responsive to both\n",
    "    green_aud_prop_resp_median = np.nanmedian(green_aud_prop_resp)\n",
    "\n",
    "    #####################################################\n",
    "    #divide responsive sessions by area\n",
    "    areas_green_aud = asignAreaToSession(df, policy='mostRois')\n",
    "    green_aud_resp_byArea = divideSessionsByArea(green_aud_prop_resp, areas, areas_green_aud)\n",
    "    #############################################\n",
    "    #get selective\n",
    "    # green_aud_selective_azi, _ = self.applySignificanceTests(df_green_aud, modality = modality,extra = extra, dimension = 'long', sig_policy = 'selective_maxWilcoxon', nSDs = 1, alpha = 0.05, capped = 0, GLM=1)\n",
    "    # green_aud_selective_elev, _ = self.applySignificanceTests(df_green_aud, modality = modality,extra = extra, dimension = 'short',sig_policy = 'selective_maxWilcoxon', nSDs = 1, alpha = 0.05, capped = 0, GLM=1)\n",
    "    # green_aud_selective_int, _= self.applySignificanceTests(df_green_aud, modality = modality,extra = extra, dimension = 'int', sig_policy = 'selective_maxWilcoxon', nSDs = 1, alpha = 0.05, capped = 0, GLM=1)\n",
    "\n",
    "    # green_aud_selective_all = np.unique(np.concatenate((green_aud_selective_azi, green_aud_selective_elev, green_aud_selective_int),0))\n",
    "    #load index of selective boutons\n",
    "    green_aud_selective_azi= np.load(os.path.join(ops['dataPath'],'locations_dataset', 'selective_green_aud_azimuth_maxWilcoxon_a1.npy'))\n",
    "    green_aud_selective_elev =np.load(os.path.join(ops['dataPath'], 'locations_dataset','selective_green_aud_elevation_maxWilcoxon_a1.npy'))\n",
    "    \n",
    "    df_sel_azi = df.iloc[green_aud_selective_azi]\n",
    "    df_sel_elev = df.iloc[green_aud_selective_elev]\n",
    "    # df_sel_int = df_green_aud.iloc[green_aud_selective_int]\n",
    "    # df_sel_all = df_green_aud.iloc[green_aud_selective_all]\n",
    "\n",
    "    #####################################\n",
    "    #make the proportions selective\n",
    "    green_aud_prop_sel_azi = makeProportions_bySession_v2(df_sel_azi, df_green_aud_resp,thresh=10)\n",
    "    green_aud_prop_sel_median_azi = np.nanmedian(green_aud_prop_sel_azi)\n",
    "\n",
    "    green_aud_prop_sel_elev = makeProportions_bySession_v2(df_sel_elev, df_green_aud_resp)\n",
    "    green_aud_prop_sel_median_elev = np.nanmedian(green_aud_prop_sel_elev)\n",
    "\n",
    "#     green_aud_prop_sel_int = makeProportions_bySession_v2(df_sel_int, df_green_aud_resp)\n",
    "#     green_aud_prop_sel_median_int = np.nanmedian(green_aud_prop_sel_int)\n",
    "\n",
    "#     green_aud_prop_sel_all = makeProportions_bySession_v2(df_sel_all, df_green_aud_resp)\n",
    "#     green_aud_prop_sel_median_all = np.nanmedian(green_aud_prop_sel_all)\n",
    "\n",
    "    #########################################\n",
    "    #assign area to session\n",
    "    areas_green_aud = asignAreaToSession(df_green_aud_resp, policy='mostRois')\n",
    "    # noneResp = np.nonzero(np.array(green_aud_prop_resp) == 0)[0]\n",
    "    # areas_green_aud['areas'] = np.delete(areas_green_aud['areas'],noneResp)\n",
    "    # areas_green_aud['sessionIdx'] = np.delete(areas_green_aud['sessionIdx'],noneResp)\n",
    "\n",
    "    green_aud_sel_byArea_azi = divideSessionsByArea(green_aud_prop_sel_azi, areas, areas_green_aud)\n",
    "    green_aud_sel_byArea_elev = divideSessionsByArea(green_aud_prop_sel_elev, areas, areas_green_aud)\n",
    "    # green_aud_sel_byArea_int = divideSessionsByArea(green_aud_prop_sel_int, areas, areas_green_aud)\n",
    "    # green_aud_sel_byArea_all = divideSessionsByArea(green_aud_prop_sel_all, areas, areas_green_aud)\n",
    "\n",
    "    #################################################\n",
    "    #do shuffles\n",
    "   \n",
    "    # Save for LMM\n",
    "    sessionRef = makeSessionReference(df)\n",
    "    notOut = np.nonzero(np.array(areas_green_aud['areas']) != 'OUT')[0]\n",
    "    df_props_forTest = pd.DataFrame({'proportion_resp': np.array(green_aud_prop_resp)[notOut],\n",
    "                                     'proportion_sel_azi': np.array(green_aud_prop_sel_azi)[notOut],\n",
    "                                     'proportion_sel_elev': np.array(green_aud_prop_sel_elev)[notOut],\n",
    "                                    # 'proportion_sel_int': np.array(green_aud_prop_sel_int)[notOut],\n",
    "                                    'area': np.array(areas_green_aud['areas'])[notOut], \n",
    "                                    'animal':  np.array(areas_green_aud['animals'])[notOut],\n",
    "                                    'Inj_DV': np.array(sessionRef['pos_DV'])[notOut],\n",
    "                                    'Inj_AP': np.array(sessionRef['pos_AP'])[notOut],\n",
    "                                    'prop_ventral': np.array(sessionRef['prop_ventral'])[notOut]})#\n",
    "\n",
    "    df_path = os.path.join(ops['outputPath'], 'prop_freq_forLMM.csv')\n",
    "    df_props_forTest.to_csv(df_path)\n",
    "\n",
    "    meanLineWidth = 0.5\n",
    "    meanLineWidth_small = 0.3\n",
    "\n",
    "\n",
    "    #%%\n",
    "    ylim_sel = [-0.05, 1.05]\n",
    "    #Plot azi and elev\n",
    "    fig = plt.figure(figsize=(ops['mm']*40, ops['mm']*52), constrained_layout=True)\n",
    "    ax = fig.add_subplot(2,1,1)\n",
    "    plt.plot([- meanLineWidth, meanLineWidth], [green_aud_prop_sel_median_azi,green_aud_prop_sel_median_azi],linewidth = 2,c = 'k',zorder =2)     \n",
    "    xVals_scatter = np.random.normal(loc =0,scale =0.05,size = len(green_aud_prop_sel_azi)) \n",
    "    plt.scatter(xVals_scatter, np.array(green_aud_prop_sel_azi), s = 10, facecolors = 'white' , edgecolors ='k', linewidths =0.5,zorder = 1, alpha=0.3)\n",
    "\n",
    "    data = green_aud_sel_byArea_azi\n",
    "    data0 = []\n",
    "    for i in range(len(data)):\n",
    "        this = np.nonzero(np.isnan(data[i]) < 0.5)[0]\n",
    "        data0.append(data[i][this])\n",
    "    data = data0   \n",
    "    # ref =  green_aud_prop_sel_median_azi\n",
    "    data_medians_byArea = np.array([np.nanmedian(data[j]) for j in range(len(data))])       \n",
    "    # pVals = doWilcoxon_againstRef(data, ref, multiComp = 'hs')\n",
    "\n",
    "    formula = 'proportion_sel_azi ~ area +  Inj_DV + Inj_AP + (1|animal)'                 \n",
    "    p_LMM, all_pVals = eng.linearMixedModel_fromPython_anova_multiVar(df_path, formula, nargout=2)\n",
    "    print(p_LMM)\n",
    "    # upper = [np.percentile(shuffled_prop_sel_azi[j,:], 97.5) for j in range(len(areas))]\n",
    "    # lower = [np.percentile(shuffled_prop_sel_azi[j,:], 2.5) for j in range(len(areas))]\n",
    "    # t,p_kruskal = stats.kruskal(data[0],data[1],data[2],data[3],data[4],data[5],data[6],data[7],data[8],data[9])\n",
    "    # plt.hlines(prop_sel_azi_sh, 1,len(areas) +2, linestyle = 'dashed', linewidth =1, color ='k')\n",
    "    #p_mannWhitney0, compIdx = doMannWhitneyU_forBoxplots(data, multiComp = 'fdr')\n",
    "\n",
    "    plt.vlines(1,0, 1, linewidth = 0.5, color = 'gray',zorder =0)\n",
    "    for i in range(len(areas)):\n",
    "        plt.plot([i-meanLineWidth_small+2,i+meanLineWidth_small+2], [data_medians_byArea[i],data_medians_byArea[i]] , linewidth = 2, c = ops['myColorsDict']['HVA_colors'][areas[i]],zorder = 2)\n",
    "        xVals_scatter = np.random.normal(loc =i+2,scale =0.05,size = len(data[i])) \n",
    "        plt.scatter(xVals_scatter, data[i], s = 10, facecolors = 'white' , edgecolors = ops['myColorsDict']['HVA_colors'][areas[i]], linewidths =0.5,zorder = 1, alpha=0.3) \n",
    "\n",
    "        # p_mannWhitney, compIdx = doMannWhitneyU_forBoxplots(data, multiComp = 'hs')\n",
    "    if p_LMM < 0.05:\n",
    "        cnt = 0\n",
    "        p_mannWhitney, compIdx = doMannWhitneyU_forBoxplots(data, multiComp = 'fdr')\n",
    "\n",
    "        for c in range(len(compIdx)):\n",
    "            if p_mannWhitney[c] < 0.05:\n",
    "                pos = compIdx[c].split('_')\n",
    "                plt.hlines(ylim_sel[-1] - cnt, int(pos[0])+2, int(pos[1])+2, colors = 'k', linewidth=0.5)                    \n",
    "                cnt +=0.01\n",
    "       # t, p_signRank = stats.wilcoxon(data[i]-prop_sel_azi_sh)\n",
    "       # print(str(p_signRank))\n",
    "\n",
    "        # if p_signRank < 0.00511:\n",
    "        #     plt.text(i+2,ylim_sel[-1] -0.1, '*', fontsize=10)\n",
    "\n",
    "    plt.ylim(ylim_sel)\n",
    "    plt.xlim([-1,12])\n",
    "    # plt.yticks(yTickValues_resp)\n",
    "    # ax0.xaxis.set_ticklabels([])\n",
    "    # ax0.xaxis.set_ticks([])\n",
    "    plt.yticks([0,0.5, 1], ['0','50', '100'])\n",
    "    myPlotSettings_splitAxis(fig,ax,'Percentage of azimuth- \\n selective boutons (%)','','', mySize=6)  \n",
    "    # myPlotSettings_splitAxis(fig,ax,'Percentage of azimuth- \\n selective boutons (%)','','p= ' + str(p_LMM), mySize=6)  \n",
    "    \n",
    "    plt.xticks([0,2,3,4,5,6,7,8,9,10,11], np.append('All',areas), rotation =90)\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "\n",
    "    # green aud, selective, ELEVATION ONLY\n",
    "    ax = fig.add_subplot(2,1,2)\n",
    "    # plt.hlines(0,-1, 1+len(areas)+1, linewidth = 1, color = self.myColorsDict['color_gray_zeroline'],zorder =0)\n",
    "    plt.plot([- meanLineWidth, meanLineWidth], [green_aud_prop_sel_median_elev,green_aud_prop_sel_median_elev],linewidth = 2,c = 'k',zorder =2)     \n",
    "    xVals_scatter = np.random.normal(loc =0,scale =0.05,size = len(green_aud_prop_sel_elev)) \n",
    "    plt.scatter(xVals_scatter, np.array(green_aud_prop_sel_elev), s = 10, facecolors = 'white' , edgecolors ='k', linewidths =0.5,zorder = 1, alpha =0.3)\n",
    "\n",
    "    data = green_aud_sel_byArea_elev\n",
    "    data0 = []\n",
    "    for i in range(len(data)):\n",
    "        this = np.nonzero(np.isnan(data[i]) < 0.5)[0]\n",
    "        data0.append(data[i][this])\n",
    "    data = data0   \n",
    "\n",
    "    # ref =  green_aud_prop_sel_median_elev\n",
    "    data_medians_byArea = np.array([np.nanmedian(data[j]) for j in range(len(data))])       \n",
    "    # pVals = doWilcoxon_againstRef(data, ref, multiComp = 'hs')\n",
    "    formula = 'proportion_sel_elev ~ area + Inj_DV + Inj_AP + (1|animal)'                 \n",
    "    p_LMM, all_pVals = eng.linearMixedModel_fromPython_anova_multiVar(df_path, formula, nargout=2)\n",
    "    print(p_LMM)\n",
    "\n",
    "    # plt.hlines(prop_sel_elev_sh, 1,len(areas) +2, linestyle = 'dashed', linewidth =1, color ='k')  \n",
    "\n",
    "    # upper = [np.percentile(shuffled_prop_sel_elev[j,:], 97.5) for j in range(len(areas))]\n",
    "    # lower = [np.percentile(shuffled_prop_sel_elev[j,:], 2.5) for j in range(len(areas))]\n",
    "    # t,p_kruskal = stats.kruskal(data[0],data[1],data[2],data[3],data[4],data[5],data[6],data[7],data[8],data[9])\n",
    "\n",
    "    plt.vlines(1,0, 1, linewidth = 0.5, color = 'gray',zorder =0)\n",
    "    for i in range(len(areas)):\n",
    "        plt.plot([i-meanLineWidth_small+2,i+meanLineWidth_small+2], [data_medians_byArea[i],data_medians_byArea[i]] , linewidth = 2, c = ops['myColorsDict']['HVA_colors'][areas[i]],zorder = 2)\n",
    "        xVals_scatter = np.random.normal(loc =i+2,scale =0.05,size = len(data[i])) \n",
    "        plt.scatter(xVals_scatter, data[i], s = 10, facecolors = 'white' , edgecolors = ops['myColorsDict']['HVA_colors'][areas[i]], linewidths =0.5,zorder = 1, alpha=0.3) \n",
    "\n",
    "        # plt.fill_between([i-meanLineWidth_small+2,i+meanLineWidth_small+2],[lower[i], lower[i]], [upper[i],upper[i]], color= 'gray', alpha = 0.2)\n",
    "        # # plt.hlines(pVals_ks[ar], ar - 0.3,ar + 0.3, color = 'r', label='real')            \n",
    "        # plt.hlines(lower[i],i-meanLineWidth_small+2,i+meanLineWidth_small+2, linewidth = 0.5, color = self.myColorsDict['color_gray_dashedline'],zorder =0)      \n",
    "        # plt.hlines(upper[i],i-meanLineWidth_small+2,i+meanLineWidth_small+2, linewidth = 0.5, color = self.myColorsDict['color_gray_dashedline'],zorder =0) \n",
    "\n",
    "    if p_LMM < 0.05:\n",
    "        p_mannWhitney, compIdx = doMannWhitneyU_forBoxplots(data, multiComp = 'fdr')\n",
    "        cnt = 0\n",
    "        for c in range(len(compIdx)):\n",
    "            if p_mannWhitney[c] < 0.05:\n",
    "                pos = compIdx[c].split('_')\n",
    "                plt.hlines(ylim_sel[-1] - cnt, int(pos[0])+2, int(pos[1])+2, colors = 'k', linewidth=0.5)                    \n",
    "                cnt +=0.01\n",
    "      #  t, p_signRank = stats.wilcoxon(data[i]-prop_sel_elev_sh)\n",
    "        # if p_signRank <  0.00511:\n",
    "        #     plt.text(i+2,ylim_resp[-1] -0.1, '*', fontsize=10)\n",
    "        #     print(str(p_signRank))\n",
    "\n",
    "    plt.ylim(ylim_sel)\n",
    "    # plt.yticks(yTickValues_resp)\n",
    "    # ax0.xaxis.set_ticklabels([])\n",
    "    # ax0.xaxis.set_ticks([])\n",
    "    plt.xlim([-1,12])\n",
    "    plt.yticks([0,0.5, 1], ['0','50', '100'])\n",
    "   # myPlotSettings_splitAxis(fig,ax,'Percentage of elevation- \\n selective boutons (%)','','p= ' + str(p_LMM), mySize=15)\n",
    "    myPlotSettings_splitAxis(fig,ax,'Percentage of elevation- \\n selective boutons (%)','','', mySize=6)  \n",
    "\n",
    "    plt.xticks([0,2,3,4,5,6,7,8,9,10,11], np.append('All',areas), rotation =90)\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "\n",
    "    fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\significance_withSessions_byArea_coliseum.svg'))\n",
    "\n",
    "    # fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\TuningProportions_coliseum_aziElev.svg'))\n",
    "\n",
    "\n",
    "#     ylim_resp = [-0.01,0.5]\n",
    "\n",
    "#     meanLineWidth = 0.5\n",
    "#     meanLineWidth_small = 0.3\n",
    "#     color_gray_dashedline = 'gray'\n",
    "\n",
    "    # fig = plt.figure(figsize=(60*self.mm, 60*self.mm), constrained_layout=True)\n",
    "#     fig = plt.figure(figsize=(80*ops['mm'], 80*ops['mm']), constrained_layout=True)\n",
    "\n",
    "#     # green aud, responsive\n",
    "#     ax0 = fig.add_subplot(1,1,1)\n",
    "#     # plt.hlines(0,-1, 1, linewidth = 1, color = self.myColorsDict['color_gray_zeroline'],zorder =0)\n",
    "#     # plt.plot([- meanLineWidth_small, meanLineWidth], [green_aud_prop_resp_median,green_aud_prop_resp_median],linewidth = 5,c = 'k',zorder =1)     \n",
    "#     xVals_scatter = np.random.normal(loc =0,scale =0.08,size = len(green_aud_prop_resp)) \n",
    "#     plt.scatter(xVals_scatter, np.array(green_aud_prop_resp), s = 8, facecolors = 'white' , edgecolors = 'k', linewidths =0.5,zorder = 1)\n",
    "#     plt.plot([- 0.4, 0.4], [green_aud_prop_resp_median,green_aud_prop_resp_median],linewidth = 3,c = 'k',zorder =2)     \n",
    "\n",
    "\n",
    "#     plt.ylim(ylim_resp)\n",
    "#     # plt.yticks(yTickValues_resp)\n",
    "#     # ax0.xaxis.set_ticklabels([])\n",
    "#     # ax0.xaxis.set_ticks([])\n",
    "#     myPlotSettings_splitAxis(fig,ax0,'% of boutons/session','','')  \n",
    "#     # plt.gca().set_xticklabels([])\n",
    "#     # plt.gca().set_xticks([])\n",
    "#     plt.xticks([0], ['Responsive'], rotation = 45, horizontalalignment='right')\n",
    "\n",
    "#     plt.ylim([-0.02,1])\n",
    "#     plt.yticks([0,0.25, 0.5, 0.75,1],['0','25', '50', '75', '100'] )\n",
    "    # fig.savefig(os.path.join(pathStart, 'home', 'shared', 'Alex_analysis_camp', 'Thesis_figures','Locations','Prop_resp_locations_all.svg'))\n",
    "\n",
    "\n",
    "\n",
    "#     fig = plt.figure(figsize=(45*ops['mm'], 51*ops['mm']), constrained_layout=True)\n",
    "\n",
    "#     # green aud, responsive\n",
    "#     ax0 = fig.add_subplot(1,1,1)\n",
    "#     ylim_sel = [0,1]\n",
    "\n",
    "\n",
    "#     # green aud, selective\n",
    "#     # plt.hlines(0,-1, 3, linewidth = 1, color = self.myColorsDict['color_gray_zeroline'],zorder =0)\n",
    "#     xVals_scatter = np.random.normal(loc =0,scale =0.05,size = len(green_aud_prop_sel_azi)) \n",
    "#     plt.scatter(xVals_scatter, np.array(green_aud_prop_sel_azi), s = 8, facecolors = 'white' , edgecolors = 'k', linewidths =0.5)\n",
    "#     plt.plot([- meanLineWidth_small, meanLineWidth_small], [green_aud_prop_sel_median_azi,green_aud_prop_sel_median_azi],linewidth = 3,c = 'k')     \n",
    "\n",
    "#     xVals_scatter = np.random.normal(loc =1,scale =0.05,size = len(green_aud_prop_sel_elev)) \n",
    "#     plt.scatter(xVals_scatter, np.array(green_aud_prop_sel_elev), s = 8, facecolors = 'white' , edgecolors = 'k', linewidths =0.5)\n",
    "#     plt.plot([- meanLineWidth_small +1,meanLineWidth_small+1], [green_aud_prop_sel_median_elev,green_aud_prop_sel_median_elev],linewidth = 3,c = 'k')     \n",
    "\n",
    "#     xVals_scatter = np.random.normal(loc =2,scale =0.05,size = len(green_aud_prop_sel_int)) \n",
    "#     plt.scatter(xVals_scatter, np.array(green_aud_prop_sel_int), s = 8, facecolors = 'white' , edgecolors = 'k', linewidths =0.5)\n",
    "#     plt.plot([- meanLineWidth_small+2, meanLineWidth_small+2], [green_aud_prop_sel_median_int,green_aud_prop_sel_median_int],linewidth = 3,c = 'k')     \n",
    "\n",
    "#     plt.ylim(ylim_sel)\n",
    "#     plt.yticks([0,0.25, 0.5, 0.75,1],['0','25', '50', '75', '100'] )\n",
    "#     # plt.yticks(yTickValues_resp)\n",
    "#     # ax0.xaxis.set_ticklabels([])\n",
    "#     # ax0.xaxis.set_ticks([])\n",
    "#     myPlotSettings_splitAxis(fig,ax0,'','','')  \n",
    "#     plt.xticks([0,1,2], ['Azimuth', 'Elevation', 'Interaction'], rotation = 45, horizontalalignment='right')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1abfdd96-5275-4252-a4c1-af73872fc20f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotSignalCorrelation_byArea_CS(df, ops, mode = 'all' , computeMatrix =0): \n",
    "    \n",
    "    # areas = ops['areas']\n",
    "    areas = ['P', 'POR', 'LI', 'LM', 'AL', 'RL', 'A', 'AM', 'PM','V1'] \n",
    "\n",
    "    if computeMatrix: #takes a while\n",
    "        if mode=='all':\n",
    "            name = 'signal_corr_coliseum_resp_motorSub'\n",
    "        elif mode=='azi':\n",
    "            name = 'signal_corr_coliseum_resp_motorSub_azi'\n",
    "        elif mode=='elev':\n",
    "            name = 'signal_corr_coliseum_resp_motorSub_elev'\n",
    "        elif mode=='axons':\n",
    "            name = 'signal_corr_coliseum_resp_axons_motorSub'\n",
    "\n",
    "        nBatch =40\n",
    "        corrMatrix_byArea0 = np.zeros((len(areas), len(areas)))\n",
    "        for ar0 in range(len(areas)):\n",
    "            idx_thisArea = np.nonzero(np.array(df['area']) == areas[ar0])[0]\n",
    "\n",
    "            corr_byArea = [[] for _ in range(len(areas))]\n",
    "            sumPrev = 0\n",
    "            for i in tqdm(range(nBatch+1)):\n",
    "                corrs = np.load(os.path.join(ops['dataPath'], 'locations_dataset', 'signal_correlations',name,  name + '_' + str(i) + '.npy'))\n",
    "                #corrs = np.load(os.path.join(outputPath, 'signal_corr_frequencies_new_2dim' + str(i) + '.npy'))\n",
    "\n",
    "                nRois = corrs.shape[0]\n",
    "                idx_batch = np.arange(0,nRois) + sumPrev\n",
    "\n",
    "                idx_thisArea_batch = np.intersect1d(idx_thisArea, idx_batch)\n",
    "                corrs_thisArea = corrs[idx_thisArea_batch-sumPrev,:]\n",
    "\n",
    "                for ar1 in range(len(areas)):\n",
    "                    idx_area1 = np.nonzero(np.array(df['area']) == areas[ar1])[0]\n",
    "\n",
    "                    these_corr = corrs_thisArea[:,idx_area1].reshape(-1,1)\n",
    "                    notNanIdx = np.nonzero(~np.isnan(these_corr)==1)[0]\n",
    "                    these_corr = these_corr[notNanIdx]\n",
    "\n",
    "                    corr_byArea[ar1].append(these_corr)\n",
    "\n",
    "                sumPrev = nRois + sumPrev\n",
    "            for j in range(len(areas)):\n",
    "                for k in range(len(corr_byArea[j])-1):\n",
    "                    if k ==0:\n",
    "                        this = corr_byArea[j][k]\n",
    "                    else:\n",
    "                        this = np.concatenate((this,corr_byArea[j][k]),0)\n",
    "                corrMatrix_byArea0[ar0, j] = np.nanmean(this)\n",
    "                \n",
    "        #np.save(os.path.join(ops['dataPath'], 'locations_dataset', 'signalCorr_matrix_resp_axons_coliseum.npy'),corrMatrix_byArea0)\n",
    "    else:\n",
    "        if mode=='all':\n",
    "            name = 'signalCorr_matrix_resp_coliseum_boutons.npy'\n",
    "            limits = [-0.002, 0.002]\n",
    "        elif mode=='azi':\n",
    "            name = 'signalCorr_matrix_resp_coliseum_azi_boutons.npy'\n",
    "            limits = [-0.003, 0.003]\n",
    "        elif mode=='elev':\n",
    "            name = 'signalCorr_matrix_resp_coliseum_elev_boutons.npy'\n",
    "            limits = [-0.004, 0.004]\n",
    "        elif mode=='axons':\n",
    "            name = 'signalCorr_matrix_resp_coliseum_axons.npy'\n",
    "            limits = [-0.001, 0.001]\n",
    "\n",
    "            \n",
    "        corrMatrix_byArea0 = np.load(os.path.join(ops['dataPath'], 'locations_dataset', 'signal_correlations', name))\n",
    "        \n",
    "    #if small enough to load full matrix\n",
    "    # nBatch =40\n",
    "    # for i in tqdm(range(nBatch+1)):\n",
    "    #     corrs = np.load(os.path.join(outputPath, 'signal_corr_coliseum_resp_motorSub_' + str(i) + '.npy'))\n",
    "    #     if i ==0:\n",
    "    #         allCorr = corrs\n",
    "    #     else:\n",
    "    #         allCorr = np.concatenate((allCorr, corrs),0)       \n",
    "\n",
    "\n",
    "    fig = plt.figure(figsize= (ops['mm']*100,ops['mm']*100), constrained_layout =True)\n",
    "    ax = fig.add_subplot(1,1,1)\n",
    "   \n",
    "    plt.imshow(corrMatrix_byArea0, cmap = 'RdBu_r', vmin = limits[0], vmax = limits[1])\n",
    "    \n",
    "    plt.xticks(np.arange(0,len(areas)), areas, rotation = 90, fontsize=12)\n",
    "    plt.yticks(np.arange(0,len(areas)), areas,fontsize=12)\n",
    "    cbar = plt.colorbar(fraction = 0.05,ticks=[limits[0], 0,limits[1]])\n",
    "    cbar.ax.set_yticklabels([str(limits[0]), '0',str(limits[1])], fontsize=12)\n",
    "   \n",
    "    for axis in ['top','bottom','left','right']:\n",
    "        ax.spines[axis].set_linewidth(0.75)\n",
    "    plt.title('Signal corr, boutons, both dimensions', fontsize=8)\n",
    "    \n",
    "    #%%############################## by stream\n",
    "    if mode=='all':\n",
    "        name0 = 'corrs_coliseum_resp_byStream_allData'\n",
    "        name1 = 'signal_corr_coliseum_resp_motorSub'\n",
    "    elif mode=='azi':\n",
    "        name0 = 'corrs_coliseum_resp_azi_byStream_allData'\n",
    "        name1 = 'signal_corr_coliseum_resp_azi_motorSub'\n",
    "    elif mode=='elev':\n",
    "        name0 = 'corrs_coliseum_resp_elev_byStream_allData'\n",
    "        name1 = 'signal_corr_coliseum_resp_elev_motorSub'\n",
    "    elif mode=='axons':\n",
    "        name0 = 'corrs_coliseum_resp_axons_byStream_allData'\n",
    "        name1 = 'signal_corr_coliseum_resp_axons_motorSub'\n",
    "\n",
    "    boot_df = np.load(os.path.join(ops['dataPath'], 'locations_dataset','signal_correlations', name1, name0 + '.npy'), allow_pickle=True).item()\n",
    "   \n",
    "    color_dorsal = ops['myColorsDict']['HVA_colors']['AM']\n",
    "    color_ventral = ops['myColorsDict']['HVA_colors']['POR']\n",
    "    color_mixed = '#A160A4'\n",
    "    \n",
    "    diff_dd_dv = boot_df['mean_dd'] - boot_df['mean_dv']\n",
    "    diff_vv_dv = boot_df['mean_vv'] - boot_df['mean_dv']\n",
    "\n",
    "    p_dd_dv = np.float64(getBootstrapDiffP(diff_dd_dv))*2    \n",
    "    p_vv_dv = np.float64(getBootstrapDiffP(diff_vv_dv))*2      \n",
    "\n",
    "    fig = plt.figure(figsize=(ops['mm']*28, ops['mm']*39), constrained_layout=True)\n",
    "    ax= fig.add_subplot(1,1,1)\n",
    "    plt.bar(0,np.median(boot_df['mean_vv']), color= color_ventral, alpha = 0.7, edgecolor=color_ventral)\n",
    "    plt.vlines(0, np.percentile(boot_df['mean_vv'],2.5), np.percentile(boot_df['mean_vv'],97.5), color='k', linewidth=0.5)\n",
    "    plt.bar(1,np.median(boot_df['mean_dd']), color= color_dorsal, alpha = 0.7, edgecolor=color_dorsal)\n",
    "    plt.vlines(1, np.percentile(boot_df['mean_dd'],2.5), np.percentile(boot_df['mean_dd'],97.5), color='k', linewidth=0.5)\n",
    "    plt.bar(2,np.median(boot_df['mean_dv']), color= color_mixed, alpha = 0.7, edgecolor=color_mixed)\n",
    "    plt.vlines(2, np.percentile(boot_df['mean_dv'],2.5), np.percentile(boot_df['mean_dv'],97.5), color='k', linewidth=0.5)\n",
    "\n",
    "    plt.hlines(0,-0.5,2.5,color = 'dimgray', linewidth=0.5, linestyle='dashed')\n",
    "    myPlotSettings_splitAxis(fig, ax, 'Signal correlation', '', '', mySize=6)\n",
    "    plt.xticks([0,1,2], ['Ventral-Ventral','Dorsal-Dorsal', 'Ventral-Dorsal'], rotation = 45, horizontalalignment='right')\n",
    "    # plt.ylim([-0.0005, 0.003])\n",
    "    # plt.yticks([ 0, 0.001, 0.002,0.003],['0', '0.001', '0.002','0.003'])\n",
    "    if mode == 'all':\n",
    "        plt.ylim([-0.0005, 0.003])\n",
    "        plt.yticks([ 0, 0.001, 0.002, 0.003],['0', '0.001', '0.002', '0.003'])\n",
    "    elif mode == 'azi':\n",
    "        plt.ylim([-0.002, 0.006])\n",
    "        plt.yticks([-0.002, 0, 0.002, 0.004, 0.006],['-0.002', '0', '0.002', '0.004', '0.006'])\n",
    "    elif mode == 'elev':\n",
    "        plt.ylim([-0.002, 0.006])\n",
    "        plt.yticks([-0.002, 0, 0.002, 0.004, 0.006],['-0.002', '0', '0.002', '0.004', '0.006'])\n",
    "    elif mode == 'axons':\n",
    "        plt.ylim([-0.0005, 0.002])\n",
    "        plt.yticks([0, 0.001, 0.002],['0', '0.001', '0.002'])\n",
    "\n",
    "    ax.tick_params(axis='y', pad=1)   \n",
    "    ax.tick_params(axis='x', pad=1)   \n",
    "    plt.text(0,np.percentile(boot_df['mean_vv'],97.5), p_vv_dv, color = 'k')\n",
    "    plt.text(0.5,np.percentile(boot_df['mean_dd'],97.5), p_dd_dv, color = 'k')\n",
    "\n",
    "    # fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\signalCorr_byStream_resp_axons_barplots_hierarchical_allData.svg'))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "#     corrs_byStream = np.load(os.path.join(ops['dataPath'],'locations_dataset', 'corrs_coliseum_resp_axons_byStream_5000.npy'), allow_pickle =True)\n",
    "\n",
    "#     diff_dd_dv = corrs_byStream[:,0] - corrs_byStream[:,2]\n",
    "#     diff_vv_dv = corrs_byStream[:,1] - corrs_byStream[:,2]\n",
    "\n",
    "#     #find p-value for boostrapped difference\n",
    "#     #sort values, find the first one that is above 0.05, and compute the p-value from that\n",
    "#     p_dd_dv = getBootstrapDiffP(diff_dd_dv)       \n",
    "#     p_vv_dv = getBootstrapDiffP(diff_vv_dv)       \n",
    "\n",
    "#     color_ventral = 'r'\n",
    "#     color_dorsal = 'b'\n",
    "   \n",
    "#     color_dorsal =ops['myColorsDict']['HVA_colors']['AM']\n",
    "#     color_ventral =ops['myColorsDict']['HVA_colors']['POR']\n",
    "#     color_mixed = '#A160A4'\n",
    "\n",
    "#     fig = plt.figure(figsize=(ops['mm']*70, ops['mm']*100), constrained_layout=True)\n",
    "#     ax= fig.add_subplot(1,1,1)\n",
    "#     plt.bar(0,np.median(corrs_byStream[:,1]), color= color_ventral, alpha = 0.7, edgecolor=color_ventral)\n",
    "#     plt.vlines(0, np.percentile(corrs_byStream[:,1],2.5), np.percentile(corrs_byStream[:,1],97.5), color='k', linewidth=0.5)\n",
    "#     plt.bar(1,np.median(corrs_byStream[:,0]), color= color_dorsal, alpha = 0.7, edgecolor=color_dorsal)\n",
    "#     plt.vlines(1, np.percentile(corrs_byStream[:,0],2.5), np.percentile(corrs_byStream[:,0],97.5), color='k', linewidth=0.5)\n",
    "#     plt.bar(2,np.median(corrs_byStream[:,2]), color= color_mixed, alpha = 0.7, edgecolor=color_mixed)\n",
    "#     plt.vlines(2, np.percentile(corrs_byStream[:,2],2.5), np.percentile(corrs_byStream[:,2],97.5), color='k', linewidth=0.5)\n",
    "\n",
    "#     plt.hlines(0,-0.5,2.5,color = 'dimgray', linewidth=0.5, linestyle='dashed')\n",
    "#     myPlotSettings_splitAxis(fig, ax, 'Signal correlation', '', 'p_ven-ven_vs_ven-dor: ' + p_vv_dv + '\\np_dor-dor_vs_ven-dor: ' + p_dd_dv, mySize=15)\n",
    "#     plt.xticks([0,1,2], ['Ventral-Ventral','Dorsal-Dorsal', 'Ventral-Dorsal'], rotation = 45, horizontalalignment='right')\n",
    "#     # plt.ylim([-0.0005, 0.002])\n",
    "#     plt.yticks([-0.0002, 0, 0.0002, 0.0004,0.0006,0.0008],['-2', '0', '2', '4','6', '8'])\n",
    "#     ax.tick_params(axis='y', pad=1)   \n",
    "#     ax.tick_params(axis='x', pad=1)   \n",
    "#     # plt.text(0,0.0009, 'p_vv_dv=' + p_vv_dv, color = 'darkorange')\n",
    "#     # plt.text(0,0.0007, 'p_dd_dv=' + p_dd_dv, color = 'blue')\n",
    "\n",
    "#     #fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\signalCorr_byStream_resp_elev_axons_barplots.svg'))\n",
    "    \n",
    "#     ##### Now run the same thing for azimuth and elevation alone\n",
    "#     ########################################## AZIMUTH ##################################################\n",
    "#     areas = ops['areas']\n",
    "    \n",
    "#     if computeMatrix: #takes a while\n",
    "#         nBatch =40\n",
    "#         corrMatrix_byArea0 = np.zeros((len(areas), len(areas)))\n",
    "#         for ar0 in range(len(areas)):\n",
    "#             idx_thisArea = np.nonzero(np.array(df['area']) == areas[ar0])[0]\n",
    "\n",
    "\n",
    "#             corr_byArea = [[] for _ in range(len(areas))]\n",
    "#             sumPrev = 0\n",
    "#             for i in tqdm(range(nBatch+1)):\n",
    "#                 corrs = np.load(os.path.join(ops['dataPath'], 'locations_dataset', 'signal_corrs', 'signal_corr_coliseum_resp_axons_azi_motorSub_' + str(i) + '.npy'))\n",
    "#                 #corrs = np.load(os.path.join(outputPath, 'signal_corr_frequencies_new_2dim' + str(i) + '.npy'))\n",
    "\n",
    "#                 nRois = corrs.shape[0]\n",
    "#                 idx_batch = np.arange(0,nRois) + sumPrev\n",
    "\n",
    "#                 idx_thisArea_batch = np.intersect1d(idx_thisArea, idx_batch)\n",
    "#                 corrs_thisArea = corrs[idx_thisArea_batch-sumPrev,:]\n",
    "\n",
    "#                 for ar1 in range(len(areas)):\n",
    "#                     idx_area1 = np.nonzero(np.array(df['area']) == areas[ar1])[0]\n",
    "\n",
    "#                     these_corr = corrs_thisArea[:,idx_area1].reshape(-1,1)\n",
    "#                     notNanIdx = np.nonzero(~np.isnan(these_corr)==1)[0]\n",
    "#                     these_corr = these_corr[notNanIdx]\n",
    "\n",
    "#                     corr_byArea[ar1].append(these_corr)\n",
    "\n",
    "#                 sumPrev = nRois + sumPrev\n",
    "#             for j in range(len(areas)):\n",
    "#                 for k in range(len(corr_byArea[j])-1):\n",
    "#                     if k ==0:\n",
    "#                         this = corr_byArea[j][k]\n",
    "#                     else:\n",
    "#                         this = np.concatenate((this,corr_byArea[j][k]),0)\n",
    "#                 corrMatrix_byArea0[ar0, j] = np.nanmean(this)\n",
    "                \n",
    "#         #np.save(os.path.join(ops['dataPath'], 'locations_dataset', 'signalCorr_matrix_resp_axons_coliseum.npy'),corrMatrix_byArea0)\n",
    "#     else:\n",
    "#         corrMatrix_byArea0 = np.load(os.path.join(ops['dataPath'], 'locations_dataset', 'signalCorr_matrix_resp_axons_azi_coliseum.npy'))\n",
    "\n",
    "#     #if small enough to load full matrix\n",
    "#     # nBatch =40\n",
    "#     # for i in tqdm(range(nBatch+1)):\n",
    "#     #     corrs = np.load(os.path.join(outputPath, 'signal_corr_coliseum_resp_motorSub_' + str(i) + '.npy'))\n",
    "#     #     if i ==0:\n",
    "#     #         allCorr = corrs\n",
    "#     #     else:\n",
    "#     #         allCorr = np.concatenate((allCorr, corrs),0)       \n",
    "\n",
    "\n",
    "#     fig = plt.figure(figsize= (ops['mm']*100,ops['mm']*100), constrained_layout =True)\n",
    "#     ax = fig.add_subplot(1,1,1)\n",
    "   \n",
    "#     plt.imshow(corrMatrix_byArea0, cmap = 'RdBu_r', vmin = -0.001, vmax = 0.001)\n",
    "    \n",
    "#     plt.xticks(np.arange(0,len(areas)), areas, rotation = 90, fontsize=12)\n",
    "#     plt.yticks(np.arange(0,len(areas)), areas,fontsize=12)\n",
    "#     cbar = plt.colorbar(fraction = 0.05,ticks=[-0.001, 0,0.001])\n",
    "#     cbar.ax.set_yticklabels(['-0.001', '0','0.001'], fontsize=12)\n",
    "   \n",
    "#     for axis in ['top','bottom','left','right']:\n",
    "#         ax.spines[axis].set_linewidth(0.75)\n",
    "#     plt.title('Signal corr, azimuth only')\n",
    "    \n",
    "#     #%% by stream, normal not hierarchical\n",
    "#     corrs_byStream = np.load(os.path.join(ops['dataPath'],'locations_dataset', 'corrs_coliseum_resp_axons_azi_byStream_5000.npy'), allow_pickle =True)\n",
    "\n",
    "#     diff_dd_dv = corrs_byStream[:,0] - corrs_byStream[:,2]\n",
    "#     diff_vv_dv = corrs_byStream[:,1] - corrs_byStream[:,2]\n",
    "\n",
    "#     #find p-value for boostrapped difference\n",
    "#     #sort values, find the first one that is above 0.05, and compute the p-value from that\n",
    "#     p_dd_dv = getBootstrapDiffP(diff_dd_dv)       \n",
    "#     p_vv_dv = getBootstrapDiffP(diff_vv_dv)       \n",
    "\n",
    "#     color_ventral = 'r'\n",
    "#     color_dorsal = 'b'\n",
    "   \n",
    "#     color_dorsal =ops['myColorsDict']['HVA_colors']['AM']\n",
    "#     color_ventral =ops['myColorsDict']['HVA_colors']['POR']\n",
    "#     color_mixed = '#A160A4'\n",
    "\n",
    "#     fig = plt.figure(figsize=(ops['mm']*70, ops['mm']*100), constrained_layout=True)\n",
    "#     ax= fig.add_subplot(1,1,1)\n",
    "#     plt.bar(0,np.median(corrs_byStream[:,1]), color= color_ventral, alpha = 0.7, edgecolor=color_ventral)\n",
    "#     plt.vlines(0, np.percentile(corrs_byStream[:,1],2.5), np.percentile(corrs_byStream[:,1],97.5), color='k', linewidth=0.5)\n",
    "#     plt.bar(1,np.median(corrs_byStream[:,0]), color= color_dorsal, alpha = 0.7, edgecolor=color_dorsal)\n",
    "#     plt.vlines(1, np.percentile(corrs_byStream[:,0],2.5), np.percentile(corrs_byStream[:,0],97.5), color='k', linewidth=0.5)\n",
    "#     plt.bar(2,np.median(corrs_byStream[:,2]), color= color_mixed, alpha = 0.7, edgecolor=color_mixed)\n",
    "#     plt.vlines(2, np.percentile(corrs_byStream[:,2],2.5), np.percentile(corrs_byStream[:,2],97.5), color='k', linewidth=0.5)\n",
    "\n",
    "#     plt.hlines(0,-0.5,2.5,color = 'dimgray', linewidth=0.5, linestyle='dashed')\n",
    "#     myPlotSettings_splitAxis(fig, ax, 'Signal correlation, \\nazimuth only', '', 'p_ven-ven_vs_ven-dor: ' + p_vv_dv + '\\np_dor-dor_vs_ven-dor: ' + p_dd_dv, mySize=15)\n",
    "#     plt.xticks([0,1,2], ['Ventral-Ventral','Dorsal-Dorsal', 'Ventral-Dorsal'], rotation = 45, horizontalalignment='right')\n",
    "#     # plt.ylim([-0.0005, 0.002])\n",
    "#     plt.yticks([-0.0002, 0, 0.0002, 0.0004,0.0006,0.0008],['-2', '0', '2', '4','6', '8'])\n",
    "#     ax.tick_params(axis='y', pad=1)   \n",
    "#     ax.tick_params(axis='x', pad=1)   \n",
    "#     # plt.text(0,0.0009, 'p_vv_dv=' + p_vv_dv, color = 'darkorange')\n",
    "#     # plt.text(0,0.0007, 'p_dd_dv=' + p_dd_dv, color = 'blue')\n",
    "\n",
    "#     #fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\signalCorr_byStream_resp_elev_axons_barplots.svg'))\n",
    "    \n",
    "#     ########################################## ELEVATION ##################################################\n",
    "#     areas = ops['areas']\n",
    "    \n",
    "#     if computeMatrix: #takes a while\n",
    "#         nBatch =40\n",
    "#         corrMatrix_byArea0 = np.zeros((len(areas), len(areas)))\n",
    "#         for ar0 in range(len(areas)):\n",
    "#             idx_thisArea = np.nonzero(np.array(df['area']) == areas[ar0])[0]\n",
    "\n",
    "\n",
    "#             corr_byArea = [[] for _ in range(len(areas))]\n",
    "#             sumPrev = 0\n",
    "#             for i in tqdm(range(nBatch+1)):\n",
    "#                 corrs = np.load(os.path.join(ops['dataPath'], 'locations_dataset', 'signal_corrs', 'signal_corr_coliseum_resp_axons_elev_motorSub_' + str(i) + '.npy'))\n",
    "#                 #corrs = np.load(os.path.join(outputPath, 'signal_corr_frequencies_new_2dim' + str(i) + '.npy'))\n",
    "\n",
    "#                 nRois = corrs.shape[0]\n",
    "#                 idx_batch = np.arange(0,nRois) + sumPrev\n",
    "\n",
    "#                 idx_thisArea_batch = np.intersect1d(idx_thisArea, idx_batch)\n",
    "#                 corrs_thisArea = corrs[idx_thisArea_batch-sumPrev,:]\n",
    "\n",
    "#                 for ar1 in range(len(areas)):\n",
    "#                     idx_area1 = np.nonzero(np.array(df['area']) == areas[ar1])[0]\n",
    "\n",
    "#                     these_corr = corrs_thisArea[:,idx_area1].reshape(-1,1)\n",
    "#                     notNanIdx = np.nonzero(~np.isnan(these_corr)==1)[0]\n",
    "#                     these_corr = these_corr[notNanIdx]\n",
    "\n",
    "#                     corr_byArea[ar1].append(these_corr)\n",
    "\n",
    "#                 sumPrev = nRois + sumPrev\n",
    "#             for j in range(len(areas)):\n",
    "#                 for k in range(len(corr_byArea[j])-1):\n",
    "#                     if k ==0:\n",
    "#                         this = corr_byArea[j][k]\n",
    "#                     else:\n",
    "#                         this = np.concatenate((this,corr_byArea[j][k]),0)\n",
    "#                 corrMatrix_byArea0[ar0, j] = np.nanmean(this)\n",
    "                \n",
    "#         #np.save(os.path.join(ops['dataPath'], 'locations_dataset', 'signalCorr_matrix_resp_axons_coliseum.npy'),corrMatrix_byArea0)\n",
    "#     else:\n",
    "#         corrMatrix_byArea0 = np.load(os.path.join(ops['dataPath'], 'locations_dataset', 'signalCorr_matrix_resp_axons_elev_coliseum.npy'))\n",
    "\n",
    "#     #if small enough to load full matrix\n",
    "#     # nBatch =40\n",
    "#     # for i in tqdm(range(nBatch+1)):\n",
    "#     #     corrs = np.load(os.path.join(outputPath, 'signal_corr_coliseum_resp_motorSub_' + str(i) + '.npy'))\n",
    "#     #     if i ==0:\n",
    "#     #         allCorr = corrs\n",
    "#     #     else:\n",
    "#     #         allCorr = np.concatenate((allCorr, corrs),0)       \n",
    "\n",
    "\n",
    "#     fig = plt.figure(figsize= (ops['mm']*100,ops['mm']*100), constrained_layout =True)\n",
    "#     ax = fig.add_subplot(1,1,1)\n",
    "   \n",
    "#     plt.imshow(corrMatrix_byArea0, cmap = 'RdBu_r', vmin = -0.001, vmax = 0.001)\n",
    "    \n",
    "#     plt.xticks(np.arange(0,len(areas)), areas, rotation = 90, fontsize=12)\n",
    "#     plt.yticks(np.arange(0,len(areas)), areas,fontsize=12)\n",
    "#     cbar = plt.colorbar(fraction = 0.05,ticks=[-0.001, 0,0.001])\n",
    "#     cbar.ax.set_yticklabels(['-0.001', '0','0.001'], fontsize=12)\n",
    "   \n",
    "#     for axis in ['top','bottom','left','right']:\n",
    "#         ax.spines[axis].set_linewidth(0.75)\n",
    "#     plt.title('Signal corr, elevation only')\n",
    "    \n",
    "#     #%% by stream, normal not hierarchical\n",
    "#     corrs_byStream = np.load(os.path.join(ops['dataPath'],'locations_dataset', 'corrs_coliseum_resp_axons_elev_byStream_5000.npy'), allow_pickle =True)\n",
    "\n",
    "#     diff_dd_dv = corrs_byStream[:,0] - corrs_byStream[:,2]\n",
    "#     diff_vv_dv = corrs_byStream[:,1] - corrs_byStream[:,2]\n",
    "\n",
    "#     #find p-value for boostrapped difference\n",
    "#     #sort values, find the first one that is above 0.05, and compute the p-value from that\n",
    "#     p_dd_dv = getBootstrapDiffP(diff_dd_dv)       \n",
    "#     p_vv_dv = getBootstrapDiffP(diff_vv_dv)       \n",
    "\n",
    "#     color_ventral = 'r'\n",
    "#     color_dorsal = 'b'\n",
    "   \n",
    "#     color_dorsal =ops['myColorsDict']['HVA_colors']['AM']\n",
    "#     color_ventral =ops['myColorsDict']['HVA_colors']['POR']\n",
    "#     color_mixed = '#A160A4'\n",
    "\n",
    "#     fig = plt.figure(figsize=(ops['mm']*70, ops['mm']*100), constrained_layout=True)\n",
    "#     ax= fig.add_subplot(1,1,1)\n",
    "#     plt.bar(0,np.median(corrs_byStream[:,1]), color= color_ventral, alpha = 0.7, edgecolor=color_ventral)\n",
    "#     plt.vlines(0, np.percentile(corrs_byStream[:,1],2.5), np.percentile(corrs_byStream[:,1],97.5), color='k', linewidth=0.5)\n",
    "#     plt.bar(1,np.median(corrs_byStream[:,0]), color= color_dorsal, alpha = 0.7, edgecolor=color_dorsal)\n",
    "#     plt.vlines(1, np.percentile(corrs_byStream[:,0],2.5), np.percentile(corrs_byStream[:,0],97.5), color='k', linewidth=0.5)\n",
    "#     plt.bar(2,np.median(corrs_byStream[:,2]), color= color_mixed, alpha = 0.7, edgecolor=color_mixed)\n",
    "#     plt.vlines(2, np.percentile(corrs_byStream[:,2],2.5), np.percentile(corrs_byStream[:,2],97.5), color='k', linewidth=0.5)\n",
    "\n",
    "#     plt.hlines(0,-0.5,2.5,color = 'dimgray', linewidth=0.5, linestyle='dashed')\n",
    "#     myPlotSettings_splitAxis(fig, ax, 'Signal correlation, \\nelevation only', '', 'p_ven-ven_vs_ven-dor: ' + p_vv_dv + '\\np_dor-dor_vs_ven-dor: ' + p_dd_dv, mySize=15)\n",
    "#     plt.xticks([0,1,2], ['Ventral-Ventral','Dorsal-Dorsal', 'Ventral-Dorsal'], rotation = 45, horizontalalignment='right')\n",
    "#     # plt.ylim([-0.0005, 0.002])\n",
    "#     plt.yticks([-0.001, 0, 0.001, 0.002],['-0.001', '0', '0.001', '0.002'])\n",
    "#     ax.tick_params(axis='y', pad=1)   \n",
    "#     ax.tick_params(axis='x', pad=1)   \n",
    "#     # plt.text(0,0.0009, 'p_vv_dv=' + p_vv_dv, color = 'darkorange')\n",
    "#     # plt.text(0,0.0007, 'p_dd_dv=' + p_dd_dv, color = 'blue')\n",
    "\n",
    "#     #fig.savefig(os.path.join('Z:\\\\home\\\\shared\\\\Alex_analysis_camp\\\\paperFigures\\\\Plots\\\\signalCorr_byStream_resp_elev_axons_barplots.svg'))\n",
    "    \n",
    "#     ##### Now run the same thing for azimuth and elevation alone\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
